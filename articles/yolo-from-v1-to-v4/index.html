
<!DOCTYPE html>

    <html lang="zh-Hans-CN">

    
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="雨天等放晴">
    <title>实时目标检测方法 YOLO — 从 V1 到 V4 - 雨天等放晴</title>
    <meta name="author" content="Tang Huan">
    
        <meta name="keywords" content="YOLO,Object Detection,目标检测,目標檢測">
    
    
        <link rel="icon" href="https://tangh.github.io/assets/images/favicon.png">
    
    
        <link rel="apple-touch-icon" sizes="180x180" href="https://tangh.github.io/assets/images/apple-touch-icon.png">
    
    
    <script type="application/ld+json">{"@context":"http://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Tang Huan","sameAs":["https://twitter.com/tanghrtx/","https://www.flickr.com/photos/135277712@N07/","https://www.instagram.com/tanghrtx/","https://www.youtube.com/channel/UCO-I0MZR6-HYmI_tgbBc0yw/","https://space.bilibili.com/634428/"],"image":"icon.jpg"},"articleBody":"\n\n\n目前真正能实时（30fps 以上）的目标检测算法效果最好的可能就是 YOLO 了，本文注重它从五年前最初版本到前两天公布的 v4 版本的进化过程，会涉及到很多其它关联算法，希望能说清楚算法流程。此文不会对各种 ablation experiment 有分析，这种实验结果类的应当去看原文，只会提及 mAP 等关键数据；对于 related work 中 YOLO 没有使用的，也不会提到，这也应该去看原文。\n论文地址：\n\nV1，CVPR2016：https://arxiv.org/abs/1506.02640\n\nV2，CVPR2017：https://arxiv.org/abs/1612.08242\n\nV3：https://arxiv.org/abs/1804.02767\n\nV4：https://arxiv.org/abs/2004.10934\n\n作者网站：https://pjreddie.com/，上面有一些 slides、oral 视频、审稿 review\n\n代码：https://github.com/AlexeyAB/darknet，官方代码是 C&#x2F;CUDA 写的，除了 OpenCV 不依赖任何第三方库，包括现代的 tensor 库比如 TensorFlow、PyTorch 这些，它本身就是一个框架\n\n\n\n\n下个月应该会把一个两年前做的 R-CNN 系列的 slides 放上来（已更新至 Google Presentation），这样双极网络和单级网络的代表算法系列就齐活了。当然去年以来有一些很重要的 Anchor Free 的算法，虽然也可以划分为双极和单级，但其实挺大区别的，大致它们都是关键点检测的思想用了进来。\n下面的图来自 YOLOv4 的论文，检测的各个步骤和相应研究，我觉得分地挺好的。\nobject detection steps\n\n通常而言，单级网络去除了 Proposals 的生成过程，直接由预设好的 Anchors 加上回归值（SSD），或者网络直接预测框的中心和宽高（YOLO），来给出图像内 BBox 的位置。且单级网络没有特征重采样的过程，始终是一个密集预测，这使得一些平衡正负样本或其它作用的采样方式无法使用。\n此外，在两级网络中，对于一个位置上的一组 Anchors 或者一组 Proposals 的 类别 和 回归值，通常是由两个并行的全连接层分支给出的；而单级网络中，类别 和 Anchor 的回归值（或 BBox 的宽高）一般直接由一个预测卷积层给出，类别和回归值按照一定次序排列在输出特征的特定通道中。且通常一个点上只有一个位置预测，而不像两级网络一样，一个点上多个类别有对应的多个位置预测。\n\n\n\n\nOverview以下速度数据均在 Titan X (Maxwell) 上测试，Tesla M40 基本是相同的 GPU。新一代构架的是 Titan X (Pascal)、Titan Xp、GTX 1080 Ti、Tesla P100 这些。Titan Volta (Titan V)、Tesla V100 是更加新一代。再就到目前的 Turing，Titan RTX 这些。\n在 Pascal VOC 07 test 上，使用 07+12 训练\n\n\n\n名称\n速度（fps）\n精度（mAP）\n输入尺寸\n网络结构\n\n\n\nYOLOv1\n45\n63.4%\n448 × 448\nDarknet-24\n\n\nFast YOLOv1\n155\n52.7%\n448 × 448\nDarknet-9\n\n\nYOLOv2\n40\n78.6%\n544 × 544\nDarknet-19\n\n\nYOLOv2\n59\n77.8%\n480 × 480\nDarknet-19\n\n\nYOLOv2\n67\n76.8%\n416 × 416\nDarknet-19\n\n\nYOLOv2\n81\n73.7%\n352 × 352\nDarknet-19\n\n\nYOLOv2\n91\n69.0%\n288 × 288\nDarknet-19\n\n\n在 Pascal VOC 12 test 上，使用 07++12（即含 07 test）训练\n\n\n\n名称\n速度（fps）\n精度（mAP）\n输入尺寸\n网络结构\n\n\n\nYOLOv1\n45\n57.9%\n448 × 448\nDarknet-24\n\n\nYOLOv2\n–\n73.4%\n–\nDarknet-19\n\n\n在 MS COCO test-dev 上，使用 2017 split (trainval35k) 训练\n\n\n\n名称\n速度（fps）\n精度（mAP）\n精度（mAP 50）\n输入尺寸\n网络结构\n\n\n\nYOLOv2\n–\n21.6%\n44.0%\n–\nDarknet-19\n\n\nYOLOv3\n19.6\n33.0%\n57.9%\n608 × 608\nDarknet-53\n\n\nYOLOv3\n34.5\n31.0%\n55.3%\n416 × 416\nDarknet-53\n\n\nYOLOv3\n45.5\n28.2%\n51.5%\n320 × 320\nDarknet-53\n\n\nYOLOv4\n23\n43.5%\n65.7%\n608 × 608\nCSPDarknet-53\n\n\nYOLOv4\n31\n43.5%\n64.9%\n512 × 512\nCSPDarknet-53\n\n\nYOLOv4\n38\n43.5%\n62.8%\n416 × 416\nCSPDarknet-53\n\n\nYou Only Look Once: Unified, Real-Time Object Detection思想：缩放图片一次通过卷积神经网络同时得出位置和类别，这样速度快、中间步骤简单、基于一整张图所有信息而不是每个 Proposal 中部分信息进行检测。\nArchitectureYOLO prediction model\n\nYOLO 的检测方法是将输入图划分成 S×S 个格子（Grid），每一个格子预测出 B 个框。如果一个物体的中心落在某一个格子内部，那么这个格子负责预测这个物体。一个格子首先要预测它负责预测的物体的类别概率，这是一个长度为 Class (C) 的数组。此外，对于一个格子内的每个框，都还要预测另外的 5 个值 x, y, w, h, Pr*IoU，前两个值 x, y ∈ [0, 1] 表示框的中心点相对于这个格子的偏移，w, h 表示这个框在原图尺寸上的宽长（相对值，归一化到 [0, 1]）。这样得到预测值之后，先应用偏移 x, y 找到框的中心点，再通过 w, h 即可作出一个框。最后一个值 confidence = Pr(Object)*IoU 表示框内有物体的概率乘以这个框和 GT 之间的 IoU，也就是说，如果这个框对应的是背景，那么这个值应该是 0，如果这个框对应的是前景，那么这个值应该是与对应前景 GT 的 IoU。\n从上面我们可以看出：\n\nYOLO 所需要的整个输出为一个 S × S × (B*5 + C) 的 tensor，且这里 C 是前景的类别数，无需加上背景一类（例如对于 Pascal VOC，C&#x3D;20）。它无需两级检测网络的两个全连接分开输出类别和位置，也无需 Proposals 生成、特征重采样等过程。实验中，S&#x3D;7，B&#x3D;2。\n\n每个格子预测的长度为 Class 的概率是一个条件概率，是在有物体下的概率，即 Pr(Class_i|Object)，所以在预测的时候，把这个和每个框内预测的概率相乘 Pr(Class_i|Object) * Pr(Object) * IoU = Pr(Class_i) * IoU 就得到对每个框的逐类别概率。这里与 R-CNN 等两级网络不同之处在于，两级网络中一般使用 C+1 类判断前背景，而 YOLO 使用框内一个额外概率值判断前背景。\n\n得到的条件概率的意思是，以上图 class probability map 为例，每个格子取输出 tensor 对应的向量中的 class 分数的最大值对应的类别，就可以得到此图。最下方的红色是 C&#x3D;20 类中的一个类别，假设代表「飞机」。但是它并不表示这个格子就是「飞机」，而是，如果这个格子内有物体，那么这个格子内的物体的类别是「飞机」。而有没有物体，需要看上方图的 confidence，经提醒，这个图内的 98 个框（位置和大小反映 x, y, w, h）的粗细可能就代表这个 confidence 分数，只有 confidence 大的框，才认为里面有物体。\n\n\n下面看得到这个输出 tensor 的网络结构，YOLO 系列用了一个自创的网络结构，叫做 darknet，灵感源于 GoogLeNet (Inception V1)。在 YOLOv1 中，它有 24 层卷积层（加上 4 个池化层和 2 个全连接层），结构图如下。\nDarknet-24 (Unofficial name) Architecture\n\n这里没有使用 Inception Module，但是使用了同样的减少计算量的方法，即先用 1 × 1 reduction layer，再使用 3 × 3 convolutional layer。可以简单计算一下，在 1024 × 14 × 14 层，如果直接使用 1024 × 1024 × 3 × 3 卷积，计算量为 (1024 × 14 × 14) × (1024 × 3 × 3) = 1849.7M。而如果像图上结构一样先降维（可以理解为非线性映射到低维空间，可能联想到 PCA 虽然它是线性的）再卷积，计算量为 (512 × 14 × 14) × (1024 × 1 × 1) + (1024 × 14 × 14) × (512 × 3 × 3) = 102.7M + 924.8M = 1027.5M，接近于小到一半。这种 bottleneck 结构在现代 backbone 上很常见。\n对于激活层，最后一层使用的是线性激活函数，其它层使用的是 leaky ReLU，f(x) = 0.1x when x&lt;0。\nTraining and Inference首先在 ImageNet 上预训练前 20 层卷积，把后面替换为一个平均池化层和一个全连接层，输入尺寸为 224 × 224。训练好后改为 4 个卷积层和 2 个全连接层，输入尺寸改为 448 × 448。\nLoss 函数选择为 sum-squared error，。这有几个不平衡的问题：\n\n位置预测和类别预测是相等权重的；\n\n对于不含任何物体的格子，即负样本总是多于正样本的，所以 confidence 分数（每个 BBox 的第五个预测参数）会趋向于 0；\n\n大物体和小物体位置预测错误的权重是相等的，对于大物体，相同数量的位置偏移在 Loss 上的反映应当小于小物体的，因为对于 IoU 的影响会更小。\n\n\n对于前两个问题，通过增加权重  来解决。第三个问题，通过预测 BBox 宽高的平方根来解决。\n还有一个关于 GT 的问题是，一个格子负责预测中心点落在其内的物体，但一个格子预测了 B 个 BBox，我们只希望一个 BBox Predictor 负责一个物体。所以在训练时，只有预测出的框的与 GT 的 IoU 最大的那个 BBox 认为是有物体的（正样本）。所以这里与 R-CNN 系列两级网络不同，在那里一个 GT 是可以匹配到多个预测框的。作者这么设计意图是让每个 Predictor 专门化，专注于一种尺寸、长宽比或类别的物体。\n整个损失函数如下：\n\n\n\n公式中第一行是 BBox 的位置和大小；第二行是 BBox 内的 Pr*IoU；第三行是每个格子内的类别概率，可以看到只有格子内有物体时才有这项 loss，这与之前的条件概率是对应的。 表示如果 condition，那么这个值为 1，否则为 0。\n训练细节：\n\nepochs &#x3D; 135，batch size &#x3D; 64，momentum &#x3D; 0.9，weight decay &#x3D; 0.0005。\n\nlr：第一个 epoch 从 10e-3 增加到 10e-2，继续保持 75 个 epochs，然后 10e-3 训练 30 个 epochs，最终 10e-4 训练 30 个 epochs。\n\n第一个全连接层后加了一个 .5 的 Dropout 层防止过拟合。数据增强：20% 尺度的随机 translation 和 scaling，在 HSV 空间中 1.5x 的曝光和饱和度调整。\n\n\n对于测试，YOLO 设计为预测 98 个框，使用每个框内的第五个预测值决定是否留下这个框，类别使用格子预测的类别。对于一些大的物体，可能在多个格子内都给出接近的框，使用 NMS 可以增加 2% ～ 3% mAP。而对于 R-CNN 等基于区域分类的算法，NMS 是必不可少的。\nSummary and ResultsYOLO 的几个问题：\n\n对小物体效果不好；\n\nYOLO 通过下采样后数据得出 BBox 的位置偏移和宽高，所以精度不高，同时对于一些罕见的长宽比或者尺寸的物体的效果不好；\n\nloss 只是近似反映检测效果的好坏，比如对于不同大小的物体，x, y, w, h 的误差仍不能准确反映 IoU 的误差。YOLO 对于位置的预测较差，是降低 mAP 的主要原因。\n\n\n数据集使用 Pascal VOC 07+12。如果在 12 测试，那么 07 的 test 也被用于训练。在 07 的测试结果为 63.4% mAP，在 12 的测试结果为 57.9% mAP。\nYOLO9000: Better, Faster, Stronger改进：除了一些提高精度的，YOLOv2 还引入了 multi-scale training，所以它可在不同输入尺寸上工作，提供速度精度的 tradeoff。此外，提出了一种联合训练，可以同时在 COCO 和 ImageNet 上训练，网络可以学习检测那些没有在检测数据集中标注的类别。\nArchitecture首先看网络，作者将网络减少了几层，提高了速度，同时加入了 BN 层，提高了精度。\nDarknet-19 for classification\nDarknet-19 for detection\n\n\n整个网络（左图）含有 19 个卷积层和 5 个最大值池化层，不再有全连接层，网络的 output stride 减小了一倍变为 32。倒数第二层是 Global Average Pooling，出自 Network in Network，GoogLeNet 中也使用了，方法是在每个特征图通道上进行平均池化。在每个卷积层之后都加了 BN 层，网络不再需要 Dropout 层。\n对于检测（右图），网络输入尺寸也进行了改动，希望最终输出一个奇数尺寸，这样就会有一个中心点。所以 v2 中默认输入尺寸是 416 × 416，增减输入尺寸是以 64 为单位进行。一般一个大物体的中心会落在图像中心，所以这样可以用一个格子去预测它而不是四个格子。\n左图这个网络是用于 ImageNet Classification 的，在预训练完后需要改成检测网络。方法是去掉最后 Convolutional、AvgPool、Softmax 三层，然后加上三层 1024 × 3 × 3 卷积，最后用一个 1 × 1 卷积进行预测，得到所需 A × (5 + C) = 125 通道（这里通道数与 YOLOv1 不同，见下文）。此外，这里还加入一个 passthrough layer，使得网络对于小物体的检测效果更好。注意这里论文里说的和实际上代码里做的有些不同：论文中是把最后一个 512 × 3 × 3 卷积的结果，尺寸为 26 × 26 × 512 feature map 转化为 13 × 13 × 2048，然后 concat（通道上的连接）到倒数第二个卷积（也就是最后一个 3 × 3 卷积）的结果上；实际代码中对尺寸为 26 × 26 × 512 feature map 后面加了一个 64 × 1 × 1 的卷积，降低了通道数，然后再 reorg 转化为 13 × 13 × 256，并 concat 到 13 × 13 × 1024 的特征图上，输出一个 13 × 13 × 1280 的特征图。\n再看其它的改进：\nAnchor Box\nYOLO 在 BBox 位置预测上表现并不好，一方面是因为它直接给出宽高。相比 R-CNN 中有预设的 Anchors，网络只需要预测一个 offset，这相对容易。作者在 v2 中引入了 Anchors。\n第二个改动是，之前每个格子只预测一次类别，这实际上是对 BBox 的一种限制，现在需要 decouple。所以对每个 Anchor 都预测一组类别，它们的意义没变。同时，每个格子上的 BBox&#x2F;Anchor 数量不再是 2。\noutput tensor of YOLOv1 against YOLOv2\n\n此外，R-CNN 系列的 Anchors 是人工指定的，而这里的 Anchors 是通过 k-means 算法得到的，距离指标为 d(box, centroid) = 1 − IoU(box, centroid)，即以 IoU 来判断。下图是在 COCO 和 VOC 上聚类出的 Anchor 形状，以及使用不同距离指标或人工指定得到的平均 IoU。\nk-means result\n\nDirect location prediction\n这里先回顾一下 R-CNN 系列中的 regressor 是怎么工作的（注意在 YOLO 的论文中符号错了）：\n\n\n其中带下标 a 的是 Anchor，t 表示网络预测的值。\n对于位置这样引入了尺度不变性，比如 tx = 1 框的中心点就向右移动一个框宽度的距离。但是这对于框的位置没有限定，对于随机化的初始值，框可能出现在图中的任何位置，导致难以训练。所以位置还是沿用 v1 中的相对于格子的预测方式，宽高则采用相同的指数形式。\n\n\nYOLOv2 anchor regression\n\n公式里 sigma(·) 是一个 logistic activation (sigmoid) 用于将值限定在 [0, 1]，即把中心点的变动限制在当前格子里。cx, cy 是所在格点左上角到图像左上角的距离，例如上图中是 (1, 1)（网格大小归一化了）。这里可以看出，这个位置是直接预测出的，它不依赖于设定的 Anchors。\nTrain YOLOv2\n\n\n网络\ntop-5\ntop-1\n输入尺寸\nfloating point operations\n\n\n\nVGG-16\n90.0%\n-\n224 × 224\n30.69 billion\n\n\nDarknet-24\n88.0%\n-\n224 × 224\n8.52 billion\n\n\nDarknet-19\n91.2%\n72.9%\n224 × 224\n5.58 billion\n\n\n\n在 ImageNet 上训练 160 个 epochs。lr &#x3D; 0.1，polynomial rate decay with a power of 4，weight decay &#x3D; 0.0005，momentum &#x3D; 0.9。随机裁剪、旋转、颜色和曝光调整。\n\nHigh Resolution Classifier：ImageNet 训练是使用 224 × 224，这样在进行检测训练时，网络不仅要学习更大的 448 × 448 输入，还要同时学习检测任务。所以在 v2 中，会在 ImageNet 上使用 448 × 448 fine tune 10 个 epochs 再进行检测训练，lr &#x3D; 10e-3。准确率达到 76.5%&#x2F;93.3%。\n\nMulti-Scale Training：接下来进行检测训练。训练中每过 10 个 epochs，会在 &#123;320, 352, ..., 608&#125; 中随机选择一个输入尺寸继续训练。共 160 个 epochs，lr &#x3D; 10e-3，在 10、60、90 epoch 时减半。weight decay、momentum 与上面相同。\n\n\nSummaryThe path from YOLO to YOLOv2\n\n上表总结了从 v1 到 v2 的各项改进，说明一下：表中的 anchor boxes 指的是人工指定的，固定尺寸和长宽比的 anchors，使用这种框，mAP 69.5 -&gt; 69.2，recall 81% -&gt; 88%，精度小幅下降召回明显提高，说明网络有较大提升空间，所以作者采取了下面的 k-means 聚类找出最佳初始尺寸的方法。对于这种聚类得到的框，作者叫它 dimension priors，可能应该翻译成「先验框」。但是我觉得它本质和 anchors 没什么差别，且对于网络的修改也沿用了，其实在 v3 中作者也管它叫 anchors 了，所以在上文没有区分。\nJoint train on object detection and classification (YOLO9000)基本思路是对于检测的数据传入，BP 整个网络，对于分类的数据传入，只 BP 有关分类的网络部分。一个问题是检测数据集如 COCO 提供的是一个很泛的类别，比如「狗」，共 80 类；而分类数据集如 ImageNet 提供的类别是很具体的，如「哈士奇」，共 21841 类。而 Softmax 意味着各类别之间是相互排斥的，而我们希望只在每个数据集内类别相互排斥，而数据集之间不是。\n下面仍然先要在分类上预训练，然后再训练检测。\nClassification\nImageNet 的标签来自于 WordNet，一个语言数据集，它有详细的层级，比如 canine -&gt; dog -&gt; hunting dog -&gt; terrier -&gt; Norfolk terrier，但是它是一个 Graph 而不是 Tree，比如 dog 可以属于 canine 也可以属于 domestic animal，即有多个父节点。好在大多数类别通向 root 只有一条路径，对于有多条路径的，选择最短的路径，舍弃其它的，这样就可以构造一个 Word Tree。\n对于 ImageNet-1000，构建完整个图之后有 1369 个节点，增加了额外的 369 个节点。每一个节点预测一个条件概率，最终的概率需要将它们相乘，例如 Pr(Norfolk terrier) = Pr(Norfolk terrier|terrier) * Pr(terrier|hunting dog) ∗ ... ∗ Pr(mammal|animal) * Pr(animal|physical object) * Pr(physical object)。对于分类，每张图都有物体，所以这里最后一项 Pr(physical object) = 1。\nPrediction on ImageNet vs WordTree\n\n在 ImageNet 上使用这个图训练网络，预测的形式如上图右侧，在每层级下分别 Softmax。一张图片会顺着这个 tree（可参考下面的图）走到 root，获得路径上的所有标签，即一张图现在有多个标注。这样训练的结果为 71.9%&#x2F;90.4%。新增节点后准确率下降不多，同时如果网络见到了一个没训练过的狗的品种，那么预测中「狗」的概率会很大，同时所有具体类别的概率又很小。\nDetection\n对于框的分类结果，检测中每个格子内不一定有物体， Pr(physical object) 根据 confidence&#x2F;objectness 分数（BBox 的第五个预测值）确定。判断一个框的类别时，从 WordTree 根节点开始向下遍历，对每一个节点，在它的所有子节点中，选择概率最大的那个（一个节点下面的所有子节点是互斥的），一直向下遍历直到某个节点的子节点概率低于设定的阈值（意味着很难确定它的下一层对象到底是哪个），或达到叶子节点，那么该节点就是对应的对象。\nCombining datasets using WordTree hierarchy\n\n训练总共选取了 9000 类，含有 COCO、ImageNet 分类和检测数据集。为了构造 Tree 产生的父节点，构造的方法与之前相同，加起来共 9418 类。Oversampling COCO 使得数据量之比为 4:1。\n网络结构和 v2 相同，先验框的尺寸改为 3 种。标注和反向传播与之前类似，（1）对于检测数据集图像，loss 与之前相同，只是这里对于 class，只反向传播标注的那个节点及其父节点上的 loss，不 BP 其子节点上的；（2）对于分类数据集图像，首先找到 GT 所属类别的预测值最高的那个框，只反向传播这个框上的 class 和 objectness 部分，四个坐标不反向传播。对于 class，与检测的相同，只看其和其父节点的，对于 objectness，原文是「We also assume that the predicted box overlaps what would be the ground truth label by at least .3 IOU and we backpropagate objectness loss based on this assumption.」，我觉得意思是说如果预测的 objectness = Pr(object) * IoU 小于 1 * 0.3 的话就有一个损失在上面，具体损失形式需要以后看一下代码了更新。\nResults\n作者在 ImageNet Detection 上测试，其中 44 类是与 COCO 相同的，156 类是 COCO 中没有只出现在 ImageNet Classification 的。结果是 19.7 mAP，在不重合的 156 类上有 16.0 mAP。具体来看不重合的类别部分，对于各种动物，COCO 中有一些动物的标注，对于新动物的类别的表现不错：red panda = 50.7, fox = 52.1, koala bear = 54.3, tiger = 61.0, armadillo = 61.7；对于一些 COCO 中完全没有相关（类似）的类别的，表现很差：diaper = 0.0, horizontal bar = 0.0, rubber eraser = 0.0, sunglasses = 0.0, swimming trunks = 0.0。\nYOLOv3: An Incremental ImprovementYOLOv3 和 v4 都是 tech report，更多是把别人的工作在保证速度前提下整合进 YOLO 以提高精度。\n每一代 YOLO 都对网络或是说 backbone 进行了改进，YOLOv3 更是主要集中在这个网络上。\nNetworkYOLOv3 同样是先有一个检测网络，在 ImageNet 上预训练，然后改为检测网络训练。下图（右侧是左侧红线部分）是 DarkNet-53，含有 52 个卷积和 1 个全连接。可以看到，与 DarkNet-19 相比，层数多了不少，主要的改变在于：\n\n去掉了池化层，全部由一个步长为 2 的卷积层完成下采样。\n\n最后的全连接层又回来了。\n\n内部出现了类似于 ResNet 的残差连接。\n\n\nDarknet-53 for classification\n\n\n\n\nbackbone\ntop-1\ntop-5\n测试尺寸\nOps\nFPS\nBFLOP&#x2F;s\n\n\n\nDarknet-19\n74.1%\n91.8%\n256 × 256\n7.29 B\n171\n1246\n\n\nDarknet-53\n77.2%\n93.8%\n256 × 256\n18.7 B\n78\n1457\n\n\nResNet-101\n77.1%\n93.7%\n256 × 256\n19.7 B\n53\n1039\n\n\nResNet-152\n77.6%\n93.8%\n256 × 256\n29.4 B\n37\n1090\n\n\n上述数据统一在 TitanX 下测试，最后一项 BFLOP&#x2F;s 意味着 Darknet 对 GPU 的利用更好。\n再看检测网络，在这里作者引入了类似于 FPN 的多级预测结构。这个在论文里讲得有点零散混乱且没有结构图，我根据代码做了一个下面的网络结构图。\nDarknet-53 for detection\n\n解释几点：\n\n每一个 Conv 都跟着一个 BN 和 leaky ReLU 激活层，最后每个 Prediction 是通过一个无 BN、linear 激活的 1 × 1 卷积层得到的，就是一般的预测层，在图中没有画出（也可认为绿色的 Prediction 就是这个卷积）。\n\n每一个 Add 之后有一个 linear activation。\n\n这里每个 Residual Unit 里面只有两层，与 ResNet 的不一样。上方蓝色的 N× 表示括号内的模块重复 N 次。\n\nConv 上方的尺寸是指经过这一层后的尺寸，以输入 416 × 416 为例。都是 CHW 的格式。\n\n黄色的层是改为检测网络之后新加入的，白色的是原有的 Darknet-53 Backbone，共 52 层（去掉了最后的全连接）。\n\n\n再看最后输出的 255 个通道是怎么回事，255 = 3 × (80 + 5)，首先这里是以 COCO 为基准了，不再使用 VOC 的，所以是 80；5 就是从 v1 一直延续来的；3 指的是三个 Anchors，在 v2 里是五个，而 v3 实际用了 9 个，平均分在三级预测上。在 COCO 上尺寸分别是 (10×13),(16×30),(33×23),(30×61),(62×45),(59× 119), (116 × 90), (156 × 198), (373 × 326)。\nOther ImprovementsBounding Box Prediction (objectness)\n对于 objectness 分数，YOLOv3 采用了 logistic regression，所以如果一个 BBox 与 GT 的交叠大于任何其它的 BBox，那么它的 objectness 分数应该为 1。训练使用 binary cross-entropy loss，不再是 SSE loss。\n同时引入了类似 RPN 的匹配机制：如果一个框与 GT 的交叠大于一个阈值 0.5 但它又不是交叠最大的框，那么这个将作为非正非负的样本，在训练时被忽略。\n同样，一个 GT 只会与一个 Anchor&#x2F;BBox 匹配上，对于没有匹配上的负样本，loss 中将没有 coordinate 和 class predictions 部分，只有 objectness loss。\nClass Prediction (classes)\n作者去掉了之前使用的 Softmax 进行类别分类，因为发现对准确率没有帮助，且一个大型数据集如 Open Images 上面有一些交叠的类别，比如 Woman - Person。使用 independent logistic classifiers 预测，并设定一个阈值，高于这个阈值的类别将被赋给对应的框。训练使用 binary cross-entropy loss，不再是 SSE loss。\nResultsYOLO v3 results on COCO test-dev\n\n从上表可以看出，YOLOv3-608 在 COCO 上的结果以及到了和 ResNet-FasterRCNN 接近的水平，但是时间仅需 51ms，是后者的三倍多。同时，在 AP50 指标上 YOLO 表现得很好，说明很大一部分的问题来自于框的位置的不准确。\nprecision-speed compare on COCO test-dev\n\n\n\nYOLOv4: Optimal Speed and Accuracy of Object DetectionYOLOv4 是一篇将其它人提出许多的方法整合进 YOLO 的文章，但有一个前提就是保证速度，所以有些方法做了一些改动。同时基于这个原则，作者希望能使用较亲民的设备进行训练和预测，所以所有涉及多 GPU 的方法比如 SyncBN 均不予考虑。相应的测试也选用单个 RTX 2080Ti&#x2F;RTX 2070&#x2F;GTX 1080Ti 这类游戏显卡（但是 2080Ti 这好像不是所有打游戏的都买得起的？）。不过这篇文章还挺好的，对检测的研究也进行了一个相应的划分总结，还是挺全面的像综述一样，值得看看原文，本文里只有 YOLOv4 用到了的方法的分析。\n其实我感觉很难写，因为涉及太多其它的文章，不知道简单几句能不能给一篇文章讲清楚。此外有些还是今年的，很新，我也没看过。。。\n总的来说，作者将其它人的工作划分为 Bag of freebies (BoF) 和 Bag of specials (BoS)。前者指在训练时候的一些方法，不影响预测时间和模型复杂度；而后者指的是整个构架的改动，对预测（时间）会有影响。我花了点时间给整理了一下，下面两个表是用到的所有方法和对应论文，没有对应论文的就是作者在 YOLOv4 中应用的一些简单 BoF，可以看到，这篇文章各种 tricks 真的巨多，我相信给其它算法这么一顿军训效果也能好不少的。不过别人已经测试好了，直接能用，也很实用对吧。\n\n\n\n\n\nBackbone BoF\narXiv\nDetector BoF\narXiv\n\n\n\nCutMix\nICCV 2019 1905.04899\nCIoU-loss\nAAAI 2020 1911.08287\n\n\nDropBlock regularization\nNIPS 2018 1810.12890\nDropBlock regularization\n1810.12890\n\n\nClass label smoothing\nCVPR 2016 1512.00567\nCross mini-Batch Normalization (CmBN)\n2002.05712\n\n\n\n\nCosine annealing scheduler\n1608.03983\n\n\nOthers:\n\nBoF: Mosaic data augmentation.\n\nDetector BoF: Eliminate grid sensitivity, Optimal hyper-parameters, Random training shapes, Self-Adversarial Training, Multiple anchors for a single ground truth.\n\n\n\n\n\n\n\nBackbone BoS\narXiv\nDetector BoS\narXiv\n\n\n\nMish activation\n1908.08681\nMish activation\n1908.08681\n\n\nCross-stage partial connections (CSP)\n1911.11929\nSPP-block\nTPAMI 2015 1406.4729\n\n\nMulti-input weighted residual connections (MiWRC)\nCVPR 2020 1911.09070\nPath-aggregation block (PAN)\nCVPR 2018 1803.01534\n\n\n\n\nSAM-block\nECCV 2018 1807.06521\n\n\n\n\nDIoU-NMS\nAAAI 2020 1911.08287\n\n\n仍需要一点时间施工，不过我猜要拖到五月底了。已经到五月底了，然而事情很多，考虑到眼下两个月之内应该不会有机会看论文，所以我愉快地宣布下面的内容鸽子了 🐦。\n\n\nBag of freebies最常用的 bag of freebies 就是数据增强（data augmentation）了，YOLOv4 用了下面这些。\nCutMix\nCutMix 是一种 regional dropout strategy，这类方法通过去除一些 informative pixels 来使得网络学习图像中 less discriminative 部分的信息。\n关于训练时的标签和损失函数，YOLOv4 中使用了下面这些。\nClass label smoothing\n使得 class 标签不绝对，提升分类器效果。\nCIoU Loss\n直接以 IoU 作为 regression 的损失函数，提高了回归精度。从 IoU -&gt; GIoU -&gt; DIoU -&gt; CIoU 的变化过程，见 另一篇关于 regressor 的文中 IoU Loss 的部分。\nBag of specialsMulti-input weighted residual connections (MiWRC)、Path-aggregation block (PAN)\n前者为带权重的特征融合方式，后者为 neck 上的新的特征融合路径。见 另一篇关于 EfficientDet 文中 BiFPN 的部分。\nDIoU-NMS\n在 NMS 时考虑两个 box 中心点之间的距离以稍微降低其 IoU 值的方法，见 另一篇关于 regressor 的文中 DIoU 的部分。\n","dateCreated":"2020-04-25T00:00:00+08:00","dateModified":"2023-05-28T23:52:13+08:00","datePublished":"2020-04-25T00:00:00+08:00","description":"实时目标检测方法 YOLO 从 v1 到 v4 的进化过程，及其相关算法的步骤分析。","headline":"实时目标检测方法 YOLO — 从 V1 到 V4","image":["https://tangh.github.io/images/thumbnails/darknet-yolo.png"],"mainEntityOfPage":{"@type":"WebPage","@id":"https://tangh.github.io/articles/yolo-from-v1-to-v4/"},"publisher":{"@type":"Organization","name":"Tang Huan","sameAs":["https://twitter.com/tanghrtx/","https://www.flickr.com/photos/135277712@N07/","https://www.instagram.com/tanghrtx/","https://www.youtube.com/channel/UCO-I0MZR6-HYmI_tgbBc0yw/","https://space.bilibili.com/634428/"],"image":"icon.jpg","logo":{"@type":"ImageObject","url":"icon.jpg"}},"url":"https://tangh.github.io/articles/yolo-from-v1-to-v4/","keywords":"Computer Vision, Deep Learning, Object Detection","thumbnailUrl":"https://tangh.github.io/images/thumbnails/darknet-yolo.png"}</script>
    <meta name="description" content="实时目标检测方法 YOLO 从 v1 到 v4 的进化过程，及其相关算法的步骤分析。">
<meta property="og:type" content="blog">
<meta property="og:title" content="实时目标检测方法 YOLO — 从 V1 到 V4">
<meta property="og:url" content="https://tangh.github.io/articles/yolo-from-v1-to-v4/">
<meta property="og:site_name" content="雨天等放晴">
<meta property="og:description" content="实时目标检测方法 YOLO 从 v1 到 v4 的进化过程，及其相关算法的步骤分析。">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://d2y8c08sxwbp8v.cloudfront.net/2020-detection/yolo-detection-steps.png">
<meta property="og:image" content="https://d2y8c08sxwbp8v.cloudfront.net/2020-detection/yolo-prediction-model.png">
<meta property="og:image" content="https://d2y8c08sxwbp8v.cloudfront.net/2020-detection/yolo-darknet-24.png">
<meta property="og:image" content="https://d2y8c08sxwbp8v.cloudfront.net/2020-detection/yolo-darknet-19-classification.png">
<meta property="og:image" content="https://d2y8c08sxwbp8v.cloudfront.net/2020-detection/yolo-darknet-19-detection.png">
<meta property="og:image" content="https://d2y8c08sxwbp8v.cloudfront.net/2020-detection/yolo-output-tensor.png">
<meta property="og:image" content="https://d2y8c08sxwbp8v.cloudfront.net/2020-detection/yolo-anchor-clusters.png">
<meta property="og:image" content="https://d2y8c08sxwbp8v.cloudfront.net/2020-detection/yolo-v2-anchor-regression.png">
<meta property="og:image" content="https://d2y8c08sxwbp8v.cloudfront.net/2020-detection/yolo-v2-improvement-path.png">
<meta property="og:image" content="https://d2y8c08sxwbp8v.cloudfront.net/2020-detection/yolo-prediction-on-wordtree1k.png">
<meta property="og:image" content="https://d2y8c08sxwbp8v.cloudfront.net/2020-detection/yolo-combine-coco-and-imagenet.png">
<meta property="og:image" content="https://d2y8c08sxwbp8v.cloudfront.net/2020-detection/yolo-darknet-53-classification.png">
<meta property="og:image" content="https://d2y8c08sxwbp8v.cloudfront.net/2020-detection/yolo-darknet-53-detection.png">
<meta property="og:image" content="https://d2y8c08sxwbp8v.cloudfront.net/2020-detection/yolo-v3-results-on-coco-test-dev.png">
<meta property="og:image" content="https://d2y8c08sxwbp8v.cloudfront.net/2020-detection/yolo-v3-precision-speed-compare.png">
<meta property="article:published_time" content="2020-04-24T16:00:00.000Z">
<meta property="article:modified_time" content="2023-05-28T15:52:13.294Z">
<meta property="article:author" content="Tang Huan">
<meta property="article:tag" content="Computer Vision">
<meta property="article:tag" content="Deep Learning">
<meta property="article:tag" content="Object Detection">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://d2y8c08sxwbp8v.cloudfront.net/2020-detection/yolo-detection-steps.png">
    
    
        
    
    
        <meta property="og:image" content="https://tangh.github.io/assets/images/icon.jpg"/>
    
    
        <meta property="og:image" content="https://tangh.github.io/images/thumbnails/darknet-yolo.png"/>
        <meta class="swiftype" name="image" data-type="enum" content="https://tangh.github.io/images/thumbnails/darknet-yolo.png"/>
    
    
    
    <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+JP:wght@400;700&family=Noto+Serif+SC:wght@400;700&display=swap" rel="stylesheet">
    <!--STYLES-->
    
<link rel="stylesheet" href="/assets/css/style-iaetwm81hfopcuajcp7qnh2zsnqn4dhiu3nftuj79wdhe7fie6l4r0thrs6g.min.css">

    <!--STYLES END-->
    
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-137837052-1"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'UA-137837052-1');
    </script>


    

<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --></head>

    <body>
        <div id="blog">
            <!-- Define author's picture -->


    
        
            
        
    

<header id="header" data-behavior="4">
    <i id="btn-open-sidebar" class="fa fa-lg fa-bars"></i>
    <div class="header-title">
        <a
            class="header-title-link"
            href="/"
            aria-label=""
        >
            雨天等放晴
        </a>
    </div>
    
        
            <a
                class="header-right-picture "
                href="#about"
                aria-label="Open the link: /#about"
            >
        
        
            <img class="header-picture" src="/assets/images/icon.jpg" alt="Author&#39;s picture"/>
        
        </a>
    
</header>

            <!-- Define author's picture -->



        
    

<nav id="sidebar" data-behavior="4">
    <div class="sidebar-container">
        
            <div class="sidebar-profile">
                <a
                    href="/#about"
                    aria-label="Read more about the author"
                >
                    <img class="sidebar-profile-picture" src="/assets/images/icon.jpg" alt="Author&#39;s picture"/>
                </a>
                <h4 class="sidebar-profile-name">Tang Huan</h4>
                
                    <h5 class="sidebar-profile-bio"></h5>
                
            </div>
        
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/"
                            
                            rel="noopener"
                            title="Home"
                        >
                        <i class="sidebar-button-icon fa fa-home" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Home</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/all-categories"
                            
                            rel="noopener"
                            title="Categories"
                        >
                        <i class="sidebar-button-icon fa fa-bookmark" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Categories</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/all-tags"
                            
                            rel="noopener"
                            title="Tags"
                        >
                        <i class="sidebar-button-icon fa fa-tags" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Tags</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/all-archives"
                            
                            rel="noopener"
                            title="Archives"
                        >
                        <i class="sidebar-button-icon fa fa-archive" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Archives</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/about"
                            
                            rel="noopener"
                            title="About"
                        >
                        <i class="sidebar-button-icon fas fa-cube" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">About</span>
                    </a>
            </li>
            
        </ul>
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="https://twitter.com/tanghrtx/"
                            
                                target="_blank"
                            
                            rel="noopener"
                            title="Twitter"
                        >
                        <i class="sidebar-button-icon fab fa-twitter" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Twitter</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="https://www.flickr.com/photos/135277712@N07/"
                            
                                target="_blank"
                            
                            rel="noopener"
                            title="Flickr"
                        >
                        <i class="sidebar-button-icon fab fa-flickr" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Flickr</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="https://www.instagram.com/tanghrtx/"
                            
                                target="_blank"
                            
                            rel="noopener"
                            title="Instagram"
                        >
                        <i class="sidebar-button-icon fab fa-instagram" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Instagram</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="https://www.youtube.com/channel/UCO-I0MZR6-HYmI_tgbBc0yw/"
                            
                                target="_blank"
                            
                            rel="noopener"
                            title="YouTube"
                        >
                        <i class="sidebar-button-icon fab fa-youtube" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">YouTube</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="https://space.bilibili.com/634428/"
                            
                                target="_blank"
                            
                            rel="noopener"
                            title="BiliBili"
                        >
                        <i class="sidebar-button-icon fab fa-youtube-square" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">BiliBili</span>
                    </a>
            </li>
            
        </ul>
        
    </div>
</nav>

            
            <div id="main" data-behavior="4"
                 class="
                        hasCoverMetaIn
                        ">
                
<article class="post">
    
    
        <div class="post-header main-content-wrap text-center">
    
        <h1 class="post-title">
            实时目标检测方法 YOLO — 从 V1 到 V4
        </h1>
    
    
        <div class="post-meta">
    <time datetime="2020-04-25T00:00:00+08:00">
	
		    Apr 25, 2020
    	
    </time>
    
        <span>in </span>
        
    <a class="category-link" href="/categories/Computer-Science/">Computer Science</a>, <a class="category-link" href="/categories/Computer-Science/Deep-Learning/">Deep Learning</a>


    
</div>

    
</div>

    
    
        <div class="post-content markdown">
    
        <div class="main-content-wrap">
            <!-- excerpt -->


<p>目前真正能实时（30fps 以上）的目标检测算法效果最好的可能就是 YOLO 了，本文注重它从五年前最初版本到前两天公布的 v4 版本的进化过程，会涉及到很多其它关联算法，希望能说清楚算法流程。此文不会对各种 ablation experiment 有分析，这种实验结果类的应当去看原文，只会提及 mAP 等关键数据；对于 related work 中 YOLO 没有使用的，也不会提到，这也应该去看原文。</p>
<div class="alert info no-icon"><p><strong>论文地址：</strong></p>
<ol>
<li><p>V1，CVPR2016：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1506.02640">https://arxiv.org/abs/1506.02640</a></p>
</li>
<li><p>V2，CVPR2017：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1612.08242">https://arxiv.org/abs/1612.08242</a></p>
</li>
<li><p>V3：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1804.02767">https://arxiv.org/abs/1804.02767</a></p>
</li>
<li><p>V4：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2004.10934">https://arxiv.org/abs/2004.10934</a></p>
</li>
<li><p>作者网站：<a target="_blank" rel="noopener" href="https://pjreddie.com/">https://pjreddie.com/</a>，上面有一些 slides、oral 视频、审稿 review</p>
</li>
<li><p>代码：<a target="_blank" rel="noopener" href="https://github.com/AlexeyAB/darknet">https://github.com/AlexeyAB/darknet</a>，官方代码是 C&#x2F;CUDA 写的，除了 OpenCV 不依赖任何第三方库，包括现代的 tensor 库比如 TensorFlow、PyTorch 这些，它本身就是一个框架</p>
</li>
</ol>
</div>

<p>下个月应该会把一个两年前做的 R-CNN 系列的 slides 放上来（已更新至 <a target="_blank" rel="noopener" href="https://docs.google.com/presentation/d/1N2H12L0XVV-s0FuxcyHAcG0CFNujHxuWneObr8o7CAE/edit?usp=sharing">Google Presentation</a>），这样双极网络和单级网络的代表算法系列就齐活了。当然去年以来有一些很重要的 Anchor Free 的算法，虽然也可以划分为双极和单级，但其实挺大区别的，大致它们都是关键点检测的思想用了进来。</p>
<p>下面的图来自 YOLOv4 的论文，检测的各个步骤和相应研究，我觉得分地挺好的。</p>
<div class="figure center" style="width:;"><a class="fancybox" target="_blank" rel="noopener" href="https://d2y8c08sxwbp8v.cloudfront.net/2020-detection/yolo-detection-steps.png" title="object detection steps" data-caption="object detection steps" data-fancybox="default"><img class="fig-img" src="https://d2y8c08sxwbp8v.cloudfront.net/2020-detection/yolo-detection-steps.png" alt="object detection steps"></a><span class="caption">object detection steps</span></div><div style="clear:both;"></div>

<p>通常而言，单级网络去除了 Proposals 的生成过程，直接由预设好的 Anchors 加上回归值（SSD），或者网络直接预测框的中心和宽高（YOLO），来给出图像内 BBox 的位置。且单级网络没有特征重采样的过程，始终是一个密集预测，这使得一些平衡正负样本或其它作用的采样方式无法使用。</p>
<p>此外，在两级网络中，对于一个位置上的一组 Anchors 或者一组 Proposals 的 类别 和 回归值，通常是由两个并行的全连接层分支给出的；而单级网络中，类别 和 Anchor 的回归值（或 BBox 的宽高）一般直接由一个预测卷积层给出，类别和回归值按照一定次序排列在输出特征的特定通道中。且通常一个点上只有一个位置预测，而不像两级网络一样，一个点上多个类别有对应的多个位置预测。</p>
<h1 id="table-of-contents">Table of Contents</h1><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Overview"><span class="toc-text">Overview</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#You-Only-Look-Once-Unified-Real-Time-Object-Detection"><span class="toc-text">You Only Look Once: Unified, Real-Time Object Detection</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Architecture"><span class="toc-text">Architecture</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Training-and-Inference"><span class="toc-text">Training and Inference</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Summary-and-Results"><span class="toc-text">Summary and Results</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#YOLO9000-Better-Faster-Stronger"><span class="toc-text">YOLO9000: Better, Faster, Stronger</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Architecture-1"><span class="toc-text">Architecture</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Train-YOLOv2"><span class="toc-text">Train YOLOv2</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Summary"><span class="toc-text">Summary</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Joint-train-on-object-detection-and-classification-YOLO9000"><span class="toc-text">Joint train on object detection and classification (YOLO9000)</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#YOLOv3-An-Incremental-Improvement"><span class="toc-text">YOLOv3: An Incremental Improvement</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Network"><span class="toc-text">Network</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Other-Improvements"><span class="toc-text">Other Improvements</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Results"><span class="toc-text">Results</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#YOLOv4-Optimal-Speed-and-Accuracy-of-Object-Detection"><span class="toc-text">YOLOv4: Optimal Speed and Accuracy of Object Detection</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Bag-of-freebies"><span class="toc-text">Bag of freebies</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Bag-of-specials"><span class="toc-text">Bag of specials</span></a></li></ol></li></ol>



<h1 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h1><p>以下速度数据均在 Titan X (Maxwell) 上测试，Tesla M40 基本是相同的 GPU。新一代构架的是 Titan X (Pascal)、Titan Xp、GTX 1080 Ti、Tesla P100 这些。Titan Volta (Titan V)、Tesla V100 是更加新一代。再就到目前的 Turing，Titan RTX 这些。</p>
<p>在 Pascal VOC 07 test 上，使用 07+12 训练</p>
<table>
<thead>
<tr>
<th align="center">名称</th>
<th align="center">速度（fps）</th>
<th align="center">精度（mAP）</th>
<th align="center">输入尺寸</th>
<th align="center">网络结构</th>
</tr>
</thead>
<tbody><tr>
<td align="center">YOLOv1</td>
<td align="center">45</td>
<td align="center">63.4%</td>
<td align="center">448 × 448</td>
<td align="center">Darknet-24</td>
</tr>
<tr>
<td align="center">Fast YOLOv1</td>
<td align="center">155</td>
<td align="center">52.7%</td>
<td align="center">448 × 448</td>
<td align="center">Darknet-9</td>
</tr>
<tr>
<td align="center">YOLOv2</td>
<td align="center">40</td>
<td align="center">78.6%</td>
<td align="center">544 × 544</td>
<td align="center">Darknet-19</td>
</tr>
<tr>
<td align="center">YOLOv2</td>
<td align="center">59</td>
<td align="center">77.8%</td>
<td align="center">480 × 480</td>
<td align="center">Darknet-19</td>
</tr>
<tr>
<td align="center">YOLOv2</td>
<td align="center">67</td>
<td align="center">76.8%</td>
<td align="center">416 × 416</td>
<td align="center">Darknet-19</td>
</tr>
<tr>
<td align="center">YOLOv2</td>
<td align="center">81</td>
<td align="center">73.7%</td>
<td align="center">352 × 352</td>
<td align="center">Darknet-19</td>
</tr>
<tr>
<td align="center">YOLOv2</td>
<td align="center">91</td>
<td align="center">69.0%</td>
<td align="center">288 × 288</td>
<td align="center">Darknet-19</td>
</tr>
</tbody></table>
<p>在 Pascal VOC 12 test 上，使用 07++12（即含 07 test）训练</p>
<table>
<thead>
<tr>
<th align="center">名称</th>
<th align="center">速度（fps）</th>
<th align="center">精度（mAP）</th>
<th align="center">输入尺寸</th>
<th align="center">网络结构</th>
</tr>
</thead>
<tbody><tr>
<td align="center">YOLOv1</td>
<td align="center">45</td>
<td align="center">57.9%</td>
<td align="center">448 × 448</td>
<td align="center">Darknet-24</td>
</tr>
<tr>
<td align="center">YOLOv2</td>
<td align="center">–</td>
<td align="center">73.4%</td>
<td align="center">–</td>
<td align="center">Darknet-19</td>
</tr>
</tbody></table>
<p>在 MS COCO test-dev 上，使用 2017 split (trainval35k) 训练</p>
<table>
<thead>
<tr>
<th align="center">名称</th>
<th align="center">速度（fps）</th>
<th align="center">精度（mAP）</th>
<th align="center">精度（mAP 50）</th>
<th align="center">输入尺寸</th>
<th align="center">网络结构</th>
</tr>
</thead>
<tbody><tr>
<td align="center">YOLOv2</td>
<td align="center">–</td>
<td align="center">21.6%</td>
<td align="center">44.0%</td>
<td align="center">–</td>
<td align="center">Darknet-19</td>
</tr>
<tr>
<td align="center">YOLOv3</td>
<td align="center">19.6</td>
<td align="center">33.0%</td>
<td align="center">57.9%</td>
<td align="center">608 × 608</td>
<td align="center">Darknet-53</td>
</tr>
<tr>
<td align="center">YOLOv3</td>
<td align="center">34.5</td>
<td align="center">31.0%</td>
<td align="center">55.3%</td>
<td align="center">416 × 416</td>
<td align="center">Darknet-53</td>
</tr>
<tr>
<td align="center">YOLOv3</td>
<td align="center">45.5</td>
<td align="center">28.2%</td>
<td align="center">51.5%</td>
<td align="center">320 × 320</td>
<td align="center">Darknet-53</td>
</tr>
<tr>
<td align="center">YOLOv4</td>
<td align="center">23</td>
<td align="center">43.5%</td>
<td align="center">65.7%</td>
<td align="center">608 × 608</td>
<td align="center">CSPDarknet-53</td>
</tr>
<tr>
<td align="center">YOLOv4</td>
<td align="center">31</td>
<td align="center">43.5%</td>
<td align="center">64.9%</td>
<td align="center">512 × 512</td>
<td align="center">CSPDarknet-53</td>
</tr>
<tr>
<td align="center">YOLOv4</td>
<td align="center">38</td>
<td align="center">43.5%</td>
<td align="center">62.8%</td>
<td align="center">416 × 416</td>
<td align="center">CSPDarknet-53</td>
</tr>
</tbody></table>
<h1 id="You-Only-Look-Once-Unified-Real-Time-Object-Detection"><a href="#You-Only-Look-Once-Unified-Real-Time-Object-Detection" class="headerlink" title="You Only Look Once: Unified, Real-Time Object Detection"></a>You Only Look Once: Unified, Real-Time Object Detection</h1><p>思想：缩放图片一次通过卷积神经网络同时得出位置和类别，这样速度快、中间步骤简单、基于一整张图所有信息而不是每个 Proposal 中部分信息进行检测。</p>
<h2 id="Architecture"><a href="#Architecture" class="headerlink" title="Architecture"></a>Architecture</h2><div class="figure center" style="width:;"><a class="fancybox" target="_blank" rel="noopener" href="https://d2y8c08sxwbp8v.cloudfront.net/2020-detection/yolo-prediction-model.png" title="YOLO prediction model" data-caption="YOLO prediction model" data-fancybox="default"><img class="fig-img" src="https://d2y8c08sxwbp8v.cloudfront.net/2020-detection/yolo-prediction-model.png" alt="YOLO prediction model"></a><span class="caption">YOLO prediction model</span></div><div style="clear:both;"></div>

<p>YOLO 的检测方法是将输入图划分成 S×S 个格子（Grid），每一个格子预测出 B 个框。如果一个物体的中心落在某一个格子内部，那么这个格子负责预测这个物体。一个格子首先要预测它负责预测的物体的类别概率，这是一个长度为 Class (C) 的数组。此外，对于一个格子内的每个框，都还要预测另外的 5 个值 <code>x, y, w, h, Pr*IoU</code>，前两个值 <code>x, y ∈ [0, 1]</code> 表示框的中心点相对于这个格子的偏移，<code>w, h</code> 表示这个框在原图尺寸上的宽长（相对值，归一化到 <code>[0, 1]</code>）。这样得到预测值之后，先应用偏移 <code>x, y</code> 找到框的中心点，再通过 <code>w, h</code> 即可作出一个框。最后一个值 <code>confidence = Pr(Object)*IoU</code> 表示框内有物体的概率乘以这个框和 GT 之间的 IoU，也就是说，如果这个框对应的是背景，那么这个值应该是 <code>0</code>，如果这个框对应的是前景，那么这个值应该是与对应前景 GT 的 IoU。</p>
<p>从上面我们可以看出：</p>
<ul>
<li><p>YOLO 所需要的整个输出为一个 <code>S × S × (B*5 + C)</code> 的 tensor，且这里 C 是前景的类别数，无需加上背景一类（例如对于 Pascal VOC，C&#x3D;20）。它无需两级检测网络的两个全连接分开输出类别和位置，也无需 Proposals 生成、特征重采样等过程。实验中，S&#x3D;7，B&#x3D;2。</p>
</li>
<li><p>每个格子预测的长度为 Class 的概率是一个条件概率，是在有物体下的概率，即 <code>Pr(Class_i|Object)</code>，所以在预测的时候，把这个和每个框内预测的概率相乘 <code>Pr(Class_i|Object) * Pr(Object) * IoU = Pr(Class_i) * IoU</code> 就得到对每个框的逐类别概率。这里与 R-CNN 等两级网络不同之处在于，两级网络中一般使用 C+1 类判断前背景，而 YOLO 使用框内一个额外概率值判断前背景。</p>
</li>
<li><p>得到的条件概率的意思是，以上图 class probability map 为例，每个格子取输出 tensor 对应的向量中的 class 分数的最大值对应的类别，就可以得到此图。最下方的红色是 C&#x3D;20 类中的一个类别，假设代表「飞机」。但是它并不表示这个格子就是「飞机」，而是，如果这个格子内有物体，那么这个格子内的物体的类别是「飞机」。而有没有物体，需要看上方图的 confidence，经提醒，这个图内的 98 个框（位置和大小反映 <code>x, y, w, h</code>）的粗细可能就代表这个 confidence 分数，只有 confidence 大的框，才认为里面有物体。</p>
</li>
</ul>
<p>下面看得到这个输出 tensor 的网络结构，YOLO 系列用了一个自创的网络结构，叫做 darknet，灵感源于 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1409.4842">GoogLeNet (Inception V1)</a>。在 YOLOv1 中，它有 24 层卷积层（加上 4 个池化层和 2 个全连接层），结构图如下。</p>
<div class="figure center" style="width:;"><a class="fancybox" target="_blank" rel="noopener" href="https://d2y8c08sxwbp8v.cloudfront.net/2020-detection/yolo-darknet-24.png" title="Darknet-24 (Unofficial name) Architecture" data-caption="Darknet-24 (Unofficial name) Architecture" data-fancybox="default"><img class="fig-img" src="https://d2y8c08sxwbp8v.cloudfront.net/2020-detection/yolo-darknet-24.png" alt="Darknet-24 (Unofficial name) Architecture"></a><span class="caption">Darknet-24 (Unofficial name) Architecture</span></div><div style="clear:both;"></div>

<p>这里没有使用 Inception Module，但是使用了同样的减少计算量的方法，即先用 1 × 1 reduction layer，再使用 3 × 3 convolutional layer。可以简单计算一下，在 1024 × 14 × 14 层，如果直接使用 1024 × 1024 × 3 × 3 卷积，计算量为 <code>(1024 × 14 × 14) × (1024 × 3 × 3) = 1849.7M</code>。而如果像图上结构一样先降维（可以理解为非线性映射到低维空间，可能联想到 PCA 虽然它是线性的）再卷积，计算量为 <code>(512 × 14 × 14) × (1024 × 1 × 1) + (1024 × 14 × 14) × (512 × 3 × 3) = 102.7M + 924.8M = 1027.5M</code>，接近于小到一半。这种 bottleneck 结构在现代 backbone 上很常见。</p>
<p>对于激活层，最后一层使用的是线性激活函数，其它层使用的是 leaky ReLU，<code>f(x) = 0.1x when x&lt;0</code>。</p>
<h2 id="Training-and-Inference"><a href="#Training-and-Inference" class="headerlink" title="Training and Inference"></a>Training and Inference</h2><p>首先在 ImageNet 上预训练前 20 层卷积，把后面替换为一个平均池化层和一个全连接层，输入尺寸为 224 × 224。训练好后改为 4 个卷积层和 2 个全连接层，输入尺寸改为 448 × 448。</p>
<p>Loss 函数选择为 sum-squared error，<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.663ex;" xmlns="http://www.w3.org/2000/svg" width="19.635ex" height="2.55ex" role="img" focusable="false" viewBox="0 -833.9 8678.5 1127.1" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-5-TEX-I-1D446" d="M308 24Q367 24 416 76T466 197Q466 260 414 284Q308 311 278 321T236 341Q176 383 176 462Q176 523 208 573T273 648Q302 673 343 688T407 704H418H425Q521 704 564 640Q565 640 577 653T603 682T623 704Q624 704 627 704T632 705Q645 705 645 698T617 577T585 459T569 456Q549 456 549 465Q549 471 550 475Q550 478 551 494T553 520Q553 554 544 579T526 616T501 641Q465 662 419 662Q362 662 313 616T263 510Q263 480 278 458T319 427Q323 425 389 408T456 390Q490 379 522 342T554 242Q554 216 546 186Q541 164 528 137T492 78T426 18T332 -20Q320 -22 298 -22Q199 -22 144 33L134 44L106 13Q83 -14 78 -18T65 -22Q52 -22 52 -14Q52 -11 110 221Q112 227 130 227H143Q149 221 149 216Q149 214 148 207T144 186T142 153Q144 114 160 87T203 47T255 29T308 24Z"></path><path id="MJX-5-TEX-I-1D438" d="M492 213Q472 213 472 226Q472 230 477 250T482 285Q482 316 461 323T364 330H312Q311 328 277 192T243 52Q243 48 254 48T334 46Q428 46 458 48T518 61Q567 77 599 117T670 248Q680 270 683 272Q690 274 698 274Q718 274 718 261Q613 7 608 2Q605 0 322 0H133Q31 0 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H757Q764 676 764 669Q764 664 751 557T737 447Q735 440 717 440H705Q698 445 698 453L701 476Q704 500 704 528Q704 558 697 578T678 609T643 625T596 632T532 634H485Q397 633 392 631Q388 629 386 622Q385 619 355 499T324 377Q347 376 372 376H398Q464 376 489 391T534 472Q538 488 540 490T557 493Q562 493 565 493T570 492T572 491T574 487T577 483L544 351Q511 218 508 216Q505 213 492 213Z"></path><path id="MJX-5-TEX-N-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path><path id="MJX-5-TEX-SO-2211" d="M61 748Q64 750 489 750H913L954 640Q965 609 976 579T993 533T999 516H979L959 517Q936 579 886 621T777 682Q724 700 655 705T436 710H319Q183 710 183 709Q186 706 348 484T511 259Q517 250 513 244L490 216Q466 188 420 134T330 27L149 -187Q149 -188 362 -188Q388 -188 436 -188T506 -189Q679 -189 778 -162T936 -43Q946 -27 959 6H999L913 -249L489 -250Q65 -250 62 -248Q56 -246 56 -239Q56 -234 118 -161Q186 -81 245 -11L428 206Q428 207 242 462L57 717L56 728Q56 744 61 748Z"></path><path id="MJX-5-TEX-I-1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path><path id="MJX-5-TEX-N-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path><path id="MJX-5-TEX-I-1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path><path id="MJX-5-TEX-N-2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path><path id="MJX-5-TEX-N-5E" d="M112 560L249 694L257 686Q387 562 387 560L361 531Q359 532 303 581L250 627L195 580Q182 569 169 557T148 538L140 532Q138 530 125 546L112 560Z"></path><path id="MJX-5-TEX-N-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path><path id="MJX-5-TEX-N-32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D446" xlink:href="#MJX-5-TEX-I-1D446"></use></g><g data-mml-node="mi" transform="translate(645,0)"><use data-c="1D446" xlink:href="#MJX-5-TEX-I-1D446"></use></g><g data-mml-node="mi" transform="translate(1290,0)"><use data-c="1D438" xlink:href="#MJX-5-TEX-I-1D438"></use></g><g data-mml-node="mo" transform="translate(2331.8,0)"><use data-c="3D" xlink:href="#MJX-5-TEX-N-3D"></use></g><g data-mml-node="munder" transform="translate(3387.6,0)"><g data-mml-node="mo"><use data-c="2211" xlink:href="#MJX-5-TEX-SO-2211"></use></g><g data-mml-node="mi" transform="translate(1089,-285.4) scale(0.707)"><use data-c="1D456" xlink:href="#MJX-5-TEX-I-1D456"></use></g></g><g data-mml-node="mo" transform="translate(4770.5,0)"><use data-c="28" xlink:href="#MJX-5-TEX-N-28"></use></g><g data-mml-node="msub" transform="translate(5159.5,0)"><g data-mml-node="mi"><use data-c="1D465" xlink:href="#MJX-5-TEX-I-1D465"></use></g><g data-mml-node="mi" transform="translate(605,-150) scale(0.707)"><use data-c="1D456" xlink:href="#MJX-5-TEX-I-1D456"></use></g></g><g data-mml-node="mo" transform="translate(6280.7,0)"><use data-c="2212" xlink:href="#MJX-5-TEX-N-2212"></use></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(7280.9,0)"><g data-mml-node="mover"><g data-mml-node="mi"><use data-c="1D465" xlink:href="#MJX-5-TEX-I-1D465"></use></g><g data-mml-node="mo" transform="translate(313.8,16) translate(-250 0)"><use data-c="5E" xlink:href="#MJX-5-TEX-N-5E"></use></g></g></g><g data-mml-node="msup" transform="translate(7852.9,0)"><g data-mml-node="mo"><use data-c="29" xlink:href="#MJX-5-TEX-N-29"></use></g><g data-mml-node="mn" transform="translate(422,363) scale(0.707)"><use data-c="32" xlink:href="#MJX-5-TEX-N-32"></use></g></g></g></g></svg></mjx-container>。这有几个不平衡的问题：</p>
<ol>
<li><p>位置预测和类别预测是相等权重的；</p>
</li>
<li><p>对于不含任何物体的格子，即负样本总是多于正样本的，所以 confidence 分数（每个 BBox 的第五个预测参数）会趋向于 <code>0</code>；</p>
</li>
<li><p>大物体和小物体位置预测错误的权重是相等的，对于大物体，相同数量的位置偏移在 Loss 上的反映应当小于小物体的，因为对于 IoU 的影响会更小。</p>
</li>
</ol>
<p>对于前两个问题，通过增加权重 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.667ex;" xmlns="http://www.w3.org/2000/svg" width="21.206ex" height="2.237ex" role="img" focusable="false" viewBox="0 -694 9373 989" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-5-TEX-I-1D706" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z"></path><path id="MJX-5-TEX-N-63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z"></path><path id="MJX-5-TEX-N-6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z"></path><path id="MJX-5-TEX-N-72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z"></path><path id="MJX-5-TEX-N-64" d="M376 495Q376 511 376 535T377 568Q377 613 367 624T316 637H298V660Q298 683 300 683L310 684Q320 685 339 686T376 688Q393 689 413 690T443 693T454 694H457V390Q457 84 458 81Q461 61 472 55T517 46H535V0Q533 0 459 -5T380 -11H373V44L365 37Q307 -11 235 -11Q158 -11 96 50T34 215Q34 315 97 378T244 442Q319 442 376 393V495ZM373 342Q328 405 260 405Q211 405 173 369Q146 341 139 305T131 211Q131 155 138 120T173 59Q203 26 251 26Q322 26 373 103V342Z"></path><path id="MJX-5-TEX-N-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path><path id="MJX-5-TEX-N-35" d="M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z"></path><path id="MJX-5-TEX-N-2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path><path id="MJX-5-TEX-N-A0" d=""></path><path id="MJX-5-TEX-N-6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z"></path><path id="MJX-5-TEX-N-62" d="M307 -11Q234 -11 168 55L158 37Q156 34 153 28T147 17T143 10L138 1L118 0H98V298Q98 599 97 603Q94 622 83 628T38 637H20V660Q20 683 22 683L32 684Q42 685 61 686T98 688Q115 689 135 690T165 693T176 694H179V543Q179 391 180 391L183 394Q186 397 192 401T207 411T228 421T254 431T286 439T323 442Q401 442 461 379T522 216Q522 115 458 52T307 -11ZM182 98Q182 97 187 90T196 79T206 67T218 55T233 44T250 35T271 29T295 26Q330 26 363 46T412 113Q424 148 424 212Q424 287 412 323Q385 405 300 405Q270 405 239 390T188 347L182 339V98Z"></path><path id="MJX-5-TEX-N-6A" d="M98 609Q98 637 116 653T160 669Q183 667 200 652T217 609Q217 579 200 564T158 549Q133 549 116 564T98 609ZM28 -163Q58 -168 64 -168Q124 -168 135 -77Q137 -65 137 141T136 353Q132 371 120 377T72 385H52V408Q52 431 54 431L58 432Q62 432 70 432T87 433T108 434T133 436Q151 437 171 438T202 441T214 442H218V184Q217 -36 217 -59T211 -98Q195 -145 153 -175T58 -205Q9 -205 -23 -179T-55 -117Q-55 -94 -40 -79T-2 -64T36 -79T52 -118Q52 -143 28 -163Z"></path><path id="MJX-5-TEX-N-2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><use data-c="1D706" xlink:href="#MJX-5-TEX-I-1D706"></use></g><g data-mml-node="mtext" transform="translate(616,-150) scale(0.707)"><use data-c="63" xlink:href="#MJX-5-TEX-N-63"></use><use data-c="6F" xlink:href="#MJX-5-TEX-N-6F" transform="translate(444,0)"></use><use data-c="6F" xlink:href="#MJX-5-TEX-N-6F" transform="translate(944,0)"></use><use data-c="72" xlink:href="#MJX-5-TEX-N-72" transform="translate(1444,0)"></use><use data-c="64" xlink:href="#MJX-5-TEX-N-64" transform="translate(1836,0)"></use></g></g><g data-mml-node="mo" transform="translate(2635.2,0)"><use data-c="3D" xlink:href="#MJX-5-TEX-N-3D"></use></g><g data-mml-node="mn" transform="translate(3691,0)"><use data-c="35" xlink:href="#MJX-5-TEX-N-35"></use></g><g data-mml-node="mo" transform="translate(4191,0)"><use data-c="2C" xlink:href="#MJX-5-TEX-N-2C"></use></g><g data-mml-node="mtext" transform="translate(4635.6,0)"><use data-c="A0" xlink:href="#MJX-5-TEX-N-A0"></use></g><g data-mml-node="msub" transform="translate(4885.6,0)"><g data-mml-node="mi"><use data-c="1D706" xlink:href="#MJX-5-TEX-I-1D706"></use></g><g data-mml-node="mtext" transform="translate(616,-150) scale(0.707)"><use data-c="6E" xlink:href="#MJX-5-TEX-N-6E"></use><use data-c="6F" xlink:href="#MJX-5-TEX-N-6F" transform="translate(556,0)"></use><use data-c="6F" xlink:href="#MJX-5-TEX-N-6F" transform="translate(1056,0)"></use><use data-c="62" xlink:href="#MJX-5-TEX-N-62" transform="translate(1556,0)"></use><use data-c="6A" xlink:href="#MJX-5-TEX-N-6A" transform="translate(2112,0)"></use></g></g><g data-mml-node="mo" transform="translate(7539.2,0)"><use data-c="3D" xlink:href="#MJX-5-TEX-N-3D"></use></g><g data-mml-node="mn" transform="translate(8595,0)"><use data-c="2E" xlink:href="#MJX-5-TEX-N-2E"></use><use data-c="35" xlink:href="#MJX-5-TEX-N-35" transform="translate(278,0)"></use></g></g></g></svg></mjx-container> 来解决。第三个问题，通过预测 BBox 宽高的平方根来解决。</p>
<p>还有一个关于 GT 的问题是，一个格子负责预测中心点落在其内的物体，但一个格子预测了 B 个 BBox，我们只希望一个 BBox Predictor 负责一个物体。所以在训练时，只有预测出的框的与 GT 的 IoU 最大的那个 BBox 认为是有物体的（正样本）。所以这里与 R-CNN 系列两级网络不同，在那里一个 GT 是可以匹配到多个预测框的。作者这么设计意图是让每个 Predictor 专门化，专注于一种尺寸、长宽比或类别的物体。</p>
<p>整个损失函数如下：</p>
<mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -13.721ex;" xmlns="http://www.w3.org/2000/svg" width="79.5ex" height="28.573ex" role="img" focusable="false" viewBox="0 -6564.7 35138.9 12629.3" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-5-TEX-I-1D706" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z"></path><path id="MJX-5-TEX-N-63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z"></path><path id="MJX-5-TEX-N-6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z"></path><path id="MJX-5-TEX-N-72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z"></path><path id="MJX-5-TEX-N-64" d="M376 495Q376 511 376 535T377 568Q377 613 367 624T316 637H298V660Q298 683 300 683L310 684Q320 685 339 686T376 688Q393 689 413 690T443 693T454 694H457V390Q457 84 458 81Q461 61 472 55T517 46H535V0Q533 0 459 -5T380 -11H373V44L365 37Q307 -11 235 -11Q158 -11 96 50T34 215Q34 315 97 378T244 442Q319 442 376 393V495ZM373 342Q328 405 260 405Q211 405 173 369Q146 341 139 305T131 211Q131 155 138 120T173 59Q203 26 251 26Q322 26 373 103V342Z"></path><path id="MJX-5-TEX-LO-2211" d="M60 948Q63 950 665 950H1267L1325 815Q1384 677 1388 669H1348L1341 683Q1320 724 1285 761Q1235 809 1174 838T1033 881T882 898T699 902H574H543H251L259 891Q722 258 724 252Q725 250 724 246Q721 243 460 -56L196 -356Q196 -357 407 -357Q459 -357 548 -357T676 -358Q812 -358 896 -353T1063 -332T1204 -283T1307 -196Q1328 -170 1348 -124H1388Q1388 -125 1381 -145T1356 -210T1325 -294L1267 -449L666 -450Q64 -450 61 -448Q55 -446 55 -439Q55 -437 57 -433L590 177Q590 178 557 222T452 366T322 544L56 909L55 924Q55 945 60 948Z"></path><path id="MJX-5-TEX-I-1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path><path id="MJX-5-TEX-N-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path><path id="MJX-5-TEX-N-30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path id="MJX-5-TEX-I-1D446" d="M308 24Q367 24 416 76T466 197Q466 260 414 284Q308 311 278 321T236 341Q176 383 176 462Q176 523 208 573T273 648Q302 673 343 688T407 704H418H425Q521 704 564 640Q565 640 577 653T603 682T623 704Q624 704 627 704T632 705Q645 705 645 698T617 577T585 459T569 456Q549 456 549 465Q549 471 550 475Q550 478 551 494T553 520Q553 554 544 579T526 616T501 641Q465 662 419 662Q362 662 313 616T263 510Q263 480 278 458T319 427Q323 425 389 408T456 390Q490 379 522 342T554 242Q554 216 546 186Q541 164 528 137T492 78T426 18T332 -20Q320 -22 298 -22Q199 -22 144 33L134 44L106 13Q83 -14 78 -18T65 -22Q52 -22 52 -14Q52 -11 110 221Q112 227 130 227H143Q149 221 149 216Q149 214 148 207T144 186T142 153Q144 114 160 87T203 47T255 29T308 24Z"></path><path id="MJX-5-TEX-N-32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path><path id="MJX-5-TEX-I-1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path><path id="MJX-5-TEX-I-1D435" d="M231 637Q204 637 199 638T194 649Q194 676 205 682Q206 683 335 683Q594 683 608 681Q671 671 713 636T756 544Q756 480 698 429T565 360L555 357Q619 348 660 311T702 219Q702 146 630 78T453 1Q446 0 242 0Q42 0 39 2Q35 5 35 10Q35 17 37 24Q42 43 47 45Q51 46 62 46H68Q95 46 128 49Q142 52 147 61Q150 65 219 339T288 628Q288 635 231 637ZM649 544Q649 574 634 600T585 634Q578 636 493 637Q473 637 451 637T416 636H403Q388 635 384 626Q382 622 352 506Q352 503 351 500L320 374H401Q482 374 494 376Q554 386 601 434T649 544ZM595 229Q595 273 572 302T512 336Q506 337 429 337Q311 337 310 336Q310 334 293 263T258 122L240 52Q240 48 252 48T333 46Q422 46 429 47Q491 54 543 105T595 229Z"></path><path id="MJX-5-TEX-D-1D540" d="M20 666Q20 676 31 683H358Q369 676 369 666Q369 648 331 648Q288 645 282 632Q278 626 278 341Q278 57 282 50Q286 42 295 40T331 35Q369 35 369 16Q369 6 358 -1H31Q20 4 20 16Q20 35 58 35Q84 37 93 39T107 50Q113 60 113 341Q113 623 107 632Q101 645 58 648Q20 648 20 666ZM249 35Q246 40 246 41T244 54T242 83T242 139V341Q242 632 244 639L249 648H140Q146 634 147 596T149 341Q149 124 148 86T140 35H249Z"></path><path id="MJX-5-TEX-N-62" d="M307 -11Q234 -11 168 55L158 37Q156 34 153 28T147 17T143 10L138 1L118 0H98V298Q98 599 97 603Q94 622 83 628T38 637H20V660Q20 683 22 683L32 684Q42 685 61 686T98 688Q115 689 135 690T165 693T176 694H179V543Q179 391 180 391L183 394Q186 397 192 401T207 411T228 421T254 431T286 439T323 442Q401 442 461 379T522 216Q522 115 458 52T307 -11ZM182 98Q182 97 187 90T196 79T206 67T218 55T233 44T250 35T271 29T295 26Q330 26 363 46T412 113Q424 148 424 212Q424 287 412 323Q385 405 300 405Q270 405 239 390T188 347L182 339V98Z"></path><path id="MJX-5-TEX-N-6A" d="M98 609Q98 637 116 653T160 669Q183 667 200 652T217 609Q217 579 200 564T158 549Q133 549 116 564T98 609ZM28 -163Q58 -168 64 -168Q124 -168 135 -77Q137 -65 137 141T136 353Q132 371 120 377T72 385H52V408Q52 431 54 431L58 432Q62 432 70 432T87 433T108 434T133 436Q151 437 171 438T202 441T214 442H218V184Q217 -36 217 -59T211 -98Q195 -145 153 -175T58 -205Q9 -205 -23 -179T-55 -117Q-55 -94 -40 -79T-2 -64T36 -79T52 -118Q52 -143 28 -163Z"></path><path id="MJX-5-TEX-N-22C5" d="M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z"></path><path id="MJX-5-TEX-S3-28" d="M701 -940Q701 -943 695 -949H664Q662 -947 636 -922T591 -879T537 -818T475 -737T412 -636T350 -511T295 -362T250 -186T221 17T209 251Q209 962 573 1361Q596 1386 616 1405T649 1437T664 1450H695Q701 1444 701 1441Q701 1436 681 1415T629 1356T557 1261T476 1118T400 927T340 675T308 359Q306 321 306 250Q306 -139 400 -430T690 -924Q701 -936 701 -940Z"></path><path id="MJX-5-TEX-N-5B" d="M118 -250V750H255V710H158V-210H255V-250H118Z"></path><path id="MJX-5-TEX-N-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path><path id="MJX-5-TEX-I-1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path><path id="MJX-5-TEX-N-2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path><path id="MJX-5-TEX-N-5E" d="M112 560L249 694L257 686Q387 562 387 560L361 531Q359 532 303 581L250 627L195 580Q182 569 169 557T148 538L140 532Q138 530 125 546L112 560Z"></path><path id="MJX-5-TEX-N-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path><path id="MJX-5-TEX-N-2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path><path id="MJX-5-TEX-I-1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path><path id="MJX-5-TEX-N-5D" d="M22 710V750H159V-250H22V-210H119V710H22Z"></path><path id="MJX-5-TEX-N-221A" d="M95 178Q89 178 81 186T72 200T103 230T169 280T207 309Q209 311 212 311H213Q219 311 227 294T281 177Q300 134 312 108L397 -77Q398 -77 501 136T707 565T814 786Q820 800 834 800Q841 800 846 794T853 782V776L620 293L385 -193Q381 -200 366 -200Q357 -200 354 -197Q352 -195 256 15L160 225L144 214Q129 202 113 190T95 178Z"></path><path id="MJX-5-TEX-I-1D464" d="M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z"></path><path id="MJX-5-TEX-SO-221A" d="M263 249Q264 249 315 130T417 -108T470 -228L725 302Q981 837 982 839Q989 850 1001 850Q1008 850 1013 844T1020 832V826L741 243Q645 43 540 -176Q479 -303 469 -324T453 -348Q449 -350 436 -350L424 -349L315 -96Q206 156 205 156L171 130Q138 104 137 104L111 130L263 249Z"></path><path id="MJX-5-TEX-I-210E" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path><path id="MJX-5-TEX-LO-221A" d="M1001 1150Q1017 1150 1020 1132Q1020 1127 741 244L460 -643Q453 -650 436 -650H424Q423 -647 423 -645T421 -640T419 -631T415 -617T408 -594T399 -560T385 -512T367 -448T343 -364T312 -259L203 119L138 41L111 67L212 188L264 248L472 -474L983 1140Q988 1150 1001 1150Z"></path><path id="MJX-5-TEX-S3-29" d="M34 1438Q34 1446 37 1448T50 1450H56H71Q73 1448 99 1423T144 1380T198 1319T260 1238T323 1137T385 1013T440 864T485 688T514 485T526 251Q526 134 519 53Q472 -519 162 -860Q139 -885 119 -904T86 -936T71 -949H56Q43 -949 39 -947T34 -937Q88 -883 140 -813Q428 -430 428 251Q428 453 402 628T338 922T245 1146T145 1309T46 1425Q44 1427 42 1429T39 1433T36 1436L34 1438Z"></path><path id="MJX-5-TEX-I-1D436" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q484 659 454 652T382 628T299 572T226 479Q194 422 175 346T156 222Q156 108 232 58Q280 24 350 24Q441 24 512 92T606 240Q610 253 612 255T628 257Q648 257 648 248Q648 243 647 239Q618 132 523 55T319 -22Q206 -22 128 53T50 252Z"></path><path id="MJX-5-TEX-N-6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z"></path><path id="MJX-5-TEX-I-1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path><path id="MJX-5-TEX-N-2208" d="M84 250Q84 372 166 450T360 539Q361 539 377 539T419 540T469 540H568Q583 532 583 520Q583 511 570 501L466 500Q355 499 329 494Q280 482 242 458T183 409T147 354T129 306T124 272V270H568Q583 262 583 250T568 230H124V228Q124 207 134 177T167 112T231 48T328 7Q355 1 466 0H570Q583 -10 583 -20Q583 -32 568 -40H471Q464 -40 446 -40T417 -41Q262 -41 172 45Q84 127 84 250Z"></path><path id="MJX-5-TEX-N-6C" d="M42 46H56Q95 46 103 60V68Q103 77 103 91T103 124T104 167T104 217T104 272T104 329Q104 366 104 407T104 482T104 542T103 586T103 603Q100 622 89 628T44 637H26V660Q26 683 28 683L38 684Q48 685 67 686T104 688Q121 689 141 690T171 693T182 694H185V379Q185 62 186 60Q190 52 198 49Q219 46 247 46H263V0H255L232 1Q209 2 183 2T145 3T107 3T57 1L34 0H26V46H42Z"></path><path id="MJX-5-TEX-N-61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z"></path><path id="MJX-5-TEX-N-73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z"></path><path id="MJX-5-TEX-N-65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z"></path><path id="MJX-5-TEX-SO-28" d="M152 251Q152 646 388 850H416Q422 844 422 841Q422 837 403 816T357 753T302 649T255 482T236 250Q236 124 255 19T301 -147T356 -251T403 -315T422 -340Q422 -343 416 -349H388Q359 -325 332 -296T271 -213T212 -97T170 56T152 251Z"></path><path id="MJX-5-TEX-I-1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path><path id="MJX-5-TEX-SO-29" d="M305 251Q305 -145 69 -349H56Q43 -349 39 -347T35 -338Q37 -333 60 -307T108 -239T160 -136T204 27T221 250T204 473T160 636T108 740T60 807T35 839Q35 850 50 850H56H69Q197 743 256 566Q305 425 305 251Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mtable"><g data-mml-node="mtr" transform="translate(0,4725)"><g data-mml-node="mtd"></g><g data-mml-node="mtd"><g data-mml-node="msub"><g data-mml-node="mi"><use data-c="1D706" xlink:href="#MJX-5-TEX-I-1D706"></use></g><g data-mml-node="mtext" transform="translate(616,-150) scale(0.707)"><use data-c="63" xlink:href="#MJX-5-TEX-N-63"></use><use data-c="6F" xlink:href="#MJX-5-TEX-N-6F" transform="translate(444,0)"></use><use data-c="6F" xlink:href="#MJX-5-TEX-N-6F" transform="translate(944,0)"></use><use data-c="72" xlink:href="#MJX-5-TEX-N-72" transform="translate(1444,0)"></use><use data-c="64" xlink:href="#MJX-5-TEX-N-64" transform="translate(1836,0)"></use></g></g><g data-mml-node="munderover" transform="translate(2524.1,0)"><g data-mml-node="mo"><use data-c="2211" xlink:href="#MJX-5-TEX-LO-2211"></use></g><g data-mml-node="TeXAtom" transform="translate(148.2,-1087.9) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="1D456" xlink:href="#MJX-5-TEX-I-1D456"></use></g><g data-mml-node="mo" transform="translate(345,0)"><use data-c="3D" xlink:href="#MJX-5-TEX-N-3D"></use></g><g data-mml-node="mn" transform="translate(1123,0)"><use data-c="30" xlink:href="#MJX-5-TEX-N-30"></use></g></g><g data-mml-node="TeXAtom" transform="translate(321.4,1150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="msup"><g data-mml-node="mi"><use data-c="1D446" xlink:href="#MJX-5-TEX-I-1D446"></use></g><g data-mml-node="mn" transform="translate(729.6,363) scale(0.707)"><use data-c="32" xlink:href="#MJX-5-TEX-N-32"></use></g></g></g></g><g data-mml-node="munderover" transform="translate(4134.7,0)"><g data-mml-node="mo"><use data-c="2211" xlink:href="#MJX-5-TEX-LO-2211"></use></g><g data-mml-node="TeXAtom" transform="translate(124.5,-1087.9) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="1D457" xlink:href="#MJX-5-TEX-I-1D457"></use></g><g data-mml-node="mo" transform="translate(412,0)"><use data-c="3D" xlink:href="#MJX-5-TEX-N-3D"></use></g><g data-mml-node="mn" transform="translate(1190,0)"><use data-c="30" xlink:href="#MJX-5-TEX-N-30"></use></g></g><g data-mml-node="mi" transform="translate(453.7,1150) scale(0.707)"><use data-c="1D435" xlink:href="#MJX-5-TEX-I-1D435"></use></g></g><g data-mml-node="msubsup" transform="translate(5745.4,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="1D540" xlink:href="#MJX-5-TEX-D-1D540"></use></g></g><g data-mml-node="TeXAtom" transform="translate(422,498.6) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><use data-c="6F" xlink:href="#MJX-5-TEX-N-6F"></use><use data-c="62" xlink:href="#MJX-5-TEX-N-62" transform="translate(500,0)"></use><use data-c="6A" xlink:href="#MJX-5-TEX-N-6A" transform="translate(1056,0)"></use></g></g><g data-mml-node="TeXAtom" transform="translate(422,-293.8) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="1D456" xlink:href="#MJX-5-TEX-I-1D456"></use></g><g data-mml-node="mi" transform="translate(345,0)"><use data-c="1D457" xlink:href="#MJX-5-TEX-I-1D457"></use></g></g></g><g data-mml-node="mo" transform="translate(7402.7,0)"><use data-c="22C5" xlink:href="#MJX-5-TEX-N-22C5"></use></g><g data-mml-node="mrow" transform="translate(7902.9,0)"><g data-mml-node="mo" transform="translate(0 -0.5)"><use data-c="28" xlink:href="#MJX-5-TEX-S3-28"></use></g><g data-mml-node="mo" transform="translate(736,0)"><use data-c="5B" xlink:href="#MJX-5-TEX-N-5B"></use></g><g data-mml-node="mo" transform="translate(1014,0)"><use data-c="28" xlink:href="#MJX-5-TEX-N-28"></use></g><g data-mml-node="msub" transform="translate(1403,0)"><g data-mml-node="mi"><use data-c="1D465" xlink:href="#MJX-5-TEX-I-1D465"></use></g><g data-mml-node="mi" transform="translate(605,-150) scale(0.707)"><use data-c="1D456" xlink:href="#MJX-5-TEX-I-1D456"></use></g></g><g data-mml-node="mo" transform="translate(2524.2,0)"><use data-c="2212" xlink:href="#MJX-5-TEX-N-2212"></use></g><g data-mml-node="msub" transform="translate(3524.4,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mover"><g data-mml-node="mi"><use data-c="1D465" xlink:href="#MJX-5-TEX-I-1D465"></use></g><g data-mml-node="mo" transform="translate(313.8,16) translate(-250 0)"><use data-c="5E" xlink:href="#MJX-5-TEX-N-5E"></use></g></g></g><g data-mml-node="mi" transform="translate(605,-150) scale(0.707)"><use data-c="1D456" xlink:href="#MJX-5-TEX-I-1D456"></use></g></g><g data-mml-node="msup" transform="translate(4423.3,0)"><g data-mml-node="mo"><use data-c="29" xlink:href="#MJX-5-TEX-N-29"></use></g><g data-mml-node="mn" transform="translate(422,413) scale(0.707)"><use data-c="32" xlink:href="#MJX-5-TEX-N-32"></use></g></g><g data-mml-node="mo" transform="translate(5471.1,0)"><use data-c="2B" xlink:href="#MJX-5-TEX-N-2B"></use></g><g data-mml-node="mo" transform="translate(6471.3,0)"><use data-c="28" xlink:href="#MJX-5-TEX-N-28"></use></g><g data-mml-node="msub" transform="translate(6860.3,0)"><g data-mml-node="mi"><use data-c="1D466" xlink:href="#MJX-5-TEX-I-1D466"></use></g><g data-mml-node="mi" transform="translate(523,-150) scale(0.707)"><use data-c="1D456" xlink:href="#MJX-5-TEX-I-1D456"></use></g></g><g data-mml-node="mo" transform="translate(7899.5,0)"><use data-c="2212" xlink:href="#MJX-5-TEX-N-2212"></use></g><g data-mml-node="msub" transform="translate(8899.7,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mover"><g data-mml-node="mi"><use data-c="1D466" xlink:href="#MJX-5-TEX-I-1D466"></use></g><g data-mml-node="mo" transform="translate(300.6,16) translate(-250 0)"><use data-c="5E" xlink:href="#MJX-5-TEX-N-5E"></use></g></g></g><g data-mml-node="mi" transform="translate(523,-150) scale(0.707)"><use data-c="1D456" xlink:href="#MJX-5-TEX-I-1D456"></use></g></g><g data-mml-node="msup" transform="translate(9716.7,0)"><g data-mml-node="mo"><use data-c="29" xlink:href="#MJX-5-TEX-N-29"></use></g><g data-mml-node="mn" transform="translate(422,413) scale(0.707)"><use data-c="32" xlink:href="#MJX-5-TEX-N-32"></use></g></g><g data-mml-node="mo" transform="translate(10542.2,0)"><use data-c="5D" xlink:href="#MJX-5-TEX-N-5D"></use></g><g data-mml-node="mo" transform="translate(11042.5,0)"><use data-c="2B" xlink:href="#MJX-5-TEX-N-2B"></use></g><g data-mml-node="mo" transform="translate(12042.7,0)"><use data-c="5B" xlink:href="#MJX-5-TEX-N-5B"></use></g><g data-mml-node="mo" transform="translate(12320.7,0)"><use data-c="28" xlink:href="#MJX-5-TEX-N-28"></use></g><g data-mml-node="msqrt" transform="translate(12709.7,0)"><g transform="translate(853,0)"><g data-mml-node="msub"><g data-mml-node="mi"><use data-c="1D464" xlink:href="#MJX-5-TEX-I-1D464"></use></g><g data-mml-node="mi" transform="translate(749,-150) scale(0.707)"><use data-c="1D456" xlink:href="#MJX-5-TEX-I-1D456"></use></g></g></g><g data-mml-node="mo" transform="translate(0,-42.1)"><use data-c="221A" xlink:href="#MJX-5-TEX-N-221A"></use></g><rect width="1043" height="60" x="853" y="697.9"></rect></g><g data-mml-node="mo" transform="translate(14827.9,0)"><use data-c="2212" xlink:href="#MJX-5-TEX-N-2212"></use></g><g data-mml-node="msqrt" transform="translate(15828.1,0)"><g transform="translate(1020,0)"><g data-mml-node="msub"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mover"><g data-mml-node="mi"><use data-c="1D464" xlink:href="#MJX-5-TEX-I-1D464"></use></g><g data-mml-node="mo" transform="translate(441.3,17) translate(-250 0)"><use data-c="5E" xlink:href="#MJX-5-TEX-N-5E"></use></g></g></g><g data-mml-node="mi" transform="translate(749,-150) scale(0.707)"><use data-c="1D456" xlink:href="#MJX-5-TEX-I-1D456"></use></g></g></g><g data-mml-node="mo" transform="translate(0,191.9)"><use data-c="221A" xlink:href="#MJX-5-TEX-SO-221A"></use></g><rect width="1043" height="60" x="1020" y="981.9"></rect></g><g data-mml-node="msup" transform="translate(17891,0)"><g data-mml-node="mo"><use data-c="29" xlink:href="#MJX-5-TEX-N-29"></use></g><g data-mml-node="mn" transform="translate(422,413) scale(0.707)"><use data-c="32" xlink:href="#MJX-5-TEX-N-32"></use></g></g><g data-mml-node="mo" transform="translate(18938.8,0)"><use data-c="2B" xlink:href="#MJX-5-TEX-N-2B"></use></g><g data-mml-node="mo" transform="translate(19939,0)"><use data-c="28" xlink:href="#MJX-5-TEX-N-28"></use></g><g data-mml-node="msqrt" transform="translate(20328,0)"><g transform="translate(1020,0)"><g data-mml-node="msub"><g data-mml-node="mi"><use data-c="210E" xlink:href="#MJX-5-TEX-I-210E"></use></g><g data-mml-node="mi" transform="translate(609,-150) scale(0.707)"><use data-c="1D456" xlink:href="#MJX-5-TEX-I-1D456"></use></g></g></g><g data-mml-node="mo" transform="translate(0,133.4)"><use data-c="221A" xlink:href="#MJX-5-TEX-SO-221A"></use></g><rect width="903" height="60" x="1020" y="923.4"></rect></g><g data-mml-node="mo" transform="translate(22473.2,0)"><use data-c="2212" xlink:href="#MJX-5-TEX-N-2212"></use></g><g data-mml-node="msqrt" transform="translate(23473.4,0)"><g transform="translate(1020,0)"><g data-mml-node="msub"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mover"><g data-mml-node="mi"><use data-c="210E" xlink:href="#MJX-5-TEX-I-210E"></use></g><g data-mml-node="mo" transform="translate(260.2,268) translate(-250 0)"><use data-c="5E" xlink:href="#MJX-5-TEX-N-5E"></use></g></g></g><g data-mml-node="mi" transform="translate(609,-150) scale(0.707)"><use data-c="1D456" xlink:href="#MJX-5-TEX-I-1D456"></use></g></g></g><g data-mml-node="mo" transform="translate(0,317.4)"><use data-c="221A" xlink:href="#MJX-5-TEX-LO-221A"></use></g><rect width="903" height="60" x="1020" y="1407.4"></rect></g><g data-mml-node="msup" transform="translate(25396.4,0)"><g data-mml-node="mo"><use data-c="29" xlink:href="#MJX-5-TEX-N-29"></use></g><g data-mml-node="mn" transform="translate(422,413) scale(0.707)"><use data-c="32" xlink:href="#MJX-5-TEX-N-32"></use></g></g><g data-mml-node="mo" transform="translate(26221.9,0)"><use data-c="5D" xlink:href="#MJX-5-TEX-N-5D"></use></g><g data-mml-node="mo" transform="translate(26499.9,0) translate(0 -0.5)"><use data-c="29" xlink:href="#MJX-5-TEX-S3-29"></use></g></g></g></g><g data-mml-node="mtr" transform="translate(0,2342.8)"><g data-mml-node="mtd"></g></g><g data-mml-node="mtr" transform="translate(0,-46.9)"><g data-mml-node="mtd"></g><g data-mml-node="mtd"><g data-mml-node="mi"></g><g data-mml-node="mo" transform="translate(222.2,0)"><use data-c="2B" xlink:href="#MJX-5-TEX-N-2B"></use></g><g data-mml-node="munderover" transform="translate(1222.4,0)"><g data-mml-node="mo"><use data-c="2211" xlink:href="#MJX-5-TEX-LO-2211"></use></g><g data-mml-node="TeXAtom" transform="translate(148.2,-1087.9) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="1D456" xlink:href="#MJX-5-TEX-I-1D456"></use></g><g data-mml-node="mo" transform="translate(345,0)"><use data-c="3D" xlink:href="#MJX-5-TEX-N-3D"></use></g><g data-mml-node="mn" transform="translate(1123,0)"><use data-c="30" xlink:href="#MJX-5-TEX-N-30"></use></g></g><g data-mml-node="TeXAtom" transform="translate(321.4,1150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="msup"><g data-mml-node="mi"><use data-c="1D446" xlink:href="#MJX-5-TEX-I-1D446"></use></g><g data-mml-node="mn" transform="translate(729.6,363) scale(0.707)"><use data-c="32" xlink:href="#MJX-5-TEX-N-32"></use></g></g></g></g><g data-mml-node="munderover" transform="translate(2833.1,0)"><g data-mml-node="mo"><use data-c="2211" xlink:href="#MJX-5-TEX-LO-2211"></use></g><g data-mml-node="TeXAtom" transform="translate(124.5,-1087.9) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="1D457" xlink:href="#MJX-5-TEX-I-1D457"></use></g><g data-mml-node="mo" transform="translate(412,0)"><use data-c="3D" xlink:href="#MJX-5-TEX-N-3D"></use></g><g data-mml-node="mn" transform="translate(1190,0)"><use data-c="30" xlink:href="#MJX-5-TEX-N-30"></use></g></g><g data-mml-node="mi" transform="translate(453.7,1150) scale(0.707)"><use data-c="1D435" xlink:href="#MJX-5-TEX-I-1D435"></use></g></g><g data-mml-node="msubsup" transform="translate(4443.8,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="1D540" xlink:href="#MJX-5-TEX-D-1D540"></use></g></g><g data-mml-node="TeXAtom" transform="translate(422,498.6) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><use data-c="6F" xlink:href="#MJX-5-TEX-N-6F"></use><use data-c="62" xlink:href="#MJX-5-TEX-N-62" transform="translate(500,0)"></use><use data-c="6A" xlink:href="#MJX-5-TEX-N-6A" transform="translate(1056,0)"></use></g></g><g data-mml-node="TeXAtom" transform="translate(422,-293.8) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="1D456" xlink:href="#MJX-5-TEX-I-1D456"></use></g><g data-mml-node="mi" transform="translate(345,0)"><use data-c="1D457" xlink:href="#MJX-5-TEX-I-1D457"></use></g></g></g><g data-mml-node="mo" transform="translate(6101.1,0)"><use data-c="22C5" xlink:href="#MJX-5-TEX-N-22C5"></use></g><g data-mml-node="mo" transform="translate(6601.3,0)"><use data-c="28" xlink:href="#MJX-5-TEX-N-28"></use></g><g data-mml-node="msub" transform="translate(6990.3,0)"><g data-mml-node="mi"><use data-c="1D436" xlink:href="#MJX-5-TEX-I-1D436"></use></g><g data-mml-node="mi" transform="translate(748,-150) scale(0.707)"><use data-c="1D456" xlink:href="#MJX-5-TEX-I-1D456"></use></g></g><g data-mml-node="mo" transform="translate(8254.5,0)"><use data-c="2212" xlink:href="#MJX-5-TEX-N-2212"></use></g><g data-mml-node="msub" transform="translate(9254.7,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mover"><g data-mml-node="mi"><use data-c="1D436" xlink:href="#MJX-5-TEX-I-1D436"></use></g><g data-mml-node="mo" transform="translate(474.5,279) translate(-250 0)"><use data-c="5E" xlink:href="#MJX-5-TEX-N-5E"></use></g></g></g><g data-mml-node="mi" transform="translate(748,-150) scale(0.707)"><use data-c="1D456" xlink:href="#MJX-5-TEX-I-1D456"></use></g></g><g data-mml-node="msup" transform="translate(10296.6,0)"><g data-mml-node="mo"><use data-c="29" xlink:href="#MJX-5-TEX-N-29"></use></g><g data-mml-node="mn" transform="translate(422,413) scale(0.707)"><use data-c="32" xlink:href="#MJX-5-TEX-N-32"></use></g></g><g data-mml-node="mo" transform="translate(11344.4,0)"><use data-c="2B" xlink:href="#MJX-5-TEX-N-2B"></use></g><g data-mml-node="msub" transform="translate(12344.6,0)"><g data-mml-node="mi"><use data-c="1D706" xlink:href="#MJX-5-TEX-I-1D706"></use></g><g data-mml-node="TeXAtom" transform="translate(616,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><use data-c="6E" xlink:href="#MJX-5-TEX-N-6E"></use><use data-c="6F" xlink:href="#MJX-5-TEX-N-6F" transform="translate(556,0)"></use><use data-c="6F" xlink:href="#MJX-5-TEX-N-6F" transform="translate(1056,0)"></use><use data-c="62" xlink:href="#MJX-5-TEX-N-62" transform="translate(1556,0)"></use><use data-c="6A" xlink:href="#MJX-5-TEX-N-6A" transform="translate(2112,0)"></use></g></g></g><g data-mml-node="munderover" transform="translate(14887.1,0)"><g data-mml-node="mo"><use data-c="2211" xlink:href="#MJX-5-TEX-LO-2211"></use></g><g data-mml-node="TeXAtom" transform="translate(148.2,-1087.9) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="1D456" xlink:href="#MJX-5-TEX-I-1D456"></use></g><g data-mml-node="mo" transform="translate(345,0)"><use data-c="3D" xlink:href="#MJX-5-TEX-N-3D"></use></g><g data-mml-node="mn" transform="translate(1123,0)"><use data-c="30" xlink:href="#MJX-5-TEX-N-30"></use></g></g><g data-mml-node="TeXAtom" transform="translate(321.4,1150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="msup"><g data-mml-node="mi"><use data-c="1D446" xlink:href="#MJX-5-TEX-I-1D446"></use></g><g data-mml-node="mn" transform="translate(729.6,363) scale(0.707)"><use data-c="32" xlink:href="#MJX-5-TEX-N-32"></use></g></g></g></g><g data-mml-node="munderover" transform="translate(16497.8,0)"><g data-mml-node="mo"><use data-c="2211" xlink:href="#MJX-5-TEX-LO-2211"></use></g><g data-mml-node="TeXAtom" transform="translate(124.5,-1087.9) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="1D457" xlink:href="#MJX-5-TEX-I-1D457"></use></g><g data-mml-node="mo" transform="translate(412,0)"><use data-c="3D" xlink:href="#MJX-5-TEX-N-3D"></use></g><g data-mml-node="mn" transform="translate(1190,0)"><use data-c="30" xlink:href="#MJX-5-TEX-N-30"></use></g></g><g data-mml-node="mi" transform="translate(453.7,1150) scale(0.707)"><use data-c="1D435" xlink:href="#MJX-5-TEX-I-1D435"></use></g></g><g data-mml-node="msubsup" transform="translate(18108.4,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="1D540" xlink:href="#MJX-5-TEX-D-1D540"></use></g></g><g data-mml-node="TeXAtom" transform="translate(422,498.6) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><use data-c="6E" xlink:href="#MJX-5-TEX-N-6E"></use><use data-c="6F" xlink:href="#MJX-5-TEX-N-6F" transform="translate(556,0)"></use><use data-c="6F" xlink:href="#MJX-5-TEX-N-6F" transform="translate(1056,0)"></use><use data-c="62" xlink:href="#MJX-5-TEX-N-62" transform="translate(1556,0)"></use><use data-c="6A" xlink:href="#MJX-5-TEX-N-6A" transform="translate(2112,0)"></use></g></g><g data-mml-node="TeXAtom" transform="translate(422,-293.8) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="1D456" xlink:href="#MJX-5-TEX-I-1D456"></use></g><g data-mml-node="mi" transform="translate(345,0)"><use data-c="1D457" xlink:href="#MJX-5-TEX-I-1D457"></use></g></g></g><g data-mml-node="mo" transform="translate(20512.4,0)"><use data-c="22C5" xlink:href="#MJX-5-TEX-N-22C5"></use></g><g data-mml-node="mo" transform="translate(21012.7,0)"><use data-c="28" xlink:href="#MJX-5-TEX-N-28"></use></g><g data-mml-node="msub" transform="translate(21401.7,0)"><g data-mml-node="mi"><use data-c="1D436" xlink:href="#MJX-5-TEX-I-1D436"></use></g><g data-mml-node="mi" transform="translate(748,-150) scale(0.707)"><use data-c="1D456" xlink:href="#MJX-5-TEX-I-1D456"></use></g></g><g data-mml-node="mo" transform="translate(22665.8,0)"><use data-c="2212" xlink:href="#MJX-5-TEX-N-2212"></use></g><g data-mml-node="msub" transform="translate(23666.1,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mover"><g data-mml-node="mi"><use data-c="1D436" xlink:href="#MJX-5-TEX-I-1D436"></use></g><g data-mml-node="mo" transform="translate(474.5,279) translate(-250 0)"><use data-c="5E" xlink:href="#MJX-5-TEX-N-5E"></use></g></g></g><g data-mml-node="mi" transform="translate(748,-150) scale(0.707)"><use data-c="1D456" xlink:href="#MJX-5-TEX-I-1D456"></use></g></g><g data-mml-node="msup" transform="translate(24708,0)"><g data-mml-node="mo"><use data-c="29" xlink:href="#MJX-5-TEX-N-29"></use></g><g data-mml-node="mn" transform="translate(422,413) scale(0.707)"><use data-c="32" xlink:href="#MJX-5-TEX-N-32"></use></g></g></g></g><g data-mml-node="mtr" transform="translate(0,-2429.1)"><g data-mml-node="mtd"></g></g><g data-mml-node="mtr" transform="translate(0,-4818.7)"><g data-mml-node="mtd"></g><g data-mml-node="mtd"><g data-mml-node="mi"></g><g data-mml-node="mo" transform="translate(222.2,0)"><use data-c="2B" xlink:href="#MJX-5-TEX-N-2B"></use></g><g data-mml-node="munderover" transform="translate(1222.4,0)"><g data-mml-node="mo"><use data-c="2211" xlink:href="#MJX-5-TEX-LO-2211"></use></g><g data-mml-node="TeXAtom" transform="translate(148.2,-1087.9) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="1D456" xlink:href="#MJX-5-TEX-I-1D456"></use></g><g data-mml-node="mo" transform="translate(345,0)"><use data-c="3D" xlink:href="#MJX-5-TEX-N-3D"></use></g><g data-mml-node="mn" transform="translate(1123,0)"><use data-c="30" xlink:href="#MJX-5-TEX-N-30"></use></g></g><g data-mml-node="TeXAtom" transform="translate(321.4,1150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="msup"><g data-mml-node="mi"><use data-c="1D446" xlink:href="#MJX-5-TEX-I-1D446"></use></g><g data-mml-node="mn" transform="translate(729.6,363) scale(0.707)"><use data-c="32" xlink:href="#MJX-5-TEX-N-32"></use></g></g></g></g><g data-mml-node="msubsup" transform="translate(2833.1,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="1D540" xlink:href="#MJX-5-TEX-D-1D540"></use></g></g><g data-mml-node="TeXAtom" transform="translate(422,498.6) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><use data-c="6F" xlink:href="#MJX-5-TEX-N-6F"></use><use data-c="62" xlink:href="#MJX-5-TEX-N-62" transform="translate(500,0)"></use><use data-c="6A" xlink:href="#MJX-5-TEX-N-6A" transform="translate(1056,0)"></use></g></g><g data-mml-node="TeXAtom" transform="translate(422,-293.8) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="1D456" xlink:href="#MJX-5-TEX-I-1D456"></use></g></g></g><g data-mml-node="munder" transform="translate(4434.9,0)"><g data-mml-node="mo" transform="translate(673.8,0)"><use data-c="2211" xlink:href="#MJX-5-TEX-LO-2211"></use></g><g data-mml-node="TeXAtom" transform="translate(0,-1107.7) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="1D450" xlink:href="#MJX-5-TEX-I-1D450"></use></g><g data-mml-node="mo" transform="translate(433,0)"><use data-c="2208" xlink:href="#MJX-5-TEX-N-2208"></use></g><g data-mml-node="mtext" transform="translate(1100,0)"><use data-c="63" xlink:href="#MJX-5-TEX-N-63"></use><use data-c="6C" xlink:href="#MJX-5-TEX-N-6C" transform="translate(444,0)"></use><use data-c="61" xlink:href="#MJX-5-TEX-N-61" transform="translate(722,0)"></use><use data-c="73" xlink:href="#MJX-5-TEX-N-73" transform="translate(1222,0)"></use><use data-c="73" xlink:href="#MJX-5-TEX-N-73" transform="translate(1616,0)"></use><use data-c="65" xlink:href="#MJX-5-TEX-N-65" transform="translate(2010,0)"></use><use data-c="73" xlink:href="#MJX-5-TEX-N-73" transform="translate(2454,0)"></use></g></g></g><g data-mml-node="msup" transform="translate(7393.2,0)"><g data-mml-node="mrow"><g data-mml-node="mo" transform="translate(0 -0.5)"><use data-c="28" xlink:href="#MJX-5-TEX-SO-28"></use></g><g data-mml-node="msub" transform="translate(458,0)"><g data-mml-node="mi"><use data-c="1D45D" xlink:href="#MJX-5-TEX-I-1D45D"></use></g><g data-mml-node="mi" transform="translate(536,-150) scale(0.707)"><use data-c="1D456" xlink:href="#MJX-5-TEX-I-1D456"></use></g></g><g data-mml-node="mo" transform="translate(1288,0)"><use data-c="28" xlink:href="#MJX-5-TEX-N-28"></use></g><g data-mml-node="mi" transform="translate(1677,0)"><use data-c="1D450" xlink:href="#MJX-5-TEX-I-1D450"></use></g><g data-mml-node="mo" transform="translate(2110,0)"><use data-c="29" xlink:href="#MJX-5-TEX-N-29"></use></g><g data-mml-node="mo" transform="translate(2721.2,0)"><use data-c="2212" xlink:href="#MJX-5-TEX-N-2212"></use></g><g data-mml-node="msub" transform="translate(3721.4,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mover"><g data-mml-node="mi"><use data-c="1D45D" xlink:href="#MJX-5-TEX-I-1D45D"></use></g><g data-mml-node="mo" transform="translate(334.8,16) translate(-250 0)"><use data-c="5E" xlink:href="#MJX-5-TEX-N-5E"></use></g></g></g><g data-mml-node="mi" transform="translate(536,-150) scale(0.707)"><use data-c="1D456" xlink:href="#MJX-5-TEX-I-1D456"></use></g></g><g data-mml-node="mo" transform="translate(4551.3,0)"><use data-c="28" xlink:href="#MJX-5-TEX-N-28"></use></g><g data-mml-node="mi" transform="translate(4940.3,0)"><use data-c="1D450" xlink:href="#MJX-5-TEX-I-1D450"></use></g><g data-mml-node="mo" transform="translate(5373.3,0)"><use data-c="29" xlink:href="#MJX-5-TEX-N-29"></use></g><g data-mml-node="mo" transform="translate(5762.3,0) translate(0 -0.5)"><use data-c="29" xlink:href="#MJX-5-TEX-SO-29"></use></g></g><g data-mml-node="mn" transform="translate(6253.3,576.6) scale(0.707)"><use data-c="32" xlink:href="#MJX-5-TEX-N-32"></use></g></g></g></g></g></g></g></svg></mjx-container>


<p>公式中第一行是 BBox 的位置和大小；第二行是 BBox 内的 <code>Pr*IoU</code>；第三行是每个格子内的类别概率，可以看到只有格子内有物体时才有这项 loss，这与之前的条件概率是对应的。<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0;" xmlns="http://www.w3.org/2000/svg" width="7.558ex" height="1.932ex" role="img" focusable="false" viewBox="0 -853.7 3340.7 853.7" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-5-TEX-D-1D540" d="M20 666Q20 676 31 683H358Q369 676 369 666Q369 648 331 648Q288 645 282 632Q278 626 278 341Q278 57 282 50Q286 42 295 40T331 35Q369 35 369 16Q369 6 358 -1H31Q20 4 20 16Q20 35 58 35Q84 37 93 39T107 50Q113 60 113 341Q113 623 107 632Q101 645 58 648Q20 648 20 666ZM249 35Q246 40 246 41T244 54T242 83T242 139V341Q242 632 244 639L249 648H140Q146 634 147 596T149 341Q149 124 148 86T140 35H249Z"></path><path id="MJX-5-TEX-N-63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z"></path><path id="MJX-5-TEX-N-6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z"></path><path id="MJX-5-TEX-N-6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z"></path><path id="MJX-5-TEX-N-64" d="M376 495Q376 511 376 535T377 568Q377 613 367 624T316 637H298V660Q298 683 300 683L310 684Q320 685 339 686T376 688Q393 689 413 690T443 693T454 694H457V390Q457 84 458 81Q461 61 472 55T517 46H535V0Q533 0 459 -5T380 -11H373V44L365 37Q307 -11 235 -11Q158 -11 96 50T34 215Q34 315 97 378T244 442Q319 442 376 393V495ZM373 342Q328 405 260 405Q211 405 173 369Q146 341 139 305T131 211Q131 155 138 120T173 59Q203 26 251 26Q322 26 373 103V342Z"></path><path id="MJX-5-TEX-N-69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z"></path><path id="MJX-5-TEX-N-74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msup"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="1D540" xlink:href="#MJX-5-TEX-D-1D540"></use></g></g><g data-mml-node="TeXAtom" transform="translate(422,363) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><use data-c="63" xlink:href="#MJX-5-TEX-N-63"></use><use data-c="6F" xlink:href="#MJX-5-TEX-N-6F" transform="translate(444,0)"></use><use data-c="6E" xlink:href="#MJX-5-TEX-N-6E" transform="translate(944,0)"></use><use data-c="64" xlink:href="#MJX-5-TEX-N-64" transform="translate(1500,0)"></use><use data-c="69" xlink:href="#MJX-5-TEX-N-69" transform="translate(2056,0)"></use><use data-c="74" xlink:href="#MJX-5-TEX-N-74" transform="translate(2334,0)"></use><use data-c="69" xlink:href="#MJX-5-TEX-N-69" transform="translate(2723,0)"></use><use data-c="6F" xlink:href="#MJX-5-TEX-N-6F" transform="translate(3001,0)"></use><use data-c="6E" xlink:href="#MJX-5-TEX-N-6E" transform="translate(3501,0)"></use></g></g></g></g></g></svg></mjx-container> 表示如果 <code>condition</code>，那么这个值为 <code>1</code>，否则为 <code>0</code>。</p>
<p><strong>训练细节：</strong></p>
<ol>
<li><p>epochs &#x3D; 135，batch size &#x3D; 64，momentum &#x3D; 0.9，weight decay &#x3D; 0.0005。</p>
</li>
<li><p>lr：第一个 epoch 从 10e-3 增加到 10e-2，继续保持 75 个 epochs，然后 10e-3 训练 30 个 epochs，最终 10e-4 训练 30 个 epochs。</p>
</li>
<li><p>第一个全连接层后加了一个 <code>.5</code> 的 Dropout 层防止过拟合。数据增强：20% 尺度的随机 translation 和 scaling，在 HSV 空间中 1.5x 的曝光和饱和度调整。</p>
</li>
</ol>
<p>对于测试，YOLO 设计为预测 98 个框，使用每个框内的第五个预测值决定是否留下这个框，类别使用格子预测的类别。对于一些大的物体，可能在多个格子内都给出接近的框，使用 NMS 可以增加 2% ～ 3% mAP。而对于 R-CNN 等基于区域分类的算法，NMS 是必不可少的。</p>
<h2 id="Summary-and-Results"><a href="#Summary-and-Results" class="headerlink" title="Summary and Results"></a>Summary and Results</h2><p>YOLO 的几个问题：</p>
<ol>
<li><p>对小物体效果不好；</p>
</li>
<li><p>YOLO 通过下采样后数据得出 BBox 的位置偏移和宽高，所以精度不高，同时对于一些罕见的长宽比或者尺寸的物体的效果不好；</p>
</li>
<li><p>loss 只是近似反映检测效果的好坏，比如对于不同大小的物体，<code>x, y, w, h</code> 的误差仍不能准确反映 IoU 的误差。YOLO 对于位置的预测较差，是降低 mAP 的主要原因。</p>
</li>
</ol>
<p>数据集使用 Pascal VOC 07+12。如果在 12 测试，那么 07 的 test 也被用于训练。在 07 的测试结果为 <code>63.4%</code> mAP，在 12 的测试结果为 <code>57.9%</code> mAP。</p>
<h1 id="YOLO9000-Better-Faster-Stronger"><a href="#YOLO9000-Better-Faster-Stronger" class="headerlink" title="YOLO9000: Better, Faster, Stronger"></a>YOLO9000: Better, Faster, Stronger</h1><p>改进：除了一些提高精度的，YOLOv2 还引入了 multi-scale training，所以它可在不同输入尺寸上工作，提供速度精度的 tradeoff。此外，提出了一种联合训练，可以同时在 COCO 和 ImageNet 上训练，网络可以学习检测那些没有在检测数据集中标注的类别。</p>
<h2 id="Architecture-1"><a href="#Architecture-1" class="headerlink" title="Architecture"></a>Architecture</h2><p>首先看网络，作者将网络减少了几层，提高了速度，同时加入了 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1502.03167">BN</a> 层，提高了精度。</p>
<div class="figure fig-50" style="width:;"><a class="fancybox" target="_blank" rel="noopener" href="https://d2y8c08sxwbp8v.cloudfront.net/2020-detection/yolo-darknet-19-classification.png" title="Darknet-19 for classification" data-caption="Darknet-19 for classification" data-fancybox="default"><img class="fig-img" src="https://d2y8c08sxwbp8v.cloudfront.net/2020-detection/yolo-darknet-19-classification.png" alt="Darknet-19 for classification"></a><span class="caption">Darknet-19 for classification</span></div>
<div class="figure fig-50" style="width:;"><a class="fancybox" target="_blank" rel="noopener" href="https://d2y8c08sxwbp8v.cloudfront.net/2020-detection/yolo-darknet-19-detection.png" title="Darknet-19 for detection" data-caption="Darknet-19 for detection" data-fancybox="default"><img class="fig-img" src="https://d2y8c08sxwbp8v.cloudfront.net/2020-detection/yolo-darknet-19-detection.png" alt="Darknet-19 for detection"></a><span class="caption">Darknet-19 for detection</span></div>
<div style="clear:both;"></div>

<p>整个网络（左图）含有 19 个卷积层和 5 个最大值池化层，不再有全连接层，网络的 output stride 减小了一倍变为 32。倒数第二层是 Global Average Pooling，出自 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1312.4400">Network in Network</a>，<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1409.4842">GoogLeNet</a> 中也使用了，方法是在每个特征图通道上进行平均池化。在每个卷积层之后都加了 BN 层，网络不再需要 Dropout 层。</p>
<p>对于检测（右图），网络输入尺寸也进行了改动，希望最终输出一个奇数尺寸，这样就会有一个中心点。所以 v2 中默认输入尺寸是 416 × 416，增减输入尺寸是以 64 为单位进行。一般一个大物体的中心会落在图像中心，所以这样可以用一个格子去预测它而不是四个格子。</p>
<p>左图这个网络是用于 ImageNet Classification 的，在预训练完后需要改成检测网络。方法是去掉最后 Convolutional、AvgPool、Softmax 三层，然后加上三层 1024 × 3 × 3 卷积，最后用一个 1 × 1 卷积进行预测，得到所需 <code>A × (5 + C) = 125</code> 通道（这里通道数与 YOLOv1 不同，见下文）。此外，这里还加入一个 passthrough layer，使得网络对于小物体的检测效果更好。注意这里论文里说的和实际上<a target="_blank" rel="noopener" href="https://github.com/pjreddie/darknet/blob/master/cfg/yolov2.cfg#L211-L217">代码</a>里做的有些不同：论文中是把最后一个 512 × 3 × 3 卷积的结果，尺寸为 26 × 26 × 512 feature map 转化为 13 × 13 × 2048，然后 concat（通道上的连接）到倒数第二个卷积（也就是最后一个 3 × 3 卷积）的结果上；实际代码中对尺寸为 26 × 26 × 512 feature map 后面加了一个 64 × 1 × 1 的卷积，降低了通道数，然后再 <a target="_blank" rel="noopener" href="https://github.com/pjreddie/darknet/blob/8215a8864d4ad07e058acafd75b2c6ff6600b9e8/src/blas.c#L9-L30">reorg</a> 转化为 13 × 13 × 256，并 concat 到 13 × 13 × 1024 的特征图上，输出一个 13 × 13 × 1280 的特征图。</p>
<p>再看其它的改进：</p>
<p><strong>Anchor Box</strong></p>
<p>YOLO 在 BBox 位置预测上表现并不好，一方面是因为它直接给出宽高。相比 R-CNN 中有预设的 Anchors，网络只需要预测一个 offset，这相对容易。作者在 v2 中引入了 Anchors。</p>
<p>第二个改动是，之前每个格子只预测一次类别，这实际上是对 BBox 的一种限制，现在需要 decouple。所以对每个 Anchor 都预测一组类别，它们的意义没变。同时，每个格子上的 BBox&#x2F;Anchor 数量不再是 2。</p>
<div class="figure center" style="width:;"><a class="fancybox" target="_blank" rel="noopener" href="https://d2y8c08sxwbp8v.cloudfront.net/2020-detection/yolo-output-tensor.png" title="output tensor of YOLOv1 against YOLOv2" data-caption="output tensor of YOLOv1 against YOLOv2" data-fancybox="default"><img class="fig-img" src="https://d2y8c08sxwbp8v.cloudfront.net/2020-detection/yolo-output-tensor.png" alt="output tensor of YOLOv1 against YOLOv2"></a><span class="caption">output tensor of YOLOv1 against YOLOv2</span></div><div style="clear:both;"></div>

<p>此外，R-CNN 系列的 Anchors 是人工指定的，而这里的 Anchors 是通过 k-means 算法得到的，距离指标为 <code>d(box, centroid) = 1 − IoU(box, centroid)</code>，即以 IoU 来判断。下图是在 COCO 和 VOC 上聚类出的 Anchor 形状，以及使用不同距离指标或人工指定得到的平均 IoU。</p>
<div class="figure center" style="width:;"><a class="fancybox" target="_blank" rel="noopener" href="https://d2y8c08sxwbp8v.cloudfront.net/2020-detection/yolo-anchor-clusters.png" title="k-means result" data-caption="k-means result" data-fancybox="default"><img class="fig-img" src="https://d2y8c08sxwbp8v.cloudfront.net/2020-detection/yolo-anchor-clusters.png" alt="k-means result"></a><span class="caption">k-means result</span></div><div style="clear:both;"></div>

<p><strong>Direct location prediction</strong></p>
<p>这里先回顾一下 R-CNN 系列中的 regressor 是怎么工作的（注意在 YOLO 的论文中符号错了）：</p>
<mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -3.677ex;" xmlns="http://www.w3.org/2000/svg" width="37.07ex" height="8.486ex" role="img" focusable="false" viewBox="0 -2125.3 16384.7 3750.6" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-5-TEX-I-1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path><path id="MJX-5-TEX-N-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path><path id="MJX-5-TEX-N-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path><path id="MJX-5-TEX-I-1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path><path id="MJX-5-TEX-N-2217" d="M229 286Q216 420 216 436Q216 454 240 464Q241 464 245 464T251 465Q263 464 273 456T283 436Q283 419 277 356T270 286L328 328Q384 369 389 372T399 375Q412 375 423 365T435 338Q435 325 425 315Q420 312 357 282T289 250L355 219L425 184Q434 175 434 161Q434 146 425 136T401 125Q393 125 383 131T328 171L270 213Q283 79 283 63Q283 53 276 44T250 35Q231 35 224 44T216 63Q216 80 222 143T229 213L171 171Q115 130 110 127Q106 124 100 124Q87 124 76 134T64 161Q64 166 64 169T67 175T72 181T81 188T94 195T113 204T138 215T170 230T210 250L74 315Q65 324 65 338Q65 353 74 363T98 374Q106 374 116 368T171 328L229 286Z"></path><path id="MJX-5-TEX-I-1D464" d="M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z"></path><path id="MJX-5-TEX-I-1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path><path id="MJX-5-TEX-N-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path><path id="MJX-5-TEX-N-2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path><path id="MJX-5-TEX-N-A0" d=""></path><path id="MJX-5-TEX-N-2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path><path id="MJX-5-TEX-I-1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path><path id="MJX-5-TEX-I-210E" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path><path id="MJX-5-TEX-N-22C5" d="M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z"></path><path id="MJX-5-TEX-I-1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mtable"><g data-mml-node="mtr" transform="translate(0,1375.3)"><g data-mml-node="mtd"><g data-mml-node="mi"><use data-c="1D465" xlink:href="#MJX-5-TEX-I-1D465"></use></g><g data-mml-node="mo" transform="translate(849.8,0)"><use data-c="3D" xlink:href="#MJX-5-TEX-N-3D"></use></g><g data-mml-node="mo" transform="translate(1905.6,0)"><use data-c="28" xlink:href="#MJX-5-TEX-N-28"></use></g><g data-mml-node="msub" transform="translate(2294.6,0)"><g data-mml-node="mi"><use data-c="1D461" xlink:href="#MJX-5-TEX-I-1D461"></use></g><g data-mml-node="mi" transform="translate(394,-150) scale(0.707)"><use data-c="1D465" xlink:href="#MJX-5-TEX-I-1D465"></use></g></g><g data-mml-node="mo" transform="translate(3365.2,0)"><use data-c="2217" xlink:href="#MJX-5-TEX-N-2217"></use></g><g data-mml-node="msub" transform="translate(4087.5,0)"><g data-mml-node="mi"><use data-c="1D464" xlink:href="#MJX-5-TEX-I-1D464"></use></g><g data-mml-node="mi" transform="translate(749,-150) scale(0.707)"><use data-c="1D44E" xlink:href="#MJX-5-TEX-I-1D44E"></use></g></g><g data-mml-node="mo" transform="translate(5260.5,0)"><use data-c="29" xlink:href="#MJX-5-TEX-N-29"></use></g><g data-mml-node="mo" transform="translate(5871.7,0)"><use data-c="2B" xlink:href="#MJX-5-TEX-N-2B"></use></g><g data-mml-node="msub" transform="translate(6872,0)"><g data-mml-node="mi"><use data-c="1D465" xlink:href="#MJX-5-TEX-I-1D465"></use></g><g data-mml-node="mi" transform="translate(605,-150) scale(0.707)"><use data-c="1D44E" xlink:href="#MJX-5-TEX-I-1D44E"></use></g></g><g data-mml-node="mtext" transform="translate(7901,0)"><use data-c="A0" xlink:href="#MJX-5-TEX-N-A0"></use></g></g><g data-mml-node="mtd" transform="translate(8151,0)"><g data-mml-node="mi"></g><g data-mml-node="mo"><use data-c="2C" xlink:href="#MJX-5-TEX-N-2C"></use></g><g data-mml-node="mtext" transform="translate(444.7,0)"><use data-c="A0" xlink:href="#MJX-5-TEX-N-A0"></use></g><g data-mml-node="mi" transform="translate(694.7,0)"><use data-c="1D466" xlink:href="#MJX-5-TEX-I-1D466"></use></g><g data-mml-node="mo" transform="translate(1462.4,0)"><use data-c="3D" xlink:href="#MJX-5-TEX-N-3D"></use></g><g data-mml-node="mo" transform="translate(2518.2,0)"><use data-c="28" xlink:href="#MJX-5-TEX-N-28"></use></g><g data-mml-node="msub" transform="translate(2907.2,0)"><g data-mml-node="mi"><use data-c="1D461" xlink:href="#MJX-5-TEX-I-1D461"></use></g><g data-mml-node="mi" transform="translate(394,-150) scale(0.707)"><use data-c="1D466" xlink:href="#MJX-5-TEX-I-1D466"></use></g></g><g data-mml-node="mo" transform="translate(3919.9,0)"><use data-c="2217" xlink:href="#MJX-5-TEX-N-2217"></use></g><g data-mml-node="msub" transform="translate(4642.1,0)"><g data-mml-node="mi"><use data-c="210E" xlink:href="#MJX-5-TEX-I-210E"></use></g><g data-mml-node="mi" transform="translate(609,-150) scale(0.707)"><use data-c="1D44E" xlink:href="#MJX-5-TEX-I-1D44E"></use></g></g><g data-mml-node="mo" transform="translate(5675.2,0)"><use data-c="29" xlink:href="#MJX-5-TEX-N-29"></use></g><g data-mml-node="mo" transform="translate(6286.4,0)"><use data-c="2B" xlink:href="#MJX-5-TEX-N-2B"></use></g><g data-mml-node="msub" transform="translate(7286.7,0)"><g data-mml-node="mi"><use data-c="1D466" xlink:href="#MJX-5-TEX-I-1D466"></use></g><g data-mml-node="mi" transform="translate(523,-150) scale(0.707)"><use data-c="1D44E" xlink:href="#MJX-5-TEX-I-1D44E"></use></g></g></g></g><g data-mml-node="mtr" transform="translate(0,30.3)"><g data-mml-node="mtd" transform="translate(8151,0)"></g></g><g data-mml-node="mtr" transform="translate(0,-1375.3)"><g data-mml-node="mtd" transform="translate(2735,0)"><g data-mml-node="mi"><use data-c="1D464" xlink:href="#MJX-5-TEX-I-1D464"></use></g><g data-mml-node="mo" transform="translate(993.8,0)"><use data-c="3D" xlink:href="#MJX-5-TEX-N-3D"></use></g><g data-mml-node="msub" transform="translate(2049.6,0)"><g data-mml-node="mi"><use data-c="1D464" xlink:href="#MJX-5-TEX-I-1D464"></use></g><g data-mml-node="mi" transform="translate(749,-150) scale(0.707)"><use data-c="1D44E" xlink:href="#MJX-5-TEX-I-1D44E"></use></g></g><g data-mml-node="mo" transform="translate(3444.8,0)"><use data-c="22C5" xlink:href="#MJX-5-TEX-N-22C5"></use></g><g data-mml-node="msup" transform="translate(3945.1,0)"><g data-mml-node="mi"><use data-c="1D452" xlink:href="#MJX-5-TEX-I-1D452"></use></g><g data-mml-node="TeXAtom" transform="translate(499,413) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="msub"><g data-mml-node="mi"><use data-c="1D461" xlink:href="#MJX-5-TEX-I-1D461"></use></g><g data-mml-node="mi" transform="translate(394,-150) scale(0.707)"><use data-c="1D464" xlink:href="#MJX-5-TEX-I-1D464"></use></g></g></g></g><g data-mml-node="mtext" transform="translate(5166,0)"><use data-c="A0" xlink:href="#MJX-5-TEX-N-A0"></use></g></g><g data-mml-node="mtd" transform="translate(8151,0)"><g data-mml-node="mi"></g><g data-mml-node="mo"><use data-c="2C" xlink:href="#MJX-5-TEX-N-2C"></use></g><g data-mml-node="mtext" transform="translate(444.7,0)"><use data-c="A0" xlink:href="#MJX-5-TEX-N-A0"></use></g><g data-mml-node="mi" transform="translate(694.7,0)"><use data-c="210E" xlink:href="#MJX-5-TEX-I-210E"></use></g><g data-mml-node="mo" transform="translate(1548.4,0)"><use data-c="3D" xlink:href="#MJX-5-TEX-N-3D"></use></g><g data-mml-node="msub" transform="translate(2604.2,0)"><g data-mml-node="mi"><use data-c="210E" xlink:href="#MJX-5-TEX-I-210E"></use></g><g data-mml-node="mi" transform="translate(609,-150) scale(0.707)"><use data-c="1D44E" xlink:href="#MJX-5-TEX-I-1D44E"></use></g></g><g data-mml-node="mo" transform="translate(3859.5,0)"><use data-c="22C5" xlink:href="#MJX-5-TEX-N-22C5"></use></g><g data-mml-node="msup" transform="translate(4359.7,0)"><g data-mml-node="mi"><use data-c="1D452" xlink:href="#MJX-5-TEX-I-1D452"></use></g><g data-mml-node="TeXAtom" transform="translate(499,413) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="msub"><g data-mml-node="mi"><use data-c="1D461" xlink:href="#MJX-5-TEX-I-1D461"></use></g><g data-mml-node="mi" transform="translate(394,-150) scale(0.707)"><use data-c="210E" xlink:href="#MJX-5-TEX-I-210E"></use></g></g></g></g></g></g></g></g></g></svg></mjx-container>

<p>其中带下标 <code>a</code> 的是 Anchor，<code>t</code> 表示网络预测的值。</p>
<p>对于位置这样引入了尺度不变性，比如 <code>tx = 1</code> 框的中心点就向右移动一个框宽度的距离。但是这对于框的位置没有限定，对于随机化的初始值，框可能出现在图中的任何位置，导致难以训练。所以位置还是沿用 v1 中的相对于格子的预测方式，宽高则采用相同的指数形式。</p>
<mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -3.677ex;" xmlns="http://www.w3.org/2000/svg" width="31.564ex" height="8.486ex" role="img" focusable="false" viewBox="0 -2125.3 13951.5 3750.6" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-5-TEX-I-1D44F" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path><path id="MJX-5-TEX-I-1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path><path id="MJX-5-TEX-N-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path><path id="MJX-5-TEX-I-1D70E" d="M184 -11Q116 -11 74 34T31 147Q31 247 104 333T274 430Q275 431 414 431H552Q553 430 555 429T559 427T562 425T565 422T567 420T569 416T570 412T571 407T572 401Q572 357 507 357Q500 357 490 357T476 358H416L421 348Q439 310 439 263Q439 153 359 71T184 -11ZM361 278Q361 358 276 358Q152 358 115 184Q114 180 114 178Q106 141 106 117Q106 67 131 47T188 26Q242 26 287 73Q316 103 334 153T356 233T361 278Z"></path><path id="MJX-5-TEX-N-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path><path id="MJX-5-TEX-I-1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path><path id="MJX-5-TEX-N-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path><path id="MJX-5-TEX-N-2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path><path id="MJX-5-TEX-I-1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path><path id="MJX-5-TEX-N-A0" d=""></path><path id="MJX-5-TEX-N-2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path><path id="MJX-5-TEX-I-1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path><path id="MJX-5-TEX-I-1D464" d="M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z"></path><path id="MJX-5-TEX-I-1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path><path id="MJX-5-TEX-I-1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path><path id="MJX-5-TEX-I-210E" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mtable"><g data-mml-node="mtr" transform="translate(0,1375.3)"><g data-mml-node="mtd"><g data-mml-node="msub"><g data-mml-node="mi"><use data-c="1D44F" xlink:href="#MJX-5-TEX-I-1D44F"></use></g><g data-mml-node="mi" transform="translate(462,-150) scale(0.707)"><use data-c="1D465" xlink:href="#MJX-5-TEX-I-1D465"></use></g></g><g data-mml-node="mo" transform="translate(1194.2,0)"><use data-c="3D" xlink:href="#MJX-5-TEX-N-3D"></use></g><g data-mml-node="mi" transform="translate(2250,0)"><use data-c="1D70E" xlink:href="#MJX-5-TEX-I-1D70E"></use></g><g data-mml-node="mo" transform="translate(2821,0)"><use data-c="28" xlink:href="#MJX-5-TEX-N-28"></use></g><g data-mml-node="msub" transform="translate(3210,0)"><g data-mml-node="mi"><use data-c="1D461" xlink:href="#MJX-5-TEX-I-1D461"></use></g><g data-mml-node="mi" transform="translate(394,-150) scale(0.707)"><use data-c="1D465" xlink:href="#MJX-5-TEX-I-1D465"></use></g></g><g data-mml-node="mo" transform="translate(4058.5,0)"><use data-c="29" xlink:href="#MJX-5-TEX-N-29"></use></g><g data-mml-node="mo" transform="translate(4669.7,0)"><use data-c="2B" xlink:href="#MJX-5-TEX-N-2B"></use></g><g data-mml-node="msub" transform="translate(5669.9,0)"><g data-mml-node="mi"><use data-c="1D450" xlink:href="#MJX-5-TEX-I-1D450"></use></g><g data-mml-node="mi" transform="translate(466,-150) scale(0.707)"><use data-c="1D465" xlink:href="#MJX-5-TEX-I-1D465"></use></g></g><g data-mml-node="mtext" transform="translate(6590.4,0)"><use data-c="A0" xlink:href="#MJX-5-TEX-N-A0"></use></g></g><g data-mml-node="mtd" transform="translate(6840.4,0)"><g data-mml-node="mi"></g><g data-mml-node="mo"><use data-c="2C" xlink:href="#MJX-5-TEX-N-2C"></use></g><g data-mml-node="mtext" transform="translate(444.7,0)"><use data-c="A0" xlink:href="#MJX-5-TEX-N-A0"></use></g><g data-mml-node="msub" transform="translate(694.7,0)"><g data-mml-node="mi"><use data-c="1D44F" xlink:href="#MJX-5-TEX-I-1D44F"></use></g><g data-mml-node="mi" transform="translate(462,-150) scale(0.707)"><use data-c="1D466" xlink:href="#MJX-5-TEX-I-1D466"></use></g></g><g data-mml-node="mo" transform="translate(1830.9,0)"><use data-c="3D" xlink:href="#MJX-5-TEX-N-3D"></use></g><g data-mml-node="mi" transform="translate(2886.7,0)"><use data-c="1D70E" xlink:href="#MJX-5-TEX-I-1D70E"></use></g><g data-mml-node="mo" transform="translate(3457.7,0)"><use data-c="28" xlink:href="#MJX-5-TEX-N-28"></use></g><g data-mml-node="msub" transform="translate(3846.7,0)"><g data-mml-node="mi"><use data-c="1D461" xlink:href="#MJX-5-TEX-I-1D461"></use></g><g data-mml-node="mi" transform="translate(394,-150) scale(0.707)"><use data-c="1D466" xlink:href="#MJX-5-TEX-I-1D466"></use></g></g><g data-mml-node="mo" transform="translate(4637.2,0)"><use data-c="29" xlink:href="#MJX-5-TEX-N-29"></use></g><g data-mml-node="mo" transform="translate(5248.4,0)"><use data-c="2B" xlink:href="#MJX-5-TEX-N-2B"></use></g><g data-mml-node="msub" transform="translate(6248.6,0)"><g data-mml-node="mi"><use data-c="1D450" xlink:href="#MJX-5-TEX-I-1D450"></use></g><g data-mml-node="mi" transform="translate(466,-150) scale(0.707)"><use data-c="1D466" xlink:href="#MJX-5-TEX-I-1D466"></use></g></g></g></g><g data-mml-node="mtr" transform="translate(0,30.3)"><g data-mml-node="mtd" transform="translate(6840.4,0)"></g></g><g data-mml-node="mtr" transform="translate(0,-1375.3)"><g data-mml-node="mtd" transform="translate(1925.3,0)"><g data-mml-node="msub"><g data-mml-node="mi"><use data-c="1D44F" xlink:href="#MJX-5-TEX-I-1D44F"></use></g><g data-mml-node="mi" transform="translate(462,-150) scale(0.707)"><use data-c="1D464" xlink:href="#MJX-5-TEX-I-1D464"></use></g></g><g data-mml-node="mo" transform="translate(1296.1,0)"><use data-c="3D" xlink:href="#MJX-5-TEX-N-3D"></use></g><g data-mml-node="msub" transform="translate(2351.8,0)"><g data-mml-node="mi"><use data-c="1D45D" xlink:href="#MJX-5-TEX-I-1D45D"></use></g><g data-mml-node="mi" transform="translate(536,-150) scale(0.707)"><use data-c="1D464" xlink:href="#MJX-5-TEX-I-1D464"></use></g></g><g data-mml-node="msup" transform="translate(3444.1,0)"><g data-mml-node="mi"><use data-c="1D452" xlink:href="#MJX-5-TEX-I-1D452"></use></g><g data-mml-node="TeXAtom" transform="translate(499,413) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="msub"><g data-mml-node="mi"><use data-c="1D461" xlink:href="#MJX-5-TEX-I-1D461"></use></g><g data-mml-node="mi" transform="translate(394,-150) scale(0.707)"><use data-c="1D464" xlink:href="#MJX-5-TEX-I-1D464"></use></g></g></g></g><g data-mml-node="mtext" transform="translate(4665.1,0)"><use data-c="A0" xlink:href="#MJX-5-TEX-N-A0"></use></g></g><g data-mml-node="mtd" transform="translate(6840.4,0)"><g data-mml-node="mi"></g><g data-mml-node="mo"><use data-c="2C" xlink:href="#MJX-5-TEX-N-2C"></use></g><g data-mml-node="mtext" transform="translate(444.7,0)"><use data-c="A0" xlink:href="#MJX-5-TEX-N-A0"></use></g><g data-mml-node="msub" transform="translate(694.7,0)"><g data-mml-node="mi"><use data-c="1D44F" xlink:href="#MJX-5-TEX-I-1D44F"></use></g><g data-mml-node="mi" transform="translate(462,-150) scale(0.707)"><use data-c="210E" xlink:href="#MJX-5-TEX-I-210E"></use></g></g><g data-mml-node="mo" transform="translate(1891.7,0)"><use data-c="3D" xlink:href="#MJX-5-TEX-N-3D"></use></g><g data-mml-node="msub" transform="translate(2947.5,0)"><g data-mml-node="mi"><use data-c="1D45D" xlink:href="#MJX-5-TEX-I-1D45D"></use></g><g data-mml-node="mi" transform="translate(536,-150) scale(0.707)"><use data-c="210E" xlink:href="#MJX-5-TEX-I-210E"></use></g></g><g data-mml-node="msup" transform="translate(3940.8,0)"><g data-mml-node="mi"><use data-c="1D452" xlink:href="#MJX-5-TEX-I-1D452"></use></g><g data-mml-node="TeXAtom" transform="translate(499,413) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="msub"><g data-mml-node="mi"><use data-c="1D461" xlink:href="#MJX-5-TEX-I-1D461"></use></g><g data-mml-node="mi" transform="translate(394,-150) scale(0.707)"><use data-c="210E" xlink:href="#MJX-5-TEX-I-210E"></use></g></g></g></g></g></g></g></g></g></svg></mjx-container>

<div class="figure center" style="width:75%;"><a class="fancybox" target="_blank" rel="noopener" href="https://d2y8c08sxwbp8v.cloudfront.net/2020-detection/yolo-v2-anchor-regression.png" title="YOLOv2 anchor regression" data-caption="YOLOv2 anchor regression" data-fancybox="default"><img class="fig-img" src="https://d2y8c08sxwbp8v.cloudfront.net/2020-detection/yolo-v2-anchor-regression.png" style="width:75%;"alt="YOLOv2 anchor regression"></a><span class="caption">YOLOv2 anchor regression</span></div><div style="clear:both;"></div>

<p>公式里 <code>sigma(·)</code> 是一个 logistic activation (sigmoid) 用于将值限定在 <code>[0, 1]</code>，即把中心点的变动限制在当前格子里。<code>cx, cy</code> 是所在格点左上角到图像左上角的距离，例如上图中是 <code>(1, 1)</code>（网格大小归一化了）。这里可以看出，这个位置是直接预测出的，它不依赖于设定的 Anchors。</p>
<h2 id="Train-YOLOv2"><a href="#Train-YOLOv2" class="headerlink" title="Train YOLOv2"></a>Train YOLOv2</h2><table>
<thead>
<tr>
<th align="center">网络</th>
<th align="center">top-5</th>
<th align="center">top-1</th>
<th align="center">输入尺寸</th>
<th align="center">floating point operations</th>
</tr>
</thead>
<tbody><tr>
<td align="center">VGG-16</td>
<td align="center">90.0%</td>
<td align="center">-</td>
<td align="center">224 × 224</td>
<td align="center">30.69 billion</td>
</tr>
<tr>
<td align="center">Darknet-24</td>
<td align="center">88.0%</td>
<td align="center">-</td>
<td align="center">224 × 224</td>
<td align="center">8.52 billion</td>
</tr>
<tr>
<td align="center">Darknet-19</td>
<td align="center">91.2%</td>
<td align="center">72.9%</td>
<td align="center">224 × 224</td>
<td align="center">5.58 billion</td>
</tr>
</tbody></table>
<ol>
<li><p>在 ImageNet 上训练 160 个 epochs。lr &#x3D; 0.1，polynomial rate decay with a power of 4，weight decay &#x3D; 0.0005，momentum &#x3D; 0.9。随机裁剪、旋转、颜色和曝光调整。</p>
</li>
<li><p>High Resolution Classifier：ImageNet 训练是使用 224 × 224，这样在进行检测训练时，网络不仅要学习更大的 448 × 448 输入，还要同时学习检测任务。所以在 v2 中，会在 ImageNet 上使用 448 × 448 fine tune 10 个 epochs 再进行检测训练，lr &#x3D; 10e-3。准确率达到 76.5%&#x2F;93.3%。</p>
</li>
<li><p>Multi-Scale Training：接下来进行检测训练。训练中每过 10 个 epochs，会在 <code>&#123;320, 352, ..., 608&#125;</code> 中随机选择一个输入尺寸继续训练。共 160 个 epochs，lr &#x3D; 10e-3，在 10、60、90 epoch 时减半。weight decay、momentum 与上面相同。</p>
</li>
</ol>
<h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><div class="figure center" style="width:;"><a class="fancybox" target="_blank" rel="noopener" href="https://d2y8c08sxwbp8v.cloudfront.net/2020-detection/yolo-v2-improvement-path.png" title="The path from YOLO to YOLOv2" data-caption="The path from YOLO to YOLOv2" data-fancybox="default"><img class="fig-img" src="https://d2y8c08sxwbp8v.cloudfront.net/2020-detection/yolo-v2-improvement-path.png" alt="The path from YOLO to YOLOv2"></a><span class="caption">The path from YOLO to YOLOv2</span></div><div style="clear:both;"></div>

<p>上表总结了从 v1 到 v2 的各项改进，说明一下：表中的 anchor boxes 指的是人工指定的，固定尺寸和长宽比的 anchors，使用这种框，mAP 69.5 -&gt; 69.2，recall 81% -&gt; 88%，精度小幅下降召回明显提高，说明网络有较大提升空间，所以作者采取了下面的 k-means 聚类找出最佳初始尺寸的方法。对于这种聚类得到的框，作者叫它 dimension priors，可能应该翻译成「先验框」。但是我觉得它本质和 anchors 没什么差别，且对于网络的修改也沿用了，其实在 v3 中作者也管它叫 anchors 了，所以在上文没有区分。</p>
<h2 id="Joint-train-on-object-detection-and-classification-YOLO9000"><a href="#Joint-train-on-object-detection-and-classification-YOLO9000" class="headerlink" title="Joint train on object detection and classification (YOLO9000)"></a>Joint train on object detection and classification (YOLO9000)</h2><p>基本思路是对于检测的数据传入，BP 整个网络，对于分类的数据传入，只 BP 有关分类的网络部分。一个问题是检测数据集如 COCO 提供的是一个很泛的类别，比如「狗」，共 80 类；而分类数据集如 ImageNet 提供的类别是很具体的，如「哈士奇」，共 21841 类。而 Softmax 意味着各类别之间是相互排斥的，而我们希望只在每个数据集内类别相互排斥，而数据集之间不是。</p>
<p>下面仍然先要在分类上预训练，然后再训练检测。</p>
<p><strong>Classification</strong></p>
<p>ImageNet 的标签来自于 WordNet，一个语言数据集，它有详细的层级，比如 canine -&gt; dog -&gt; hunting dog -&gt; terrier -&gt; Norfolk terrier，但是它是一个 Graph 而不是 Tree，比如 dog 可以属于 canine 也可以属于 domestic animal，即有多个父节点。好在大多数类别通向 root 只有一条路径，对于有多条路径的，选择最短的路径，舍弃其它的，这样就可以构造一个 Word Tree。</p>
<p>对于 ImageNet-1000，构建完整个图之后有 1369 个节点，增加了额外的 369 个节点。每一个节点预测一个条件概率，最终的概率需要将它们相乘，例如 <code>Pr(Norfolk terrier) = Pr(Norfolk terrier|terrier) * Pr(terrier|hunting dog) ∗ ... ∗ Pr(mammal|animal) * Pr(animal|physical object) * Pr(physical object)</code>。对于分类，每张图都有物体，所以这里最后一项 <code>Pr(physical object) = 1</code>。</p>
<div class="figure center" style="width:;"><a class="fancybox" target="_blank" rel="noopener" href="https://d2y8c08sxwbp8v.cloudfront.net/2020-detection/yolo-prediction-on-wordtree1k.png" title="Prediction on ImageNet vs WordTree" data-caption="Prediction on ImageNet vs WordTree" data-fancybox="default"><img class="fig-img" src="https://d2y8c08sxwbp8v.cloudfront.net/2020-detection/yolo-prediction-on-wordtree1k.png" alt="Prediction on ImageNet vs WordTree"></a><span class="caption">Prediction on ImageNet vs WordTree</span></div><div style="clear:both;"></div>

<p>在 ImageNet 上使用这个图训练网络，预测的形式如上图右侧，在每层级下分别 Softmax。一张图片会顺着这个 tree（可参考下面的图）走到 root，获得路径上的所有标签，即一张图现在有多个标注。这样训练的结果为 71.9%&#x2F;90.4%。新增节点后准确率下降不多，同时如果网络见到了一个没训练过的狗的品种，那么预测中「狗」的概率会很大，同时所有具体类别的概率又很小。</p>
<p><strong>Detection</strong></p>
<p>对于框的分类结果，检测中每个格子内不一定有物体， <code>Pr(physical object)</code> 根据 confidence&#x2F;objectness 分数（BBox 的第五个预测值）确定。判断一个框的类别时，从 WordTree 根节点开始向下遍历，对每一个节点，在它的所有子节点中，选择概率最大的那个（一个节点下面的所有子节点是互斥的），一直向下遍历直到某个节点的子节点概率低于设定的阈值（意味着很难确定它的下一层对象到底是哪个），或达到叶子节点，那么该节点就是对应的对象。</p>
<div class="figure center" style="width:;"><a class="fancybox" target="_blank" rel="noopener" href="https://d2y8c08sxwbp8v.cloudfront.net/2020-detection/yolo-combine-coco-and-imagenet.png" title="Combining datasets using WordTree hierarchy" data-caption="Combining datasets using WordTree hierarchy" data-fancybox="default"><img class="fig-img" src="https://d2y8c08sxwbp8v.cloudfront.net/2020-detection/yolo-combine-coco-and-imagenet.png" alt="Combining datasets using WordTree hierarchy"></a><span class="caption">Combining datasets using WordTree hierarchy</span></div><div style="clear:both;"></div>

<p>训练总共选取了 9000 类，含有 COCO、ImageNet 分类和检测数据集。为了构造 Tree 产生的父节点，构造的方法与之前相同，加起来共 9418 类。Oversampling COCO 使得数据量之比为 4:1。</p>
<p>网络结构和 v2 相同，先验框的尺寸改为 3 种。标注和反向传播与之前类似，（1）对于检测数据集图像，loss 与之前相同，只是这里对于 class，只反向传播标注的那个节点及其父节点上的 loss，不 BP 其子节点上的；（2）对于分类数据集图像，首先找到 GT 所属类别的预测值最高的那个框，只反向传播这个框上的 class 和 objectness 部分，四个坐标不反向传播。对于 class，与检测的相同，只看其和其父节点的，对于 objectness，原文是「We also assume that the predicted box overlaps what would be the ground truth label by at least .3 IOU and we backpropagate objectness loss based on this assumption.」，我觉得意思是说如果预测的 <code>objectness = Pr(object) * IoU</code> 小于 <code>1 * 0.3</code> 的话就有一个损失在上面，具体损失形式需要以后看一下代码了更新。</p>
<p><strong>Results</strong></p>
<p>作者在 ImageNet Detection 上测试，其中 44 类是与 COCO 相同的，156 类是 COCO 中没有只出现在 ImageNet Classification 的。结果是 19.7 mAP，在不重合的 156 类上有 16.0 mAP。具体来看不重合的类别部分，对于各种动物，COCO 中有一些动物的标注，对于新动物的类别的表现不错：<code>red panda = 50.7, fox = 52.1, koala bear = 54.3, tiger = 61.0, armadillo = 61.7</code>；对于一些 COCO 中完全没有相关（类似）的类别的，表现很差：<code>diaper = 0.0, horizontal bar = 0.0, rubber eraser = 0.0, sunglasses = 0.0, swimming trunks = 0.0</code>。</p>
<h1 id="YOLOv3-An-Incremental-Improvement"><a href="#YOLOv3-An-Incremental-Improvement" class="headerlink" title="YOLOv3: An Incremental Improvement"></a>YOLOv3: An Incremental Improvement</h1><p>YOLOv3 和 v4 都是 tech report，更多是把别人的工作在保证速度前提下整合进 YOLO 以提高精度。</p>
<p>每一代 YOLO 都对网络或是说 backbone 进行了改进，YOLOv3 更是主要集中在这个网络上。</p>
<h2 id="Network"><a href="#Network" class="headerlink" title="Network"></a>Network</h2><p>YOLOv3 同样是先有一个检测网络，在 ImageNet 上预训练，然后改为检测网络训练。下图（右侧是左侧红线部分）是 DarkNet-53，含有 52 个卷积和 1 个全连接。可以看到，与 DarkNet-19 相比，层数多了不少，主要的改变在于：</p>
<ol>
<li><p>去掉了池化层，全部由一个步长为 2 的卷积层完成下采样。</p>
</li>
<li><p>最后的全连接层又回来了。</p>
</li>
<li><p>内部出现了类似于 ResNet 的残差连接。</p>
</li>
</ol>
<div class="figure center" style="width:;"><a class="fancybox" target="_blank" rel="noopener" href="https://d2y8c08sxwbp8v.cloudfront.net/2020-detection/yolo-darknet-53-classification.png" title="Darknet-53 for classification" data-caption="Darknet-53 for classification" data-fancybox="default"><img class="fig-img" src="https://d2y8c08sxwbp8v.cloudfront.net/2020-detection/yolo-darknet-53-classification.png" alt="Darknet-53 for classification"></a><span class="caption">Darknet-53 for classification</span></div><div style="clear:both;"></div>

<table>
<thead>
<tr>
<th align="center">backbone</th>
<th align="center">top-1</th>
<th align="center">top-5</th>
<th align="center">测试尺寸</th>
<th align="center">Ops</th>
<th align="center">FPS</th>
<th align="center">BFLOP&#x2F;s</th>
</tr>
</thead>
<tbody><tr>
<td align="center">Darknet-19</td>
<td align="center">74.1%</td>
<td align="center">91.8%</td>
<td align="center">256 × 256</td>
<td align="center">7.29 B</td>
<td align="center">171</td>
<td align="center">1246</td>
</tr>
<tr>
<td align="center">Darknet-53</td>
<td align="center">77.2%</td>
<td align="center">93.8%</td>
<td align="center">256 × 256</td>
<td align="center">18.7 B</td>
<td align="center">78</td>
<td align="center">1457</td>
</tr>
<tr>
<td align="center">ResNet-101</td>
<td align="center">77.1%</td>
<td align="center">93.7%</td>
<td align="center">256 × 256</td>
<td align="center">19.7 B</td>
<td align="center">53</td>
<td align="center">1039</td>
</tr>
<tr>
<td align="center">ResNet-152</td>
<td align="center">77.6%</td>
<td align="center">93.8%</td>
<td align="center">256 × 256</td>
<td align="center">29.4 B</td>
<td align="center">37</td>
<td align="center">1090</td>
</tr>
</tbody></table>
<p>上述数据统一在 TitanX 下测试，最后一项 BFLOP&#x2F;s 意味着 Darknet 对 GPU 的利用更好。</p>
<p>再看检测网络，在这里作者引入了类似于 FPN 的多级预测结构。这个在论文里讲得有点零散混乱且没有结构图，我根据<a target="_blank" rel="noopener" href="https://github.com/pjreddie/darknet/blob/master/cfg/yolov3.cfg">代码</a>做了一个下面的网络结构图。</p>
<div class="figure center" style="width:;"><a class="fancybox" target="_blank" rel="noopener" href="https://d2y8c08sxwbp8v.cloudfront.net/2020-detection/yolo-darknet-53-detection.png" title="Darknet-53 for detection" data-caption="Darknet-53 for detection" data-fancybox="default"><img class="fig-img" src="https://d2y8c08sxwbp8v.cloudfront.net/2020-detection/yolo-darknet-53-detection.png" alt="Darknet-53 for detection"></a><span class="caption">Darknet-53 for detection</span></div><div style="clear:both;"></div>

<p>解释几点：</p>
<ol>
<li><p>每一个 Conv 都跟着一个 BN 和 leaky ReLU 激活层，最后每个 Prediction 是通过一个无 BN、linear 激活的 1 × 1 卷积层得到的，就是一般的预测层，在图中没有画出（也可认为绿色的 Prediction 就是这个卷积）。</p>
</li>
<li><p>每一个 Add 之后有一个 linear activation。</p>
</li>
<li><p>这里每个 Residual Unit 里面只有两层，与 ResNet 的不一样。上方蓝色的 <code>N×</code> 表示括号内的模块重复 N 次。</p>
</li>
<li><p>Conv 上方的尺寸是指经过这一层后的尺寸，以输入 <code>416 × 416</code> 为例。都是 CHW 的格式。</p>
</li>
<li><p>黄色的层是改为检测网络之后新加入的，白色的是原有的 Darknet-53 Backbone，共 52 层（去掉了最后的全连接）。</p>
</li>
</ol>
<p>再看最后输出的 255 个通道是怎么回事，<code>255 = 3 × (80 + 5)</code>，首先这里是以 COCO 为基准了，不再使用 VOC 的，所以是 80；5 就是从 v1 一直延续来的；3 指的是三个 Anchors，在 v2 里是五个，而 v3 实际用了 9 个，平均分在三级预测上。在 COCO 上尺寸分别是 <code>(10×13),(16×30),(33×23),(30×61),(62×45),(59× 119), (116 × 90), (156 × 198), (373 × 326)</code>。</p>
<h2 id="Other-Improvements"><a href="#Other-Improvements" class="headerlink" title="Other Improvements"></a>Other Improvements</h2><p><strong>Bounding Box Prediction (objectness)</strong></p>
<p>对于 objectness 分数，YOLOv3 采用了 logistic regression，所以如果一个 BBox 与 GT 的交叠大于任何其它的 BBox，那么它的 objectness 分数应该为 <code>1</code>。训练使用 binary cross-entropy loss，不再是 SSE loss。</p>
<p>同时引入了类似 RPN 的匹配机制：如果一个框与 GT 的交叠大于一个阈值 <code>0.5</code> 但它又不是交叠最大的框，那么这个将作为非正非负的样本，在训练时被忽略。</p>
<p>同样，一个 GT 只会与一个 Anchor&#x2F;BBox 匹配上，对于没有匹配上的负样本，loss 中将没有 coordinate 和 class predictions 部分，只有 objectness loss。</p>
<p><strong>Class Prediction (classes)</strong></p>
<p>作者去掉了之前使用的 Softmax 进行类别分类，因为发现对准确率没有帮助，且一个大型数据集如 Open Images 上面有一些交叠的类别，比如 Woman - Person。使用 independent logistic classifiers 预测，并设定一个阈值，高于这个阈值的类别将被赋给对应的框。训练使用 binary cross-entropy loss，不再是 SSE loss。</p>
<h2 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h2><div class="figure center" style="width:;"><a class="fancybox" target="_blank" rel="noopener" href="https://d2y8c08sxwbp8v.cloudfront.net/2020-detection/yolo-v3-results-on-coco-test-dev.png" title="YOLO v3 results on COCO test-dev" data-caption="YOLO v3 results on COCO test-dev" data-fancybox="default"><img class="fig-img" src="https://d2y8c08sxwbp8v.cloudfront.net/2020-detection/yolo-v3-results-on-coco-test-dev.png" alt="YOLO v3 results on COCO test-dev"></a><span class="caption">YOLO v3 results on COCO test-dev</span></div><div style="clear:both;"></div>

<p>从上表可以看出，YOLOv3-608 在 COCO 上的结果以及到了和 ResNet-FasterRCNN 接近的水平，但是时间仅需 51ms，是后者的三倍多。同时，在 AP50 指标上 YOLO 表现得很好，说明很大一部分的问题来自于框的位置的不准确。</p>
<div class="figure center" style="width:;"><a class="fancybox" target="_blank" rel="noopener" href="https://d2y8c08sxwbp8v.cloudfront.net/2020-detection/yolo-v3-precision-speed-compare.png" title="precision-speed compare on COCO test-dev" data-caption="precision-speed compare on COCO test-dev" data-fancybox="default"><img class="fig-img" src="https://d2y8c08sxwbp8v.cloudfront.net/2020-detection/yolo-v3-precision-speed-compare.png" alt="precision-speed compare on COCO test-dev"></a><span class="caption">precision-speed compare on COCO test-dev</span></div><div style="clear:both;"></div>



<h1 id="YOLOv4-Optimal-Speed-and-Accuracy-of-Object-Detection"><a href="#YOLOv4-Optimal-Speed-and-Accuracy-of-Object-Detection" class="headerlink" title="YOLOv4: Optimal Speed and Accuracy of Object Detection"></a>YOLOv4: Optimal Speed and Accuracy of Object Detection</h1><p>YOLOv4 是一篇将其它人提出许多的方法整合进 YOLO 的文章，但有一个前提就是保证速度，所以有些方法做了一些改动。同时基于这个原则，作者希望能使用较亲民的设备进行训练和预测，所以所有涉及多 GPU 的方法比如 SyncBN 均不予考虑。相应的测试也选用单个 RTX 2080Ti&#x2F;RTX 2070&#x2F;GTX 1080Ti 这类游戏显卡（但是 2080Ti 这好像不是所有打游戏的都买得起的？）。不过这篇文章还挺好的，对检测的研究也进行了一个相应的划分总结，还是挺全面的像综述一样，值得看看原文，本文里只有 YOLOv4 用到了的方法的分析。</p>
<p>其实我感觉很难写，因为涉及太多其它的文章，不知道简单几句能不能给一篇文章讲清楚。此外有些还是今年的，很新，我也没看过。。。</p>
<p>总的来说，作者将其它人的工作划分为 Bag of freebies (BoF) 和 Bag of specials (BoS)。前者指在训练时候的一些方法，不影响预测时间和模型复杂度；而后者指的是整个构架的改动，对预测（时间）会有影响。我花了点时间给整理了一下，下面两个表是用到的所有方法和对应论文，没有对应论文的就是作者在 YOLOv4 中应用的一些简单 BoF，可以看到，这篇文章各种 tricks 真的巨多，我相信给其它算法这么一顿军训效果也能好不少的。不过别人已经测试好了，直接能用，也很实用对吧。</p>
<br/>

<table>
<thead>
<tr>
<th align="center">Backbone BoF</th>
<th align="center">arXiv</th>
<th align="center">Detector BoF</th>
<th align="center">arXiv</th>
</tr>
</thead>
<tbody><tr>
<td align="center">CutMix</td>
<td align="center">ICCV 2019 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1905.04899">1905.04899</a></td>
<td align="center">CIoU-loss</td>
<td align="center">AAAI 2020 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1911.08287">1911.08287</a></td>
</tr>
<tr>
<td align="center">DropBlock regularization</td>
<td align="center">NIPS 2018 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1810.12890">1810.12890</a></td>
<td align="center">DropBlock regularization</td>
<td align="center"><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1810.12890">1810.12890</a></td>
</tr>
<tr>
<td align="center">Class label smoothing</td>
<td align="center">CVPR 2016 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1512.00567">1512.00567</a></td>
<td align="center">Cross mini-Batch Normalization (CmBN)</td>
<td align="center"><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2002.05712">2002.05712</a></td>
</tr>
<tr>
<td align="center"></td>
<td align="center"></td>
<td align="center">Cosine annealing scheduler</td>
<td align="center"><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1608.03983">1608.03983</a></td>
</tr>
</tbody></table>
<p>Others:</p>
<ul>
<li><p>BoF: Mosaic data augmentation.</p>
</li>
<li><p>Detector BoF: Eliminate grid sensitivity, Optimal hyper-parameters, Random training shapes, Self-Adversarial Training, Multiple anchors for a single ground truth.</p>
</li>
</ul>
<br/>

<table>
<thead>
<tr>
<th align="center">Backbone BoS</th>
<th align="center">arXiv</th>
<th align="center">Detector BoS</th>
<th align="center">arXiv</th>
</tr>
</thead>
<tbody><tr>
<td align="center">Mish activation</td>
<td align="center"><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1908.08681">1908.08681</a></td>
<td align="center">Mish activation</td>
<td align="center"><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1908.08681">1908.08681</a></td>
</tr>
<tr>
<td align="center">Cross-stage partial connections (CSP)</td>
<td align="center"><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1911.11929">1911.11929</a></td>
<td align="center">SPP-block</td>
<td align="center">TPAMI 2015 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1406.4729">1406.4729</a></td>
</tr>
<tr>
<td align="center">Multi-input weighted residual connections (MiWRC)</td>
<td align="center">CVPR 2020 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1911.09070">1911.09070</a></td>
<td align="center">Path-aggregation block (PAN)</td>
<td align="center">CVPR 2018 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1803.01534">1803.01534</a></td>
</tr>
<tr>
<td align="center"></td>
<td align="center"></td>
<td align="center">SAM-block</td>
<td align="center">ECCV 2018 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1807.06521">1807.06521</a></td>
</tr>
<tr>
<td align="center"></td>
<td align="center"></td>
<td align="center">DIoU-NMS</td>
<td align="center">AAAI 2020 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1911.08287">1911.08287</a></td>
</tr>
</tbody></table>
<div class="alert warning"><p><del>仍需要一点时间施工，不过我猜要拖到五月底了。</del><br>已经到五月底了，然而事情很多，考虑到眼下两个月之内应该不会有机会看论文，所以我愉快地宣布下面的内容鸽子了 🐦。</p>
</div>

<h2 id="Bag-of-freebies"><a href="#Bag-of-freebies" class="headerlink" title="Bag of freebies"></a>Bag of freebies</h2><p>最常用的 bag of freebies 就是数据增强（data augmentation）了，YOLOv4 用了下面这些。</p>
<p><strong>CutMix</strong></p>
<p>CutMix 是一种 regional dropout strategy，这类方法通过去除一些 informative pixels 来使得网络学习图像中 less discriminative 部分的信息。</p>
<p>关于训练时的标签和损失函数，YOLOv4 中使用了下面这些。</p>
<p><strong>Class label smoothing</strong></p>
<p>使得 class 标签不绝对，提升分类器效果。</p>
<p><strong>CIoU Loss</strong></p>
<p>直接以 IoU 作为 regression 的损失函数，提高了回归精度。从 IoU -&gt; GIoU -&gt; DIoU -&gt; CIoU 的变化过程，见 <a href="https://tangh.github.io/articles/improvements-of-regressor-in-detector/#Generalized-Intersection-over-Union-A-Metric-and-A-Loss-for-Bounding-Box-Regression-CVPR-2019">另一篇关于 regressor 的文中 IoU Loss 的部分</a>。</p>
<h2 id="Bag-of-specials"><a href="#Bag-of-specials" class="headerlink" title="Bag of specials"></a>Bag of specials</h2><p><strong>Multi-input weighted residual connections (MiWRC)、Path-aggregation block (PAN)</strong></p>
<p>前者为带权重的特征融合方式，后者为 neck 上的新的特征融合路径。见 <a href="https://tangh.github.io/articles/efficientnet-and-efficientdet/#Neck-BiFPN">另一篇关于 EfficientDet 文中 BiFPN 的部分</a>。</p>
<p><strong>DIoU-NMS</strong></p>
<p>在 NMS 时考虑两个 box 中心点之间的距离以稍微降低其 IoU 值的方法，见 <a href="https://tangh.github.io/articles/improvements-of-regressor-in-detector/#Distance-IoU-and-Complete-IoU">另一篇关于 regressor 的文中 DIoU 的部分</a>。</p>
<br/>
            


        </div>
    </div>
    <div id="post-footer" class="post-footer main-content-wrap">
        
            <div class="post-footer-tags">
                <span class="text-color-light text-small">TAGGED IN</span><br/>
                
    <a class="tag tag--primary tag--small t-none-link" href="/tags/Computer-Vision/" rel="tag">Computer Vision</a> <a class="tag tag--primary tag--small t-none-link" href="/tags/Deep-Learning/" rel="tag">Deep Learning</a> <a class="tag tag--primary tag--small t-none-link" href="/tags/Object-Detection/" rel="tag">Object Detection</a>

            </div>
        
        
            <div class="post-actions-wrap">
    <nav>
        <ul class="post-actions post-action-nav">
            <li class="post-action">
                
                    
                <a
                    class="post-action-btn btn btn--default tooltip--top"
                    href="/articles/efficientnet-and-efficientdet/"
                    data-tooltip="EfficientNet 和 EfficientDet"
                    aria-label="PREVIOUS: EfficientNet 和 EfficientDet"
                >
                    
                        <i class="fa fa-angle-left" aria-hidden="true"></i>
                        <span class="hide-xs hide-sm text-small icon-ml">PREVIOUS</span>
                    </a>
            </li>
            <li class="post-action">
                
                    
                <a
                    class="post-action-btn btn btn--default tooltip--top"
                    href="/articles/backward-in-convolutional-neural-networks/"
                    data-tooltip="卷積神經網絡中的反向傳播"
                    aria-label="NEXT: 卷積神經網絡中的反向傳播"
                >
                    
                        <span class="hide-xs hide-sm text-small icon-mr">NEXT</span>
                        <i class="fa fa-angle-right" aria-hidden="true"></i>
                    </a>
            </li>
        </ul>
    </nav>
    <ul class="post-actions post-action-share">
        <li class="post-action hide-lg hide-md hide-sm">
            <a
                class="post-action-btn btn btn--default btn-open-shareoptions"
                href="#btn-open-shareoptions"
                aria-label="Share this post"
            >
                <i class="fa fa-share-alt" aria-hidden="true"></i>
            </a>
        </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://www.facebook.com/sharer/sharer.php?u=https://tangh.github.io/articles/yolo-from-v1-to-v4/"
                    title="Share on Facebook"
                    aria-label="Share on Facebook"
                >
                    <i class="fab fa-facebook" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://twitter.com/intent/tweet?text=https://tangh.github.io/articles/yolo-from-v1-to-v4/"
                    title="Share on Twitter"
                    aria-label="Share on Twitter"
                >
                    <i class="fab fa-twitter" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="http://service.weibo.com/share/share.php?&amp;title=https://tangh.github.io/articles/yolo-from-v1-to-v4/"
                    title="Share on Weibo"
                    aria-label="Share on Weibo"
                >
                    <i class="fab fa-weibo" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="http://connect.qq.com/widget/shareqq/index.html?url=https://tangh.github.io/articles/yolo-from-v1-to-v4/&amp;title=实时目标检测方法 YOLO — 从 V1 到 V4"
                    title="Share on QQ"
                    aria-label="Share on QQ"
                >
                    <i class="fab fa-qq" aria-hidden="true"></i>
                </a>
            </li>
        
        
            
                <li class="post-action">
                    <a
                        class="post-action-btn btn btn--default"
                        href="#gitalk"
                        aria-label="Leave a comment"
                    >
                        <i class="fa fa-comment"></i>
                    </a>
                </li>
            
        
        <li class="post-action">
            
                <a class="post-action-btn btn btn--default" href="#table-of-contents" aria-label="Table of Contents">
            
                <i class="fa fa-list" aria-hidden="true"></i>
            </a>
        </li>
    </ul>
</div>


        
        
            
                <div id="gitalk"></div>

            
        
    </div>
</article>



                <footer id="footer" class="main-content-wrap">
    <span class="copyrights">
        Copyrights &copy; 2023 Tang Huan. All Rights Reserved.
    </span>
</footer>

            </div>
            
                <div id="bottom-bar" class="post-bottom-bar" data-behavior="4">
                    <div class="post-bar-actions-wrap">
    <div class="post-actions post-action-share">
        <div class="post-action">
            
                <a class="post-bar-action-btn btn btn--default" href="#table-of-contents" aria-label="Table of Contents">
            
                <i class="fas fa-angle-up" aria-hidden="true"></i>
            </a>
        </div>
        
            
                <div class="post-action">
                    <a 
                        class="post-bar-action-btn btn btn--default"
                        href="#gitalk"
                        aria-label="Leave a comment"
                    >
                         <i class="fas fa-angle-down"></i>
                    </a>
                </div>
            
        
    </div>
</div>
                </div>
                
    <div id="share-options-bar" class="share-options-bar" data-behavior="4">
        <i id="btn-close-shareoptions" class="fa fa-times"></i>
        <ul class="share-options">
            
                
                
                <li class="share-option">
                    <a
                        class="share-option-btn"
                        target="new"
                        href="https://www.facebook.com/sharer/sharer.php?u=https://tangh.github.io/articles/yolo-from-v1-to-v4/"
                        aria-label="Share on Facebook"
                    >
                        <i class="fab fa-facebook" aria-hidden="true"></i><span>Share on Facebook</span>
                    </a>
                </li>
            
                
                
                <li class="share-option">
                    <a
                        class="share-option-btn"
                        target="new"
                        href="https://twitter.com/intent/tweet?text=https://tangh.github.io/articles/yolo-from-v1-to-v4/"
                        aria-label="Share on Twitter"
                    >
                        <i class="fab fa-twitter" aria-hidden="true"></i><span>Share on Twitter</span>
                    </a>
                </li>
            
                
                
                <li class="share-option">
                    <a
                        class="share-option-btn"
                        target="new"
                        href="http://service.weibo.com/share/share.php?&amp;title=https://tangh.github.io/articles/yolo-from-v1-to-v4/"
                        aria-label="Share on Weibo"
                    >
                        <i class="fab fa-weibo" aria-hidden="true"></i><span>Share on Weibo</span>
                    </a>
                </li>
            
                
                
                <li class="share-option">
                    <a
                        class="share-option-btn"
                        target="new"
                        href="http://connect.qq.com/widget/shareqq/index.html?url=https://tangh.github.io/articles/yolo-from-v1-to-v4/&amp;title=实时目标检测方法 YOLO — 从 V1 到 V4"
                        aria-label="Share on QQ"
                    >
                        <i class="fab fa-qq" aria-hidden="true"></i><span>Share on QQ</span>
                    </a>
                </li>
            
        </ul>
    </div>


            
        </div>
        


    
        
    

<div id="about">
    <div id="about-card">
        <div id="about-btn-close">
            <i class="fa fa-times"></i>
        </div>
        
            <img id="about-card-picture" src="/assets/images/icon.jpg" alt="Author&#39;s picture"/>
        
            <h4 id="about-card-name">Tang Huan</h4>
        
            <div id="about-card-bio"></div>
        
        
            <div id="about-card-job">
                <i class="fa fa-briefcase"></i>
                <br/>
                
            </div>
        
        
            <div id="about-card-location">
                <i class="fa fa-map-marker-alt"></i>
                <br/>
                Shanghai
            </div>
        
    </div>
</div>

        
        
<div id="cover" style="background-image:url('/assets/images/cover.jpg');"></div>
        

<!--SCRIPTS-->

<script src="/assets/js/script-21vlobaq8sfmdbypn0z91hl6jyot6shixuux8ijser2jcbktmikbwlb6yvjx.min.js"></script>

<!--SCRIPTS END-->


    
      <script type="text/javascript">
        (function() {
          function render() {
            new Gitalk({
              clientID: 'b7b365f41dbbfaaf9b88',
              clientSecret: '25de272b8030e3c498dd56b883e4386d881b6d62',
              repo: 'tangh.github.io',
              owner: 'tangh',
              admin: ['tangh'],
              id: 'articles/yolo-from-v1-to-v4',
              title: document.title.replace(' - 雨天等放晴', ''),
              ...{"language":"en","perPage":10,"distractionFreeMode":false,"enableHotKey":true,"pagerDirection":"first","createIssueManually":true}
            }).render('gitalk');
          }
          var gc = document.createElement('script');
          gc.type = 'text/javascript';
          gc.src = '//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js';
          gc.charset = 'UTF-8';
          gc.onload = render;
          gc.async = true;
          document.querySelector('body').appendChild(gc);
          var gcs = document.createElement('link');
          gcs.href = '//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css';
          gcs.type = 'text/css';
          gcs.rel = 'stylesheet';
          gcs.media = 'screen,print';
          document.querySelector('head').appendChild(gcs);
        })();
      </script>
    




    
        <style>
            [bg-lazy] {
                background-image: none !important;
                background-color: #eee !important;
            }
        </style>
        <script>
            window.imageLazyLoadSetting = {
                isSPA: false,
                preloadRatio: 2,
                processImages: null,
            };
        </script><script>window.addEventListener("load",function(){var t=/\.(gif|jpg|jpeg|tiff|png)$/i,r=/^data:image\/[a-z]+;base64,/;Array.prototype.slice.call(document.querySelectorAll("img[data-original]")).forEach(function(a){var e=a.parentNode;"A"===e.tagName&&(e.href.match(t)||e.href.match(r))&&(e.href=a.dataset.original)})});</script><script>!function(r){r.imageLazyLoadSetting.processImages=t;var e=r.imageLazyLoadSetting.isSPA,n=r.imageLazyLoadSetting.preloadRatio||1,c=a();function a(){var t=Array.prototype.slice.call(document.querySelectorAll("img[data-original]")),e=Array.prototype.slice.call(document.querySelectorAll("[bg-lazy]"));return t.concat(e)}function t(){e&&(c=a());for(var t,o=0;o<c.length;o++)0<=(t=(t=c[o]).getBoundingClientRect()).bottom&&0<=t.left&&t.top<=(r.innerHeight*n||document.documentElement.clientHeight*n)&&function(){var t,e,n,a,i=c[o];e=function(){c=c.filter(function(t){return i!==t}),r.imageLazyLoadSetting.onImageLoaded&&r.imageLazyLoadSetting.onImageLoaded(i)},(t=i).hasAttribute("bg-lazy")?(t.removeAttribute("bg-lazy"),e&&e()):(n=new Image,a=t.getAttribute("data-original"),n.onload=function(){t.src=a,t.removeAttribute("data-original"),e&&e()},t.src!==a&&(n.src=a))}()}function i(){clearTimeout(t.tId),t.tId=setTimeout(t,500)}t(),document.addEventListener("scroll",i),r.addEventListener("resize",i),r.addEventListener("orientationchange",i)}(this);</script></body>
</html>
