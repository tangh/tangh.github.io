
<!DOCTYPE html>

    <html lang="zh-Hant-CN">

    
<head>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="é›¨å¤©ç­‰æ”¾æ™´">
    <title>å·ç©ç¥ç¶“ç¶²çµ¡ä¸­çš„åå‘å‚³æ’­ - é›¨å¤©ç­‰æ”¾æ™´</title>
    <meta name="author" content="Tang Huan">
    
        <meta name="keywords" content="PyTorch,CNNs,Backpropagation,å·ç©ç¶²çµ¡,åå‘å‚³æ’­,å·ç§¯ç½‘ç»œ,åå‘ä¼ æ’­">
    
    
        <link rel="icon" href="https://tangh.github.io/assets/images/favicon.png">
    
    
        <link rel="apple-touch-icon" sizes="180x180" href="https://tangh.github.io/assets/images/apple-touch-icon.png">
    
    
    <script type="application/ld+json">{"@context":"http://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Tang Huan","sameAs":["https://twitter.com/tanghrtx/","https://www.flickr.com/photos/135277712@N07/","https://www.instagram.com/tanghrtx/","https://www.youtube.com/channel/UCO-I0MZR6-HYmI_tgbBc0yw/","https://space.bilibili.com/634428/"],"image":"icon.jpg"},"articleBody":"\n\n\nå‰å¹¾å¤©æœ‰äººå•æˆ‘ä¸€å€‹å•é¡Œï¼Œä»–æƒ³æŠŠä¸€å€‹è‡ªå·±å‰µå»ºçš„ tensorï¼ˆè€Œä¸æ˜¯ç¶²çµ¡çš„æ¬Šé‡ï¼‰æ”¾é€² optimizerï¼Œä½†æ˜¯ PyTorch å ±éŒ¯ï¼šValueError: can&#39;t optimize a non-leaf Tensorã€‚çŸ­è©±é•·èªªï¼Œæˆ‘æ±ºå®šå¯«ä¸€å€‹é—œæ–¼åå‘å‚³æ’­çš„æ–‡ç« ï¼Œè‡³æ–¼å‰é¢é€™å€‹å•é¡Œï¼Œæœƒåœ¨ä¸­é–“ç”¨ä¸€ç¯€å»è§£é‡‹ï¼ˆä¸æ˜¯è§£æ±ºï¼Œç”¨ä¸€å€‹ .detach() å°±èƒ½è§£æ±ºäº†ï¼‰ã€‚\nå¦å¤–æˆ‘å…ˆè¦èªªä¸€é»å°±æ˜¯ï¼ˆå¯èƒ½æ˜¯æ¼¢èªç¿’æ…£çš„å•é¡Œï¼‰ï¼Œå°æ–¼ä¸€å€‹ç¶²çµ¡ï¼Œå®ƒæ›´é è¿‘æœ€çµ‚è¼¸å‡ºçš„éƒ¨åˆ†å«ã€Œå‰é¢ã€ï¼Œè‹±æ–‡çš„ forwardã€network head é€™äº›å°±æ˜¯é€™å€‹æ„æ€ï¼Œé è¿‘è¼¸å…¥çš„åœ°æ–¹å«ã€Œå¾Œé¢ã€ã€‚\n\n\n\n\næœ€åŸºæœ¬çš„åå‘å‚³æ’­ä¾‹å­æˆ‘å€‘å®šç¾©ä¸€å€‹ tensor xï¼Œç„¶å¾Œå°å…¶é€²è¡Œä¸€äº›é‹ç®—ï¼š\n123456789import torchx = torch.ones(2, 2, requires_grad=True)y = x + 2z = y * y * 3out = z.mean()out.backward()print(x.grad)\n\nåœ¨é€™è£¡ï¼Œx æ˜¯ä¸€å€‹ 2Ã—2 çš„æ•°çµ„ï¼Œæœ€çµ‚è¼¸å‡ºçš„çµæœæ˜¯ tensor([[4.5000, 4.5000],[4.5000, 4.5000]])ã€‚æˆ‘å€‘æ‰‹å‹•è¨ˆç®—ä¸€ä¸‹é€™å€‹æ¢¯åº¦ï¼šæœ‰ \\( o = \\frac{1}{4}\\sum_i z_i \\)ï¼Œä¸” \\( z_i = 3(x_i+2)^2 \\)ï¼Œæ‰€ä»¥ \\( \\frac{\\partial o}{\\partial x_i} = \\frac{3}{2}(x_i+2) \\)ï¼Œæ­¤æ™‚ x=1ï¼Œå‰‡æ¢¯åº¦ $$ \\frac{\\partial o}{\\partial x_i}\\bigr\\rvert_{x_i=1} = \\frac{9}{2} = 4.5 $$\né€™å€‹ä¾‹å­ä¹‹æ‰€ä»¥ç°¡å–®æ˜ç­ï¼Œæ˜¯å› ç‚ºå‰ä¸€å±‚ä¸­ä¸€å€‹å…ƒç´ å¯¦éš›ä¸Šåªå’Œå‰å¾Œä¸€å±‚ä¸­çš„åŒä½ç½®çš„ä¸€å€‹å…ƒç´ ç›¸å°æ‡‰ï¼Œå¦‚ä¸‹æ‰€ç¤ºã€‚\n12345x1 â”€ y1 â”€ z1 â”x2 â”€ y2 â”€ z2 â”¤             â”œâ”€ outx3 â”€ y3 â”€ z3 â”¤x4 â”€ y4 â”€ z4 â”˜\n\nåœ¨é€²è¡Œåˆ°ä¸‹ä¸€æ­¥ä¹‹å‰ï¼Œæˆ‘å€‘å…ˆä¾†çœ‹ä¸€å€‹ PyTorch çš„æ“ä½œã€‚\nå¦‚æœ print(out)ï¼Œçµæœç‚º tensor(27., grad_fn=&lt;MeanBackward0&gt;)ï¼Œé€™è£¡ä¸åƒ…å¯ä»¥çœ‹åˆ°å®ƒçš„å€¼ï¼Œé‚„å¯ä»¥çœ‹åˆ°å®ƒæ‰€é—œè¯çš„æ¢¯åº¦å‡½æ•°ï¼Œé€™å€‹å‡½æ•°ï¼Œå¯ä»¥é€šé out.grad_fn è¨ªå•ï¼Œå®ƒæœ‰ä¸€å€‹å±æ€§ next_functionsã€‚å°æ–¼ out.grad_fn.next_functionsï¼Œè¼¸å‡ºçš„çµæœç‚º ((&lt;MulBackward0 object at 0x7fa140178850&gt;, 0),)ï¼Œå¦‚æœçœ‹çœ‹ z.grad_fn å¯ä»¥å¾—åˆ° &lt;MulBackward0 object at 0x7fa140178850&gt;ã€‚ä¹Ÿå°±æ˜¯èªªï¼Œnext_functions æŒ‡å‘çš„å°±æ˜¯åå‘å‚³æ’­ç¶²çµ¡ä¸­ï¼ŒæŸä¸€å€‹æ¢¯åº¦å‡½æ•°çš„ä¸‹ä¸€ç´šçš„æ¢¯åº¦å‡½æ•°ã€‚\nnext_functions è¿”å›çš„ç¬¬ä¸€å±‚ tuple å…§æ˜¯æŒ‡å‘çš„æ‰€æœ‰çš„ä¸‹ä¸€ç´šï¼Œä¹Ÿå°±æ˜¯èªªï¼Œå®ƒå¯èƒ½æŒ‡å‘å¤šå€‹å‡½æ•°ï¼›ç¬¬äºŒå±‚ tuple å…§çš„ç¬¬äºŒå€‹å…ƒç´ ä¸€èˆ¬æ˜¯ 0ï¼Œå®ƒæ˜¯åå‘å‡½æ•°çš„è¼¸å…¥å€¼ï¼Œåªæœ‰è¿”å›å¤šå€‹å¯å¾®åˆ†çš„å€¼çš„å‡½æ•°ï¼ˆä¾‹å¦‚ torch.unbind()ï¼‰æ‰æœƒä½¿å®ƒçš„åå‘å‡½æ•°çš„é€™å€‹è¼¸å…¥å€¼éé›¶ã€‚ç¬¬äºŒå±‚ tuple å…§çš„ç¬¬ä¸€å€‹å…ƒç´ å¦‚æœæ˜¯ Noneï¼Œèªªæ˜å®ƒæŒ‡å‘äº†ä¸€å€‹å¸¸æ•°ã€‚\nç¸½ä¹‹ï¼Œæˆ‘å€‘å¯ä»¥ä¸€å±‚ä¸€å±‚å»çœ‹é€™å€‹åå‘å‚³æ’­ç¶²çµ¡ï¼Œçµæœå¦‚ä¸‹åœ–ã€‚æˆ‘å€‘å¯ä»¥çœ‹åˆ°ï¼ŒPyTorch è‡ªå‹•å‰µå»ºçš„é€™å€‹åå‘ç¶²çµ¡æ˜¯ä¸€ç´šä¸€ç´šçš„ï¼Œæ¯æ¬¡åªæœ‰ä¸€æ­¥æ“ä½œï¼Œæˆ‘å€‘å¯«åœ¨ä¸€è¡Œå…§çš„æ“ä½œä¹Ÿæœƒè‡ªå‹•è¢«æ‹†åˆ†é–‹ä¾†ã€‚\nbackward network automatic built by pytorch\n\næœ€æœ«å°¾çš„ AccumulateGrad object æœ‰ä¸€å€‹ .variable å±æ€§ï¼Œå®ƒæŒ‡å‘çš„å°±æ˜¯ xï¼Œé€™å€‹å¾Œé¢é‚„æœƒæåˆ°ã€‚\nå…¨é€£æ¥å±‚ä¸­çš„åå‘å‚³æ’­å°æ–¼å·ç©ç¥ç¶“ç¶²çµ¡ï¼Œè£¡é¢ä¹Ÿä¸æ’é™¤åŒ…å«å…¨é€£æ¥å±‚ã€‚æ­¤å¤–ï¼Œä¸€å€‹å…·é«”è€Œç°¡å–®çš„ç¥ç¶“ç¶²çµ¡ä¾‹å­ï¼Œé€šå¸¸é¸æ“‡å…¨é€£æ¥ç¶²çµ¡ï¼Œæˆ–è€…å« MLP (Mutli-Layer Perceptron)ã€‚ç‚ºäº†ç°¡å–®ä¸€èˆ¬åªä½œä¸‰å±‚ï¼šè¼¸å…¥å±‚ã€éš±è—å±‚ï¼ˆhidden layerï¼‰ã€è¼¸å‡ºå±‚ã€‚å…¶ä¸­æ¯ä¸€å€‹ç¥ç¶“å…ƒï¼Œéƒ½èˆ‡å‰å¾Œå±‚ä¸­æ¯å€‹ç¥ç¶“å…ƒç›¸é€£ï¼ŒåŒæ¨£ç‚ºäº†ç°¡ä¾¿ï¼Œåœ¨æœ¬æ–‡çš„ä¾‹å­ä¸­æˆ‘å€‘æ¯ä¸€å±‚åªæœ‰å…©å€‹ç¥ç¶“å…ƒï¼Œç•«å‡ºçµæ§‹åœ–å¦‚ä¸‹ã€‚\na simple MLP network\n\né€™è£¡å¯ä»¥çœ‹åˆ°ï¼Œèˆ‡ä¸Šä¸€ç¯€ä¸åŒï¼Œç¥ç¶“å…ƒä¹‹é–“çš„é€£çµæ›´è¤‡é›œäº†ï¼Œä¸å†åªæ˜¯å¹³è¡Œåœ°é€£çµï¼›ä½†æ˜¯é€™è£¡ä¹Ÿåªæœ‰ä¸€æ¬¡ä¹˜æ³•ï¼ˆç·šæ€§é‹ç®—ï¼‰ï¼Œæ²’æœ‰äºŒæ¬¡çš„é …äº†ã€‚æ­¤å¤–ï¼Œå°æ¯ä¸€å€‹ç¥ç¶“å…ƒï¼ˆåœ“åœˆç¯€é»ï¼‰ï¼Œå¦‚ä¸Šåœ–å³å´æ‰€ç¤ºï¼ˆh1 ç‚ºä¾‹ï¼‰ï¼Œé™¤äº†æ¬Šé‡ w ä»¥å¤–ï¼Œé‚„æœ‰åŠ ä¸Šä¸€å€‹åç½® bï¼Œå¾ neth1 åˆ° outh1ï¼Œéœ€è¦ç¶“éä¸€å€‹å¯å¾®åˆ†çš„æ¿€æ´»å‡½æ•°ï¼Œé€™è£¡æˆ‘å€‘ä½¿ç”¨ sigmoid å‡½æ•°ï¼Œå®ƒçš„è¡¨é”å¼å’Œå¾®åˆ†ç‚ºï¼š$$\\begin{aligned}y = \\text{sigmoid}(x) = \\frac{1}{1+e^{-x}} \\\\\\frac{\\partial y}{\\partial x} = \\frac{e^x}{({1+e^{-x})}^2} = y \\cdot (1-y)\\end{aligned}$$\nç¾åœ¨æˆ‘å€‘çµ¦å®šè¼¸å…¥å€¼å’Œç›®æ¨™ï¼ˆè—è‰²ï¼‰ï¼Œä»¥åŠåˆå§‹åŒ–å€¼çš„æ¬Šé‡ï¼ˆç´…è‰²ï¼‰ï¼Œå’Œåˆå§‹åŒ–çš„åç½®ï¼ˆé»ƒè‰²ï¼Œå‡è¨­æ¯ä¸€å±‚çš„åç½®éƒ½ç›¸åŒï¼Œç‚ºäº†ç°¡ä¾¿ï¼‰ï¼Œé€™æ¨£ä¸€ä¾†ï¼Œç¨æœ‰å¸¸è­˜çš„äººéƒ½å¯ä»¥è¨ˆç®—å‡ºæ¯å€‹ç¥ç¶“å…ƒçš„æ¿€æ´»å€¼ï¼ˆç¶ è‰²ï¼‰ï¼Œå¦‚ä¸‹åœ–æ‰€ç¤ºã€‚æœ¬æ–‡å‡å‡å®šå°å„ç¨®æ­£å‘éç¨‹éƒ½å·²ç¶“éå¸¸äº†è§£ã€‚\nforward pass of MLP\n\nç¾åœ¨æˆ‘å€‘éœ€è¦è¨ˆç®—æ¯å€‹æ¬Šé‡å’Œåç½®ç›¸å°æ–¼æœ€çµ‚åå·®çš„æ¢¯åº¦ï¼Œæå¤±å‡½æ•°é€™è£¡ä½¿ç”¨ squared error function: \\(E_{total} = \\frac{1}{2} (target - output)^2\\)ï¼Œé‚£éº¼ \\(E_{o1} = \\frac{1}{2} (target_{o1} - output_{o1})^2 = \\frac{1}{2} (0.01 - 0.751)^2 = 0.2748\\)ï¼ŒåŒç† \\(E_{o2} = 0.0236\\)ã€‚\nä¸€èˆ¬ä¾†èªªï¼Œç¸½çš„æå¤±å°±æ˜¯äºŒè€…ä¹‹å’Œï¼Œå¯ä»¥èªªæ˜¯æ¬Šé‡ç›¸ç­‰ï¼Œéƒ½ç‚º 1ã€‚å¦‚æœæˆ‘å€‘çœ‹çœ‹ PyTorchï¼Œæˆ‘å€‘ç¸½æ˜¯éœ€è¦åœ¨ä¸€å€‹æ¨™é‡è€Œä¸æ˜¯å‘é‡ä¸Šä½¿ç”¨ .backward() è¨ˆç®—æ•´å€‹ graph çš„æ¢¯åº¦ï¼Œå¦‚æœåœ¨ä¸€å€‹å‘é‡ä¸Šä½¿ç”¨æœƒå ±éŒ¯ RuntimeError: grad can be implicitly created only for scalar outputsã€‚å°æ–¼ä¸€å€‹è¼¸å‡ºå‘é‡çš„å‡½æ•° \\(\\vec{y}=f(\\vec{x})\\)ï¼Œ\\(\\vec{y}\\) ç›¸å°æ–¼ \\(\\vec{x}\\) çš„æ¢¯åº¦æ˜¯ä¸€å€‹é›…å¯æ¯”çŸ©é™£ï¼ˆJacobian Matrixï¼‰ï¼š$$\\begin{split}J = \\left( \\begin{array}{ccc} \\frac{\\partial y_{1}}{\\partial x_{1}} &amp; \\cdots &amp; \\frac{\\partial y_{1}}{\\partial x_{n}} \\\\ \\vdots &amp; \\ddots &amp; \\vdots \\\\ \\frac{\\partial y_{m}}{\\partial x_{1}} &amp; \\cdots &amp; \\frac{\\partial y_{m}}{\\partial x_{n}} \\end{array} \\right)\\end{split}$$\ntorch.autograd ç”¨æ–¼è¨ˆç®— Vector-Jacobian Productï¼Œå®ƒä¸èƒ½ç›´æ¥è¨ˆç®—æ•´å€‹ Jacobian çŸ©é™£ã€‚ä¹Ÿå°±æ˜¯èªªï¼Œæˆ‘å€‘éœ€è¦çµ¦å®šä¸€å€‹å‘é‡ vï¼Œå»è¨ˆç®— \\(v^{T} \\cdot J\\)ã€‚å¦‚æœé€™å€‹ v æ­£å¥½æ˜¯æŸä¸€å€‹çµæœç‚ºæ¨™é‡çš„å‡½æ•° \\(l = g\\left(\\vec{y}\\right)\\) çš„æ¢¯åº¦ï¼Œä¹Ÿå°±æ˜¯èªª \\(v=\\left(\\begin{array}{ccc}\\frac{\\partial l}{\\partial y_{1}} &amp; \\cdots &amp; \\frac{\\partial l}{\\partial y_{m}}\\end{array}\\right)^{T}\\)ï¼Œé‚£éº¼æ ¹æ“šéˆå¼æ³•å‰‡ï¼Œé€™å€‹ä¹˜ç©æ˜¯ \\(l\\) ç›¸å°æ–¼ \\(\\vec{x}\\) çš„æ¢¯åº¦ï¼š$$\\begin{split}J^{T}\\cdot v= \\left(\\begin{array}{ccc} \\frac{\\partial y_{1}}{\\partial x_{1}} &amp; \\cdots &amp; \\frac{\\partial y_{m}}{\\partial x_{1}} \\\\ \\vdots &amp; \\ddots &amp; \\vdots \\\\ \\frac{\\partial y_{1}}{\\partial x_{n}} &amp; \\cdots &amp; \\frac{\\partial y_{m}}{\\partial x_{n}} \\end{array}\\right)\\left(\\begin{array}{c} \\frac{\\partial l}{\\partial y_{1}} \\\\ \\vdots \\\\ \\frac{\\partial l}{\\partial y_{m}} \\end{array}\\right)=\\left(\\begin{array}{c} \\frac{\\partial l}{\\partial x_{1}} \\\\ \\vdots \\\\ \\frac{\\partial l}{\\partial x_{n}} \\end{array}\\right)\\end{split}$$\næ‰€ä»¥å¦‚æœæˆ‘å€‘æƒ³åœ¨ä¸€å€‹å‘é‡ä¸Šä½¿ç”¨ vector.backward(v)ï¼Œæˆ‘å€‘éœ€è¦å‚³å…¥ä¸€å€‹ v = torch.tensor([weight1, weight2, ...])ï¼Œå®ƒè¡¨ç¤ºçš„å°±æ˜¯æ¯ä¸€å€‹æå¤±åœ¨ç¸½æå¤±ä¸­çš„æ¬Šé‡ï¼ˆå®ƒçš„åƒæ•°åç‚º gradientï¼Œä¹Ÿå¯ä»¥çœ‹ä½œæ˜¯é€™å€‹å‘é‡å°æŸä¸€å€‹å¤–éƒ¨æ¨™é‡çš„æ¢¯åº¦ï¼‰ã€‚å¦‚æœæˆ‘å€‘åœ¨ä¸€å€‹æ¨™é‡ä¸Šä½¿ç”¨ scalar.backward()ï¼Œé‚£éº¼ç„¡éœ€å‚³å…¥ä»»ä½•åƒæ•°ã€‚\nå›åˆ°é–‹å§‹çš„è©±é¡Œï¼Œæˆ‘å€‘ç¾åœ¨é–‹å§‹è¨ˆç®—æ¯ä¸€å€‹æ¬Šé‡é—œæ–¼æœ€çµ‚æå¤±çš„æ¢¯åº¦ï¼Œå°æ–¼è¼¸å‡ºå±‚çš„ w5ï½w8ï¼Œä»¥ w5 ç‚ºä¾‹ï¼Œé¦–å…ˆæˆ‘å€‘æœ‰ï¼Œç¸½æå¤±å°æ–¼ out o1 çš„æ¢¯åº¦ï¼š$$\\frac{\\partial L_{total}}{\\partial out_{o1}} =2 \\cdot \\frac{1}{2} \\cdot (target_{o1} - out_{o1}) * (-1)\\ +\\ 0= 0.7414$$ç¸½æå¤±çš„ç¬¬äºŒé … \\(E_{o2}\\) èˆ‡ out o1 æ²’æœ‰é—œä¿‚ï¼Œæ‰€ä»¥å°å…¶çš„æ¢¯åº¦ç‚º 0ã€‚\nè€Œ out o1 å°æ–¼ net o1ï¼Œå°±æ˜¯ sigmoid çš„æ¢¯åº¦ï¼Œ\\(\\frac{\\partial out_{o1}}{\\partial net_{o1}} = out_{o1} \\cdot (1 - out_{o1}) = 0.1868 \\)ã€‚å¹¾ä¹æ‰€æœ‰æ¿€æ´»å‡½æ•°æ˜¯å°æ¯ä¸€å€‹å…ƒç´ å–®ç¨åšçš„é‹ç®—ï¼Œä¸æ¶‰åŠç›¸äº’å½±éŸ¿ï¼ˆå³å°æ¯ä¸€å€‹å…ƒç´ ï¼Œæ“ä½œå…¬å¼éƒ½æ˜¯ç›¸åŒçš„ï¼‰ï¼Œæ‰€ä»¥è·Ÿä¸Šä¸€ç¯€çš„æƒ…æ³å®Œå…¨ç›¸åŒã€‚æ¢¯åº¦é€šéæ¿€æ´»å‡½æ•°æ™‚ï¼Œæ•´å€‹æ¢¯åº¦åœ–çš„å¤§å°æ˜¯ä¸æœƒæ”¹å¤‰çš„ã€‚\næœ€çµ‚ï¼Œæˆ‘å€‘çœ‹ net o1 å°æ–¼ w5ï¼Œæœ‰ \\(net_{o1} = w_5 * out_{h1}\\ +\\ w_6 * out_{h1}\\ +\\ b_2\\)ï¼Œæ‰€ä»¥ \\(\\frac{\\partial net_{o1}}{\\partial w_5} = out_{h1} = 0.5933\\)ã€‚æ‰€ä»¥æ ¹æ“šéˆå¼æ³•å‰‡ï¼Œæˆ‘å€‘æŠŠä¸Šè¿°ä¸‰é …ç›¸ä¹˜ï¼Œå°±å¾—åˆ°ç¸½æå¤± L å°æ–¼ w5 çš„æ¢¯åº¦ 0.7414 Ã— 0.1868 Ã— 0.5933 = 0.082ã€‚\nå¦‚æœåªæŠŠå‰å…©é …ç›¸ä¹˜ï¼Œæˆ‘å€‘å¾—åˆ° \\(\\frac{\\partial L_{total}}{\\partial net_{o1}}\\)ã€‚é€šå¸¸ï¼Œæˆ‘å€‘æŠŠç¸½æå¤±å°æŸä¸€å±‚ï¼ˆæˆ–æŸä¸€å€‹ç¥ç¶“å…ƒï¼‰æœªæ¿€æ´»ä¹‹å‰çš„çµæœï¼ˆå³ netï¼‰çš„å°æ•°è¨˜ä½œ \\(\\delta_{layer}\\)ï¼Œä¾‹å¦‚é€™è£¡å¯è¨˜ä½œ \\(\\delta_{o1}\\)ã€‚\n\n\nè¨ˆç®—è¼¸å‡ºå±‚çš„å…¶å®ƒæ¬Šé‡å’Œåç½®ä¹Ÿéƒ½é¡ä¼¼ã€‚å†çœ‹ä¸­é–“çš„éš±è—å±‚ï¼Œå®ƒè·Ÿè¼¸å‡ºå±‚çš„å€åˆ¥å°±æ˜¯ï¼Œå®ƒçš„å³å´èˆ‡å¤šå€‹ç¥ç¶“å…ƒç›¸é€£ï¼Œæ‰€ä»¥æ¢¯åº¦æœƒä¾†è‡ªæ–¼å³å´å¤šæ¢é€šè·¯ï¼Œæ‰€ä»¥$$\\begin{aligned}\\frac{\\partial L_{total}}{\\partial w_1} = &amp;\\frac{\\partial L_{total}}{\\partial out_{h1}} \\cdot \\frac{\\partial out_{h1}}{\\partial net_{h1}} \\cdot \\frac{\\partial net_{h1}}{\\partial w_1} \\\\= &amp; \\left(\\frac{\\partial L_{total}}{\\partial out_{o1}} \\cdot \\frac{\\partial out_{o1}}{\\partial net_{o1}} \\cdot \\frac{\\partial net_{o1}}{\\partial out_{h1}}\\ +\\ \\frac{\\partial L_{total}}{\\partial out_{o2}} \\cdot \\frac{\\partial out_{o2}}{\\partial net_{o2}} \\cdot \\frac{\\partial net_{o2}}{\\partial out_{h1}}\\right) \\\\&amp; \\cdot \\frac{\\partial out_{h1}}{\\partial net_{h1}} \\cdot \\frac{\\partial net_{h1}}{\\partial w_1} \\\\= &amp; (sum_o \\delta_o \\cdot w_{ho}) \\times out_{h1} (1 - out_{h1}) \\times i_1 \\\\= &amp; 0.0364 \\times 0.2413 \\times 0.05 = 0.000439\\end{aligned}$$\nçœ‹è‘—å¾ˆææ€–ï¼Œå…¶å¯¦ä¸¦ä¸è¤‡é›œã€‚ä»¥ç¬¬äºŒè¡ŒåŠ è™Ÿå·¦é‚Šçš„ä¸‰é …ç‚ºä¾‹ï¼Œå‰å…©é … \\(\\delta_{o1}\\) ä¸Šé¢å·²ç¶“ç®—éäº†ï¼›ç¬¬ä¸‰é …ä»ç„¶æœ‰ \\(net_{o1} = w_5 * out_{h1}\\ +\\ w_6 * out_{h1}\\ +\\ b_2\\)ï¼Œæ‰€ä»¥ \\(\\frac{\\partial net_{o1}}{\\partial out_{h1}} = w_5 = 0.40\\)ï¼Œç”±æ–¼é€™éƒ½æ˜¯ä¸€æ¬¡ç·šæ€§çš„é‹ç®—ï¼Œæ‰€ä»¥å°æ¬Šé‡æ±‚å°å°±å¾—è¼¸å…¥ï¼Œå°è¼¸å…¥æ±‚å°å°±å¾—æ¬Šé‡ï¼›å°æ–¼ç¬¬ä¸‰è¡Œï¼Œç¬¬ä¸€é …æ˜¯æ¿€æ´»å‡½æ•°ï¼Œå’Œä¸Šé¢ä¹Ÿä¸€æ¨£ï¼Œæœ€å¾Œä¸€é …æ˜¯å°æ¬Šé‡æ±‚å°ï¼Œæ‰€ä»¥å¾—è¼¸å…¥å€¼ i1ã€‚\né€™è£¡ä¹Ÿçœ‹åˆ°ä¸€ä»¶äº‹ï¼Œå°±æ˜¯è¶Šå¾€å¾Œæ¢¯åº¦è¶Šä¾†è¶Šå°äº†ï¼Œå› ç‚ºä¹˜ä¸Šå°æ–¼ä¸€çš„é …è¶Šä¾†è¶Šå¤šï¼Œã€Œæ¢¯åº¦æ¶ˆå¤±ã€èªªçš„å°±æ˜¯é€™éº¼å›äº‹ã€‚\nå¦‚ä½•ç°¡æ˜åœ°å¯¦ç¾é¡¯ç„¶å°æ–¼æ¯ä¸€å€‹æ¬Šé‡ï¼Œæˆ‘å€‘ä¸æ‡‰ç•¶å¾æå¤±å‡½æ•°é–‹å§‹ä¸€å€‹ä¸€å€‹åœ°è¨ˆç®—åˆ°æœ€å¾Œï¼Œè€Œæ˜¯æ‡‰ç•¶å…ˆè¨ˆç®—ä¸€ç´šï¼ˆè¼¸å‡ºå±‚ï¼‰ï¼Œç„¶å¾ŒæŠŠä¸€äº›è¨ˆç®—çµæœå‚³çµ¦å‰ä¸€ç´šï¼ˆéš±è—å±‚ï¼‰ï¼Œç„¶å¾Œå‰ä¸€ç´šæ‹¿åˆ°é€™å€‹çµæœåªéœ€è¨ˆç®—å’Œä»–ç›´æ¥ç›¸é€£çš„éƒ¨åˆ†ã€‚å¯¦éš›ä½¿ç”¨ä¸Šï¼Œå…¨é€£æ¥å±‚ä¹Ÿæ˜¯ä¸€å€‹æ•´é«”ï¼Œè‚¯å®šä¸æœƒä¸€å€‹ä¸€å€‹ç¥ç¶“å…ƒå–®ç¨è¨ˆç®—ã€‚\næˆ‘å€‘åœ¨å¾—åˆ° [\\(\\delta_{o1}\\), \\(\\delta_{o2}\\)] ä¹‹å¾Œï¼Œå¯ä»¥ä½œç‚ºä¸€å€‹æ•´é«”å‚³çµ¦å¾Œä¸€å±‚ï¼Œç„¶å¾Œåšä¸€å€‹çŸ©é™£ä¹˜æ³• \\(\\cdot \\begin{bmatrix} w_5 &amp; w_6 \\\\ w_7 &amp; w_8 \\end{bmatrix}\\)ã€‚\n\nå°æ–¼ç´”å…¬å¼çš„æ¨å°ï¼Œå¯ä»¥åƒè€ƒ åå‘ä¼ æ’­ç®—æ³•æ¨å¯¼-å…¨è¿æ¥ç¥ç»ç¶²ç»œ\n\nå°æ–¼æ˜“æ‡‚çš„ä»£ç¢¼ï¼Œå¯ä»¥åƒè€ƒ How to Code a Neural Network with Backpropagation In Python (from scratch)\n\n\nå·ç©å±‚ä¸­çš„åå‘å‚³æ’­å·ç©å±‚è‡ªç„¶æ˜¯å·ç©ç¥ç¶“ç¶²çµ¡çš„é—œéµï¼Œæ‰€ä»¥é€™ä¸€éƒ¨åˆ†å…ˆæœƒèªªå¾—æ¯”è¼ƒæŠ½è±¡å’Œæ³›åŒ–ã€‚å°æ–¼å·ç©å±‚ï¼Œåœ¨é‹ç®—ä¸Šèˆ‡ä¸Šä¸€ç¯€æ²’æœ‰ä»€éº¼ä¸åŒï¼Œæ‰€ä»¥æˆ‘å€‘å¯ä»¥é æ–™å°æ¬Šé‡æ±‚å°å°±å¾—è¼¸å…¥ï¼Œå°è¼¸å…¥æ±‚å°å°±å¾—æ¬Šé‡é‚„æ˜¯ä¸€æ¨£çš„ã€‚å€åˆ¥åœ¨æ–¼å‰å¾Œçš„é€£çµæ–¹å¼ï¼Œå·ç©å±‚æ˜¯ç¨€ç–çš„é€£æ¥ï¼Œä¸€å€‹ç¥ç¶“å…ƒä¸¦ä¸æœƒå’Œå¾Œä¸€ç´šæ‰€æœ‰ç¥ç¶“å…ƒç›¸é€£ï¼Œæ­¤å¤–ï¼Œæ¬Šé‡æœƒæœ‰å¾©ç”¨ï¼Œæ‰€ä»¥ä¸åŒçš„é€£ç·šï¼Œä¸è¡¨ç¤ºé€™å€‹é€£ç·šä¸Šçš„æ¬Šé‡ä¸åŒï¼Œå¦‚ä¸‹åœ–ã€‚ç•¶å·ç©æ ¸å¤§å°ç­‰æ–¼è¼¸å…¥åœ–æ™‚ï¼Œå·ç©å±‚å°±å¤‰ç‚ºä¸€å€‹å…¨é€£æ¥å±‚ï¼Œæ‰€ä»¥é€™è£¡æœƒæ˜¯ä¸Šé¢ä¸€ç¯€é€²ä¸€æ­¥æŠ½è±¡ã€æ³›åŒ–çš„åå‘å‚³æ’­æ–¹å¼ã€‚\nforward pass of conv\n\nç¬¦è™Ÿèªªæ˜ï¼š\n\nå·ç©æ ¸ \\(w\\) çš„å°ºå¯¸ç‚º \\(k_1 \\times k_2\\)ï¼Œ\\(w_{m,n}^l\\) è¡¨ç¤ºé€™å€‹å·ç©æ ¸å…§é€šé“ç‚º \\(l\\)ï¼Œä½ç½®ç‚º \\(m, n\\) çš„åƒæ•°å€¼ã€‚\n\n\\(x_{i,j}^l\\) è¡¨ç¤ºä¸€å€‹å·ç©çš„çµæœï¼Œå®ƒæ˜¯ç”±ä¸Šä¸€å±‚çš„è¼¸å‡ºèˆ‡å·ç©æ ¸æ¬Šé‡ç›¸ä¹˜åŠ ä¸Šåç½®å€¼å¾—åˆ°ã€‚è¼¸å…¥ç‰¹å¾µåœ– \\(O\\)ï¼ˆå³é€²è¡Œå·ç©ä¹‹å‰çš„ï¼‰çš„å°ºå¯¸ä½¿ç”¨ \\(H \\times W\\) è¡¨ç¤ºï¼Œ \\(i, j\\) ç‚ºç‰¹å¾µåœ–ä¸Šçš„æŸä¸€å€‹ä½ç½®ã€‚$$x_{i,j}^l = \\sum_{m = 0}^{k_1 - 1} \\sum_{n = 0}^{k_2 - 1} w_{m,n}^l o_{i + m,j + n}^{l-1} + b^l$$\n\n\\(o_{i,j}^l\\) ç‚ºæ¿€æ´»å‡½æ•°çš„è¼¸å‡ºå€¼ï¼Œå³ \\(o_{i,j}^l = f(x_{i,j}^{l})\\)ï¼Œ\\(f(\\cdot)\\) è¡¨ç¤ºæŸç¨®æ¿€æ´»å‡½æ•°ã€‚\n\n\n\n\n\nå‡è¨­é€²è¡Œçš„æ˜¯ padding=0, stride=1 çš„å·ç©ï¼Œé‚£éº¼æ­£å‘éç¨‹å¦‚ç¬¦è™Ÿèªªæ˜å…§çš„å…¬å¼ï¼Œ\\(\\delta w_{m^{\\prime},n^{\\prime}}^l\\) ç‚º$$\\frac{\\partial L}{\\partial w_{m^{\\prime},n^{\\prime}}^l} = \\sum_{i=0}^{H-k_1} \\sum_{j=0}^{W-k_2} \\frac{\\partial L}{\\partial x_{i,j}^{l}} \\frac{\\partial x_{i,j}^{l}}{\\partial w_{m^{\\prime},n^{\\prime}}^l} \\tag{1}$$\né€™è£¡çš„ \\(x_{i,j}^l\\) å°±æ˜¯ä¸Šä¸€ç¯€ä¸­çš„ net å±‚ä¸­çš„å…ƒç´ ï¼Œæ¯”å¦‚ net h1ã€net o1ã€‚æ‰€ä»¥é€™å€‹å…¬å¼è¡¨ç¤ºçš„å°±æ˜¯ç›´é”æ¬Šé‡çš„æœ€å¾Œä¸€æ­¥ï¼Œç¬¬äºŒé …é¡ä¼¼æ–¼ä¹‹å‰çš„ \\(\\frac{\\partial net_{h1}}{\\partial w_1}\\)ï¼Œç¬¬ä¸€é … \\(\\delta x_{i,j}^{l}\\) å¦‚å‰æ‰€è¿°æ˜¯å¾å‰æ–¹å±‚å‚³ééä¾†çš„ï¼Œåœ¨é€™è£¡æ˜¯å€‹å·²çŸ¥å€¼ã€‚ç©åˆ†çš„å€åŸŸç‚ºå·ç©æ ¸ä¸Šçš„é€™å€‹åƒæ•°è§¸åŠçš„å€åŸŸã€‚\nåˆæœ‰$$x_{i,j}^l = \\sum_{m = 0}^{k_1 - 1} \\sum_{n = 0}^{k_2 - 1} w_{m,n}^l o_{i + m,j + n}^{l-1} + b^l$$\næ‰€ä»¥ç¬¬äºŒé …æœ‰$$\\frac{\\partial x_{i,j}^{l}}{\\partial w_{m^{\\prime},n^{\\prime}}^l} = \\frac{\\partial}{\\partial w_{m^{\\prime},n^{\\prime}}^l}\\left( \\sum_{m} \\sum_{n} w_{m,n}^{l}o_{i+m, j+n}^{l-1} + b^l \\right)$$\nç¹¼çºŒé€²ä¸€æ­¥å±•é–‹ï¼Œå·ç©æ ¸å…§çš„æ¯ä¸€å€‹æ¬Šé‡é¡¯ç„¶æ˜¯ç¨ç«‹çš„ï¼Œå‰ä¸€å±‚çš„è¼¸å‡º o é¡¯ç„¶ä¹Ÿä¸å—é€™å€‹å·ç©æ ¸çš„å½±éŸ¿ï¼Œæ‰€ä»¥å±•é–‹å¾Œï¼Œåªæœ‰ä¸€é …æ±‚åå°ä¸ç‚ºé›¶$$\\begin{align}\\frac{\\partial x_{i,j}^{l}}{\\partial w_{m^{\\prime},n^{\\prime}}^l} &amp;= \\frac{\\partial}{\\partial w_{mâ€™,nâ€™}^l}\\left( w_{0,0}^{l} o_{ i + 0, j + 0}^{l-1} + \\dots + w_{mâ€™,nâ€™}^{l} o_{ i + m^{\\prime}, j + n^{\\prime}}^{l-1} + \\dots + b^l\\right) \\\\&amp; = \\frac{\\partial}{\\partial w_{m^{\\prime},n^{\\prime}}^l}\\left( w_{m^{\\prime},n^{\\prime}}^{l} o_{ i + m^{\\prime}, j + n^{\\prime}}^{l-1}\\right) \\\\&amp; = o_{i+m^{\\prime},j+n^{\\prime}}^{l-1}\\end{align}$$\næŠŠé€™å€‹çµè«–ä»£å…¥æœ€é–‹å§‹çš„å…¬å¼ï¼ˆ1ï¼‰ï¼š$$\\frac{\\partial L}{\\partial w_{mâ€™,nâ€™}^l} = \\sum_{i=0}^{H-k_1} \\sum_{j=0}^{W-k_2} \\delta x_{i,j}^{l} \\cdot o_{ i + m^{\\prime}, j + n^{\\prime}}^{l-1} \\tag{2}$$\né€™å€‹å¼å­è£¡é¢é›™é‡æ±‚å’Œå°±æ˜¯æ¬Šé‡å…±äº«çš„çµæœï¼Œéš¨è‘— k1ï¼Œk2 çš„å¢å¤§ï¼Œå·ç©æ ¸çš„å¤§å°é€æ¼¸æ¥è¿‘æ–¼è¼¸å…¥ç‰¹å¾µåœ–ï¼Œé€™å€‹æ±‚å’Œå€åŸŸä¹Ÿé€æ¼¸æ¸›å°ã€‚ç•¶æ ¸çš„å¤§å°ç­‰æ–¼ç‰¹å¾µåœ–å¤§å°æ™‚ï¼Œé€™å€‹å¼å­èˆ‡ä¸Šä¸€ç¯€ä¸­çš„å…¨é€£æ¥çš„å½¢å¼ç›¸åŒã€‚åŒæ™‚æˆ‘å€‘å°æ¯”ä¸€ä¸‹æœ€é–‹å§‹çš„å·ç©å…¬å¼ï¼š$$x_{i,j}^l = \\sum_{m = 0}^{k_1 - 1} \\sum_{n = 0}^{k_2 - 1} w_{m,n}^l o_{i + m,j + n}^{l-1} + b^l$$\nå°±ç™¼ç¾é€™å€‹ï¼ˆgradients of L w.r.t to the weightï¼‰æ±‚å°çš„å…¬å¼å…¶å¯¦å°±æ˜¯å€‹å·ç©æ“ä½œï¼Œè¼¸å…¥æ˜¯ \\(O^{l-1}\\)ï¼Œå·ç©æ ¸æ˜¯å‰æ–¹å±‚å‚³ä¾†çš„æ¢¯åº¦åœ–ï¼ˆgradients of L w.r.t to the feature mapsï¼‰ï¼Œè¡¨ç¤ºç‰¹å¾µåœ–ä¸Šä¸€å€‹å€¼çš„å¤‰å‹•ï¼Œæœƒå°æå¤±å€¼é€ æˆå¤šå¤§å½±éŸ¿ã€‚é€™å€‹æ¢¯åº¦åœ–é¡¯ç„¶ä¹Ÿä¸æ˜¯æ†‘ç©ºç”¢ç”Ÿçš„ï¼Œæˆ‘å€‘ç¾åœ¨å°±é‚„è¦è¨ˆç®—å®ƒã€‚\nå°æ–¼ä¸€å€‹ \\(x_{i,j}^l\\)ï¼Œå®ƒåœ¨ l+1 å±‚ä¸­çš„å½±éŸ¿å€åŸŸæ˜¯å·¦ä¸Šè§’ \\(\\left(i^{\\prime}-k_1+1,j^{\\prime}-k_2+1 \\right)\\) åˆ°å³ä¸‹è§’ \\(\\left(i^{\\prime},j^{\\prime} \\right)\\) ä¸­é–“çš„çŸ©å½¢å€åŸŸã€‚é‚£éº¼\n$$\\begin{align}\\frac{\\partial L}{\\partial x_{iâ€™,jâ€™}^{l}} &amp;= \\sum_{m = 0}^{k_1 -1} \\sum_{n = 0}^{k_2 -1} \\frac{\\partial E}{\\partial x_{iâ€™-m, jâ€™-n}^{l+1}}\\frac{\\partial x_{iâ€™-m, jâ€™-n}^{l+1}}{\\partial x_{iâ€™,jâ€™}^l} \\\\&amp;= \\sum_{m = 0}^{k_1 -1} \\sum_{n = 0}^{k_2 -1} \\delta_{iâ€™-m, jâ€™-n}^{l+1} \\frac{\\partial x_{iâ€™-m, jâ€™-n}^{l+1}}{\\partial x_{iâ€™,jâ€™}^l} \\tag{3} \\\\\\end{align}$$\né‚„æ˜¯ä¸€æ¨£åœ°çœ‹ç¬¬äºŒé …ï¼Œå±•é–‹è£¡é¢çš„ xï¼š$$\\begin{align}\\frac{\\partial x_{iâ€™-m,jâ€™-n}^{l+1}}{\\partial x_{iâ€™,jâ€™}^l} &amp;= \\frac{\\partial}{\\partial x_{iâ€™,jâ€™}^l} \\left( \\sum_{mâ€™=0}^{k_1^{l+1} -1} \\sum_{nâ€™=0}^{k_2^{l+1} -1} w_{mâ€™, nâ€™}^{l+1} o_{iâ€™ - m + mâ€™,jâ€™ - n + nâ€™}^{l} + b^{l+1} \\right) \\\\&amp;= \\frac{\\partial}{\\partial x_{iâ€™,jâ€™}^l}\\left( \\sum_{mâ€™=0}^{k_1^{l+1} -1} \\sum_{nâ€™=0}^{k_2^{l+1} -1} w_{mâ€™,nâ€™}^{l+1}f\\left(x_{iâ€™ - m + mâ€™,jâ€™ - n + nâ€™}^{l}\\right) + b^{l+1} \\right)\\end{align}$$\nç¹¼çºŒå±•é–‹å…©å€‹æ±‚å’Œï¼Œåœ¨é€™è£¡åŒæ¨£ï¼Œä¸‹ä¸€å±‚çš„æ¬Šé‡ä¸æœƒå—é€™ä¸€å±‚çš„ç‰¹å¾µåœ–çš„å½±éŸ¿ï¼Œä¸€å€‹ç‰¹å¾µåœ–ä¹‹å…§çš„å„å€‹å€¼ä¹Ÿæ˜¯ç¨ç«‹çš„ï¼Œæ‰€ä»¥å®ƒå€‘çš„åå°éƒ½ç‚ºé›¶ï¼š$$\\begin{align}\\frac{\\partial x_{i^{\\prime} - m,j^{\\prime} - n}^{l+1}}{\\partial x_{iâ€™,jâ€™}^l}&amp;= \\frac{\\partial}{\\partial x_{iâ€™,jâ€™}^l}\\left( w_{mâ€™,nâ€™}^{l+1} f(x_{ 0 - m + mâ€™, 0 - n + nâ€™}^{l}) + \\dots + w_{m,n}^{l+1} f(x_{iâ€™,jâ€™}^{l}) + \\dots + b^{l+1}\\right) \\\\&amp;= \\frac{\\partial}{\\partial x_{iâ€™,jâ€™}^l}\\left( w_{m,n}^{l+1} f(x_{iâ€™,jâ€™}^{l}) \\right) \\\\&amp;= w_{m,n}^{l+1} \\frac{\\partial}{\\partial x_{iâ€™,jâ€™}^l} \\left( f(x_{iâ€™,jâ€™}^{l}) \\right) \\\\&amp;= w_{m,n}^{l+1} fâ€™(x_{iâ€™,jâ€™}^{l})\\end{align}$$\næŠŠé€™å€‹çµè«–ä»£å›é–‹å§‹çš„å…¬å¼ï¼ˆ3ï¼‰ï¼š$$\\frac{\\partial E}{\\partial x_{iâ€™,jâ€™}^{l}} =fâ€™(x_{iâ€™,jâ€™}^{l}) \\cdot \\sum_{m = 0}^{k_1^{l+1} - 1} \\sum_{n = 0}^{k_2^{l+1} - 1} \\delta_{iâ€™-m, jâ€™-m}^{l+1} w_{m,n}^{l+1} \\tag{4}$$\né€™åŒæ¨£æ˜¯ä¸€å€‹å·ç©ï¼Œåªæ˜¯ i-m, j-n è¡¨ç¤ºæˆ‘å€‘éœ€è¦æŠŠå·ç©æ ¸åè½‰ 180 åº¦ã€‚é€™å€‹å·ç©çš„è¼¸å…¥æ˜¯æ›´å‰é¢å±‚å‚³å›çš„ \\(\\delta_{iâ€™-m, jâ€™-m}^{l+1}\\)ï¼Œå·ç©æ ¸æ˜¯ l+1 å±‚çš„æ¬Šé‡ï¼Œè€Œ \\(fâ€™(x_{iâ€™,jâ€™}^{l})\\) é€™å€‹æ¿€æ´»å‡½æ•°çš„å°æ•°æ˜¯å€‹å¸¸æ•°ï¼Œå‰é¢ä¹Ÿæåˆ°äº†ï¼Œå®ƒæ˜¯å°æ¯å€‹å…ƒç´ å–®ç¨åšçš„ã€‚\nå…¬å¼ï¼ˆ2ï¼‰å’Œï¼ˆ4ï¼‰å°±æ˜¯åå‘å‚³æ’­çš„æ ¸å¿ƒï¼Œå‰è€…ç”¨æ–¼æ›´æ–°åƒæ•°ï¼Œå¾Œè€…ç”¨æ–¼å°‡å°ç¸½æå¤±çš„æ¢¯åº¦å‘å¾Œå‚³æ’­ï¼Œç”¨æ–¼å¾Œä¸€å±‚çš„è¨ˆç®—ã€‚åŒæ™‚ï¼Œé€™è£¡æˆ‘å€‘çœ‹åˆ°ï¼Œå·ç©æ±‚æ¢¯åº¦ä¹Ÿæ˜¯ç”±å·ç©å®Œæˆï¼Œæ‰€ä»¥æœ‰äº›åœ°æ–¹æœƒèªªåå·ç©å°±æ˜¯ç”¨å·ç©çš„æ¢¯åº¦ã€‚\nç°¡å–®ä¾‹å­å’Œä»£ç¢¼ä¸Šè¿°åˆ†æå¯ä»¥çœ‹å‡ºï¼Œå½¢å¼éƒ½æ˜¯é¡ä¼¼çš„ï¼Œä½†æ˜¯æœ‰é»æŠ½è±¡ï¼Œé€™è£¡æˆ‘å€‘çœ‹ä¸€å€‹å…·é«”çš„ä¾‹å­å¹«åŠ©ç†è§£ã€‚ä¸‹é¢çš„åœ–æ˜¯ä¸€å€‹å·ç©çš„æ­£å‘éç¨‹ï¼Œé€™è£¡æˆ‘å€‘ç•¥å» biasã€‚\nfoward pass of a simple conv example\n\n$$\\begin{align}X_{11} = W_{11} O_{11} + W_{12} O_{12} + W_{21} O_{21} + W_{22} O_{22} \\\\X_{12} = W_{11} O_{12} + W_{12} O_{13} + W_{21} O_{22} + W_{22} O_{23} \\\\X_{21} = W_{11} O_{21} + W_{12} O_{22} + W_{21} O_{31} + W_{22} O_{32} \\\\X_{22} = W_{11} O_{22} + W_{12} O_{23} + W_{21} O_{32} + W_{22} O_{33} \\\\\\end{align}$$\næŠŠä¸Šé¢å››å€‹å¼å­åŠ åœ¨ä¸€èµ·ï¼Œç„¶å¾Œåˆ†åˆ¥å°å››å€‹åƒæ•°æ±‚åå°ï¼Œå¯å¾—\n$$\\begin{align}\\frac{\\partial L}{\\partial W_{11}} = \\frac{\\partial L}{\\partial X_{11}} \\frac{\\partial X_{11}}{\\partial W_{11}} + \\frac{\\partial L}{\\partial X_{12}} \\frac{\\partial X_{12}}{\\partial W_{11}} + \\frac{\\partial L}{\\partial X_{21}} \\frac{\\partial X_{21}}{\\partial W_{11}} + \\frac{\\partial L}{\\partial X_{22}} \\frac{\\partial X_{22}}{\\partial W_{11}} \\\\\\frac{\\partial L}{\\partial W_{12}} = \\frac{\\partial L}{\\partial X_{11}} \\frac{\\partial X_{11}}{\\partial W_{12}} + \\frac{\\partial L}{\\partial X_{12}} \\frac{\\partial X_{12}}{\\partial W_{12}} + \\frac{\\partial L}{\\partial X_{21}} \\frac{\\partial X_{21}}{\\partial W_{12}} + \\frac{\\partial L}{\\partial X_{22}} \\frac{\\partial X_{22}}{\\partial W_{12}} \\\\\\frac{\\partial L}{\\partial W_{21}} = \\frac{\\partial L}{\\partial X_{11}} \\frac{\\partial X_{11}}{\\partial W_{21}} + \\frac{\\partial L}{\\partial X_{12}} \\frac{\\partial X_{12}}{\\partial W_{21}} + \\frac{\\partial L}{\\partial X_{21}} \\frac{\\partial X_{21}}{\\partial W_{12}} + \\frac{\\partial L}{\\partial X_{22}} \\frac{\\partial X_{22}}{\\partial W_{21}} \\\\\\frac{\\partial L}{\\partial W_{22}} = \\frac{\\partial L}{\\partial X_{11}} \\frac{\\partial X_{11}}{\\partial W_{22}} + \\frac{\\partial L}{\\partial X_{12}} \\frac{\\partial X_{12}}{\\partial W_{22}} + \\frac{\\partial L}{\\partial X_{21}} \\frac{\\partial X_{21}}{\\partial W_{22}} + \\frac{\\partial L}{\\partial X_{22}} \\frac{\\partial X_{22}}{\\partial W_{22}} \\\\\\end{align}$$\næˆ‘å€‘åœ¨ä¹‹å‰å·²ç¶“çŸ¥é“ï¼Œ\\(\\frac{\\partial X}{\\partial W} = O\\)ï¼Œæ‰€ä»¥ä¸Šé¢çš„å¼å­å¯ä»¥å¯«æˆ$$\\begin{align}\\frac{\\partial L}{\\partial W_{11}} = \\frac{\\partial L}{\\partial X_{11}} O_{11} + \\frac{\\partial L}{\\partial X_{12}} O_{12} + \\frac{\\partial L}{\\partial X_{21}} O_{21} + \\frac{\\partial L}{\\partial X_{22}} O_{22} \\\\\\frac{\\partial L}{\\partial W_{12}} = \\frac{\\partial L}{\\partial X_{11}} O_{12} + \\frac{\\partial L}{\\partial X_{12}} O_{13} + \\frac{\\partial L}{\\partial X_{21}} O_{22} + \\frac{\\partial L}{\\partial X_{22}} O_{23} \\\\\\frac{\\partial L}{\\partial W_{21}} = \\frac{\\partial L}{\\partial X_{11}} O_{21} + \\frac{\\partial L}{\\partial X_{12}} O_{22} + \\frac{\\partial L}{\\partial X_{21}} O_{31} + \\frac{\\partial L}{\\partial X_{22}} O_{32} \\\\\\frac{\\partial L}{\\partial W_{22}} = \\frac{\\partial L}{\\partial X_{11}} O_{22} + \\frac{\\partial L}{\\partial X_{12}} O_{23} + \\frac{\\partial L}{\\partial X_{21}} O_{32} + \\frac{\\partial L}{\\partial X_{22}} O_{33} \\\\\\end{align}$$\nå¦‚æœä»”ç´°çœ‹çœ‹ï¼Œé€™å€‹å½¢å¼ï¼Œå…¶å¯¦å°±æ˜¯å·ç©ï¼Œå·ç©çš„è¼¸å…¥æ˜¯æ­£å‘éç¨‹ç›¸åŒçš„è¼¸å…¥ï¼Œå·ç©æ ¸æ˜¯å¾å¾Œä¸€å±‚å‚³éä¾†çš„æ¢¯åº¦åœ–ï¼Œå¦‚ä¸‹åœ–æ‰€ç¤ºã€‚\nweight gradient calculation as conv\n\nç¾åœ¨æˆ‘å€‘å¾—åˆ°äº†å·ç©æ ¸ W çš„æ¯å€‹å…ƒç´ å°æ–¼æœ€çµ‚æå¤±çš„æ¢¯åº¦ï¼Œæˆ‘å€‘å¯ä»¥æ›´æ–°é€™å€‹å·ç©æ ¸çš„åƒæ•°äº†ã€‚åŒæ¨£ï¼Œä¸‹ä¸€ä»¶äº‹æ˜¯ï¼Œå¾—åˆ°è¼¸å…¥ç‰¹å¾µåœ– O ä¸Šæ¯å€‹å…ƒç´ é—œæ–¼æœ€çµ‚æå¤±çš„æ¢¯åº¦ï¼Œé€™æ¨£æˆ‘å€‘æ‰å¯ä»¥æŠŠé€™å€‹æ¢¯åº¦ç¹¼çºŒå‘å¾Œå‚³æ’­ã€‚\nåŒæ¨£æŠŠå››å€‹å¼å­ç›¸åŠ ï¼Œç„¶å¾Œæ±‚åå°ï¼Œçµæœå¦‚ä¸‹ï¼š$$\\begin{align}\\frac{\\partial L}{\\partial O_{11}} = \\frac{\\partial L}{\\partial X_{11}} W_{11} + \\frac{\\partial L}{\\partial X_{12}} \\cdot 0 + \\frac{\\partial L}{\\partial X_{21}} \\cdot 0 + \\frac{\\partial L}{\\partial X_{22}} \\cdot 0 \\\\\\frac{\\partial L}{\\partial O_{12}} = \\frac{\\partial L}{\\partial X_{11}} W_{12} + \\frac{\\partial L}{\\partial X_{12}} W_{11} + \\frac{\\partial L}{\\partial X_{21}} \\cdot 0 + \\frac{\\partial L}{\\partial X_{22}} \\cdot 0 \\\\\\frac{\\partial L}{\\partial O_{13}} = \\frac{\\partial L}{\\partial X_{11}} \\cdot 0 + \\frac{\\partial L}{\\partial X_{12}} W_{12} + \\frac{\\partial L}{\\partial X_{21}} \\cdot 0 + \\frac{\\partial L}{\\partial X_{22}} \\cdot 0 \\\\\\frac{\\partial L}{\\partial O_{21}} = \\frac{\\partial L}{\\partial X_{11}} W_{21} + \\frac{\\partial L}{\\partial X_{12}} \\cdot 0 + \\frac{\\partial L}{\\partial X_{21}} W_{11} + \\frac{\\partial L}{\\partial X_{22}} \\cdot 0 \\\\\\frac{\\partial L}{\\partial O_{22}} = \\frac{\\partial L}{\\partial X_{11}} W_{22} + \\frac{\\partial L}{\\partial X_{12}} W_{21} + \\frac{\\partial L}{\\partial X_{21}} W_{12} + \\frac{\\partial L}{\\partial X_{22}} W_{11} \\\\\\frac{\\partial L}{\\partial O_{23}} = \\frac{\\partial L}{\\partial X_{11}} \\cdot 0 + \\frac{\\partial L}{\\partial X_{12}} W_{22} + \\frac{\\partial L}{\\partial X_{21}} \\cdot 0 + \\frac{\\partial L}{\\partial X_{22}} W_{11} \\\\\\frac{\\partial L}{\\partial O_{31}} = \\frac{\\partial L}{\\partial X_{11}} \\cdot 0 + \\frac{\\partial L}{\\partial X_{12}} \\cdot 0 + \\frac{\\partial L}{\\partial X_{21}} W_{21} + \\frac{\\partial L}{\\partial X_{22}} W_{11} \\\\\\frac{\\partial L}{\\partial O_{32}} = \\frac{\\partial L}{\\partial X_{11}} \\cdot 0 + \\frac{\\partial L}{\\partial X_{12}} \\cdot 0 + \\frac{\\partial L}{\\partial X_{21}} W_{22} + \\frac{\\partial L}{\\partial X_{22}} W_{21} \\\\\\frac{\\partial L}{\\partial O_{33}} = \\frac{\\partial L}{\\partial X_{11}} \\cdot 0 + \\frac{\\partial L}{\\partial X_{12}} \\cdot 0 + \\frac{\\partial L}{\\partial X_{21}} \\cdot 0 + \\frac{\\partial L}{\\partial X_{22}} W_{22} \\\\\\end{align}$$\né€™çœ‹èµ·ä¾†é¡¯ç„¶ä¹Ÿæ˜¯ä¸€ç¨®å·ç©æ“ä½œï¼Œæœ‰äººæŠŠå®ƒå«åšå…¨å·ç©ï¼ˆå®Œå…¨çš„ã€Œå…¨ã€ï¼Œä¸æ˜¯å…¨éƒ¨çš„ã€Œå…¨ã€ï¼‰ï¼Œç¤ºæ„åœ–åœ¨ä¸‹é¢ï¼Œç°¡å–®èªªå°±æ˜¯ padding = 1ã€‚é€™è£¡æˆ‘å€‘éœ€è¦ç”¨åˆ°æ­£å‘éç¨‹ä¸­çš„å·ç©æ ¸ï¼Œå°‡å®ƒæ—‹è½‰ 180 åº¦å¾Œä½¿ç”¨ã€‚\ninput gradient calculation as full conv\n\nfull conv operation schematic diagram\n\né€™è£¡æœ‰ä¸€å€‹ç°¡å–®çš„ä»£ç¢¼æè¿°ä¸Šé¢çš„éç¨‹\n\n\n\n\næœ€é–‹å§‹çš„å•é¡Œå¾ä¸Šé¢æˆ‘å€‘å¯ä»¥çœ‹å‡ºï¼Œåœ¨åå‘å‚³æ’­çš„éç¨‹ä¸­ï¼Œé™¤äº†æå¤±å°åƒæ•°çš„æ¢¯åº¦æ˜¯å¿…é ˆè¦è¨ˆç®—ä»¥åŠå„²å­˜ä¹‹å¤–ï¼Œæˆ‘å€‘é‚„å¿…é ˆè¨ˆç®—ä¸€å€‹æå¤±å°ç‰¹å¾µåœ–çš„æ¢¯åº¦ï¼Œä¸¦ä¸”è¦æŠŠå®ƒå‚³çµ¦å¾Œä¸€å±‚ã€‚\nä»€éº¼æ˜¯è‘‰å­ç¯€é»ï¼Œç›´è§€å°±æ˜¯å°±æ˜¯ä¸åœ¨ã€Œè–ã€ä¸Šçš„ï¼Œå¾ŒçºŒæ²’æœ‰å…¶å®ƒç¯€é»çš„ç¯€é»ï¼Œå…¶å¯¦æ˜¯å€‹å¾ˆå¸¸è¦‹çš„æ¦‚å¿µã€‚åœ¨é€™è£¡èªªäººè©±å°±æ˜¯ç›´æ¥ç”±ç”¨æˆ¶å‰µå»ºï¼Œè€Œä¸æ˜¯å¾å¦ä¸€å€‹ç¯€é»è¨ˆç®—å¾—åˆ°çš„ç¯€é»ï¼ˆA leaf Variable is a variable that is at the beginning of the graphï¼‰ã€‚ç¥ç¶“ç¶²çµ¡ä¸­çš„åƒæ•°éƒ½æ˜¯ leaf tensorï¼Œè€Œä¸­é–“çš„æ‰€æœ‰ç‰¹å¾µåœ–å’Œè¼¸å‡ºéƒ½ä¸æ˜¯ leaf tensorï¼Œè¼¸å…¥åœ–å¯ä»¥æ˜¯ï¼Œä½†æ˜¯ä¸€èˆ¬æ²’äººè¨ˆç®—å®ƒçš„æ¢¯åº¦ã€‚å·§çš„æ˜¯å•æˆ‘é‚£å€‹å•é¡Œå°±æ˜¯å› ç‚ºä»–çš„å„ªåŒ–å°è±¡æ˜¯è¼¸å…¥åœ–åƒï¼ˆå¯è¦–åŒ–ã€é¢¨æ ¼é·ç§»é€™äº›ä»»å‹™ä¸Šæœ‰æ™‚éœ€é€™æ¨£åšï¼‰ã€‚åœ¨ PyTorch ä¸Šï¼Œå¦‚æœä¸€å€‹ CPU Tensor æ˜¯ requires_grad=True çš„ï¼Œé‚£éº¼ç”¨ .to(device) å°‡å®ƒç™¼é€åˆ° GPU çš„æ™‚å€™æœƒç”¢ç”Ÿä¸€å€‹é—œè¯æ“ä½œ grad_fn=&lt;CopyBackwards&gt;ï¼Œè¦è§£æ±ºçš„è©±å¯ä»¥ .to(device).detach().requires_grad_(True)ã€‚\nç‚ºä½• optimizer åªèƒ½å°è‘‰å­ç¯€é»é€²è¡Œæ¢¯åº¦ä¸‹é™ï¼Ÿå› ç‚ºå¹¾ä¹æ‰€æœ‰çš„æ·±åº¦å­¸ç¿’æ¡†æ¶ï¼Œéƒ½ä¸æœƒå„²å­˜éè‘‰å­ç¯€é»çš„æ¢¯åº¦ï¼Œå®ƒçš„æ¢¯åº¦åœ¨å‚³éçµ¦æ‰€æœ‰ç›¸é€£çš„å¾Œæ–¹å±‚ä¹‹å¾Œå°±è¢«åˆªé™¤äº†ï¼Œæ²’æœ‰ç´€éŒ„ä¸‹æ¢¯åº¦è‡ªç„¶æ²’æ³•é€²è¡Œæ¢¯åº¦ä¸‹é™ã€‚é‚£ç‚ºä½•ä¸å„²å­˜å‘¢ï¼Œå›åˆ°æœ€é–‹å§‹çš„é›…å¯æ¯”çŸ©é™£ï¼Œå°æ–¼ä¸€å€‹ tensor functionï¼Œå‡è¨­ H = Hâ€² = W = Wâ€² = 32 and C = Câ€² = 128ï¼Œé‚£éº¼é€™å€‹é›…å¯æ¯”çŸ©é™£å…§çš„å…ƒç´ æ•°æ˜¯ Hâ€²Wâ€²Câ€²HWC â‰ˆ 17 Ã— 10e9 å€‹ï¼Œéœ€è¦ç´„ 68GB é€²è¡Œå–®ç²¾åº¦å„²å­˜ï¼Œæ‰€ä»¥ .backward() ä¸€å®šæ˜¯åœ¨ä¸€å€‹æ¨™é‡ä¸Šé€²è¡Œï¼ˆæˆ–è€…èªªè¨ˆç®—çš„æ˜¯ Vector-Jacobian Productï¼‰ã€‚å°æ–¼ä¸€å€‹æ¨™é‡çš„æ¢¯åº¦ï¼ŒçŸ©é™£å¤§å°å°±åªæœ‰ HWC å¤§å°ï¼Œå¤§ç´„æ˜¯ç™¾ MB çš„ç´šåˆ¥ï¼Œä½†æ˜¯é‚„è€ƒæ…®åˆ° batch sizeï¼Œå’Œå„ç¨® skip-connectionï¼Œé€™å€‹ç¸½å¤§å°é‚„æ˜¯å¾ˆå¯è§€çš„ã€‚è€Œä¸”ç¾ä»£ç¶²çµ¡éƒ½æ˜¯å¹¾ç™¾å±‚éš¨éš¨ä¾¿ä¾¿ï¼Œçµ•å°æ²’å¯èƒ½å…¨éƒ¨å„²å­˜ä¸‹ä¾†ã€‚\nforward network for a DAG\nbackward network for a DAG\n\n\nå¦‚æœè¦åˆ¤æ–·ä¸€å€‹ tensor æ˜¯ä¸æ˜¯è‘‰å­ç¯€é»ï¼Œå¯ä»¥ä½¿ç”¨ tensor.is_leafï¼Œå°æ–¼è‘‰å­ç¯€é»ï¼Œå®ƒæœƒåœ¨åå‘åœ–ä¸­å‰µå»ºä¸€å€‹ AccumulateGrad objectï¼Œä¹Ÿå°±æ˜¯æˆ‘å€‘ç¬¬ä¸€ç¯€ä¸­æåˆ°çš„ï¼Œè¡¨ç¤ºåœ¨é€™è£¡ç´¯ç©æ¢¯åº¦ã€‚\nå¦‚æœéœ€è¦ç²å¾—ä¸€å€‹ä¸­é–“å€¼çš„æ¢¯åº¦ï¼Œå¯ä»¥ä½¿ç”¨ retain_gradï¼Œæˆ–è€…æ›´è¤‡é›œçš„å¯ä»¥ç”¨ register_hookã€‚\né€™è£¡å†èªªä¸€å€‹é—œæ–¼ optimizerã€grad å’Œ weight decay çš„äº‹ã€‚ä¸€èˆ¬ä¾†èªªï¼Œweight decayï¼ˆæ¬Šå€¼è¡°æ¸›ï¼‰æ˜¯èªªè¦åœ¨ loss ä¸ŠåŠ ä¸Šä¸€é …ï¼Œä½¿å¾—ç¶²çµ¡çš„åƒæ•°å°ä¸€é»ï¼Œé˜²æ­¢éæ“¬åˆã€‚å¦‚æœä½¿ç”¨ L2 regularizationï¼Œé‚£éº¼ç¸½çš„ loss ç‚ºï¼š$$\\text{Regularized Loss} = \\text{Loss} + \\lambda \\sum_i {\\omega}_i^2$$\nåœ¨ PyTorch ä¸­ï¼Œweight decay çš„åƒæ•°æ˜¯å‚³çµ¦ optimizer çš„ï¼Œå®ƒæ˜¯åœ¨æ›´æ–°åƒæ•°æ™‚æ‰ç”¨é€™ä¸€é …ï¼ŒæœƒæŠŠæŸä¸€å€‹åƒæ•°çš„æ¢¯åº¦ ä¹˜ä»¥ (1 + weight_decay)ã€‚é€™éº¼åšä¹Ÿæ˜¯å› ç‚ºåƒæ•°å’Œåƒæ•°ä¹‹é–“æ˜¯ç¨ç«‹çš„ï¼Œæ±‚å°ä¹‹å¾Œå¦‚ä¸‹å¼ï¼ˆä¿‚æ•° 2 å¯ä»¥å¿½ç•¥ï¼‰ã€‚$$\\text{updated weight}_i = \\text{weight}_i - lr \\times \\alpha (grad_i + 2 \\lambda {\\omega}_i)$$\næ± åŒ–å±‚ä¸­çš„åå‘å‚³æ’­çœ¾æ‰€å‘¨çŸ¥æ± åŒ–å±‚ä¸­æ˜¯æ²’æœ‰å¯å­¸ç¿’çš„åƒæ•°çš„ï¼Œæ‰€ä»¥é€™è£¡åªçœ‹å°æ–¼ç‰¹å¾µåœ–ä¸Šçš„å€¼çš„æ¢¯åº¦æ€éº¼é€šéã€‚å¾å‰é¢å‚³ä¾†ä¸€å€‹ C Ã— H Ã— W å¤§å°çš„æ¢¯åº¦åœ–ï¼Œè¦å¾€å¾Œå‚³ä¸€å€‹ C Ã— nH Ã— nW çš„æ¢¯åº¦åœ–ã€‚\n\næœ€å¤§å€¼æ± åŒ–ï¼Œå‰å‘éç¨‹ä¸­æœƒç´€éŒ„æ¯ä¸€å€‹ bin ä¸­æœ€å¤§å€¼çš„ä½ç½®ï¼Œåœ¨åå‘éç¨‹ä¸­ï¼Œæ¢¯åº¦æœƒè³¦çµ¦ä¹‹å‰ç´€éŒ„çš„ä½ç½®ï¼Œbin ä¸­çš„å…¶å®ƒä½ç½®å¡« 0ã€‚\n\nå¹³å‡å€¼æ± åŒ–ï¼Œæ¢¯åº¦æœƒç¸®å° n Ã— n å€ç„¶å¾Œè³¦çµ¦ä¸€å€‹ bin å…§æ‰€æœ‰ä½ç½®ï¼Œå³æ¯å€‹ bin å…§æ¢¯åº¦ç›¸åŒã€‚\n\n\n\n\nå¾Œè©±ï¼šè‡ªå®šç¾©ä¸€å€‹ç¶²çµ¡å±‚ï¼Œä¾‹å¦‚ RoIPooling é€™äº›ï¼Œä¸»è¦æ˜¯è¦å°‡æå¤±å°ç‰¹å¾µåœ–çš„æ¢¯åº¦è¨ˆç®—å‡ºä¾†ç„¶å¾Œå‘å¾Œå‚³å‡ºï¼Œå°æ–¼ä¸€äº›æœ‰åƒæ•°çš„å±‚ï¼Œé‚„éœ€è¦è¨ˆç®—å‡ºå°åƒæ•°çš„æ¢¯åº¦ï¼Œå„²å­˜åœ¨ tensor çš„ .grad å±æ€§ä¸­å‚³çµ¦ optimizerã€‚\næˆ‘æ²’æƒ³åˆ°å¯«é€™å€‹ç•«åœ–æ’ç‰ˆä¹‹é¡çš„å±…ç„¶èŠ±äº†å…©å¤©æ™‚é–“ï¼Œæ—©çŸ¥å¦‚æ­¤å°±ä¸å¯«äº†ã€‚ã€‚ï¼ˆé€™å¥½åƒæ˜¯çµ•å¤§å¤šèªªè¦å¯«çš„æ±è¥¿çš„ä¸‹å ´ï¼Œæˆ‘å»å¹´å±…ç„¶é‚„èªªè¦å¯«ä¸€äº›é—œæ–¼è‰²å½©ç§‘å­¸è¨ˆç®—æ”å½±ä¹‹é¡çš„ï¼Ÿï¼Ÿå°äº†ï¼Œæˆ‘æœ€è¿‘å¥½ä¸€é™£åœ¨ç ”ç©¶ ğŸï¸ï¼Œä¸¦é­”æ”¹ä¸€å€‹æ‹ç«‹å¾—çµ¦ä¸­ç‰‡å¹…è† ç‰‡æ©Ÿåšå¾ŒèƒŒï¼ŒçœŸçš„å¾ˆå¥½ç©ï¼‰\nåƒè€ƒè³‡æ–™ï¼š\n\nDeep Learning with PyTorch: A 60 Minute Blitz &gt; Autograd: Automatic Differentiation\n\nA Step by Step Backpropagation Example\n\nBackpropagation In Convolutional Neural Networks\n\nForward And Backpropagation in Convolutional Neural Network\n\nBack Propagation in Convolutional Neural Networks â€” Intuition and Code\n\nManual of MatConvNet: CNNs for MATLAB\n\nå·ç§¯ç¥ç»ç¶²ç»œ(CNN)åå‘ä¼ æ’­ç®—æ³•\n\n\n","dateCreated":"2020-04-19T00:00:00+08:00","dateModified":"2021-05-24T01:28:51+08:00","datePublished":"2020-04-19T00:00:00+08:00","description":"åå‘å‚³æ’­çš„åŸºæœ¬åŸç†ï¼Œå’Œåå‘å‚³æ’­åœ¨å·ç©ç¶²çµ¡ä¸­çš„å¹¾å€‹å¸¸è¦‹å±‚çš„å…·é«”åˆ†æï¼Œä»¥åŠä¸€äº› PyTorch åå‘åœ–ã€å„ªåŒ–å™¨çš„ç›¸é—œçŸ¥è­˜ã€‚","headline":"å·ç©ç¥ç¶“ç¶²çµ¡ä¸­çš„åå‘å‚³æ’­","image":[],"mainEntityOfPage":{"@type":"WebPage","@id":"https://tangh.github.io/articles/backward-in-convolutional-neural-networks/"},"publisher":{"@type":"Organization","name":"Tang Huan","sameAs":["https://twitter.com/tanghrtx/","https://www.flickr.com/photos/135277712@N07/","https://www.instagram.com/tanghrtx/","https://www.youtube.com/channel/UCO-I0MZR6-HYmI_tgbBc0yw/","https://space.bilibili.com/634428/"],"image":"icon.jpg","logo":{"@type":"ImageObject","url":"icon.jpg"}},"url":"https://tangh.github.io/articles/backward-in-convolutional-neural-networks/","keywords":"PyTorch, Computer Vision, Deep Learning, Backpropagation"}</script>
    <meta name="description" content="åå‘å‚³æ’­çš„åŸºæœ¬åŸç†ï¼Œå’Œåå‘å‚³æ’­åœ¨å·ç©ç¶²çµ¡ä¸­çš„å¹¾å€‹å¸¸è¦‹å±‚çš„å…·é«”åˆ†æï¼Œä»¥åŠä¸€äº› PyTorch åå‘åœ–ã€å„ªåŒ–å™¨çš„ç›¸é—œçŸ¥è­˜ã€‚">
<meta property="og:type" content="blog">
<meta property="og:title" content="å·ç©ç¥ç¶“ç¶²çµ¡ä¸­çš„åå‘å‚³æ’­">
<meta property="og:url" content="https:&#x2F;&#x2F;tangh.github.io&#x2F;articles&#x2F;backward-in-convolutional-neural-networks&#x2F;">
<meta property="og:site_name" content="é›¨å¤©ç­‰æ”¾æ™´">
<meta property="og:description" content="åå‘å‚³æ’­çš„åŸºæœ¬åŸç†ï¼Œå’Œåå‘å‚³æ’­åœ¨å·ç©ç¶²çµ¡ä¸­çš„å¹¾å€‹å¸¸è¦‹å±‚çš„å…·é«”åˆ†æï¼Œä»¥åŠä¸€äº› PyTorch åå‘åœ–ã€å„ªåŒ–å™¨çš„ç›¸é—œçŸ¥è­˜ã€‚">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https:&#x2F;&#x2F;d2y8c08sxwbp8v.cloudfront.net&#x2F;2020-backward-in-convnet&#x2F;backward-network-automatic-built-by-pytorch.png">
<meta property="og:image" content="https:&#x2F;&#x2F;d2y8c08sxwbp8v.cloudfront.net&#x2F;2020-backward-in-convnet&#x2F;a-simple-mlp-network.png">
<meta property="og:image" content="https:&#x2F;&#x2F;d2y8c08sxwbp8v.cloudfront.net&#x2F;2020-backward-in-convnet&#x2F;forward-pass-of-mlp.png">
<meta property="og:image" content="https:&#x2F;&#x2F;d2y8c08sxwbp8v.cloudfront.net&#x2F;2020-backward-in-convnet&#x2F;connection-in-forward-pass-of-conv.png">
<meta property="og:image" content="https:&#x2F;&#x2F;d2y8c08sxwbp8v.cloudfront.net&#x2F;2020-backward-in-convnet&#x2F;forward-pass-of-conv.png">
<meta property="og:image" content="https:&#x2F;&#x2F;d2y8c08sxwbp8v.cloudfront.net&#x2F;2020-backward-in-convnet&#x2F;weight-gradient-calc.png">
<meta property="og:image" content="https:&#x2F;&#x2F;d2y8c08sxwbp8v.cloudfront.net&#x2F;2020-backward-in-convnet&#x2F;input-gradient-calc.png">
<meta property="og:image" content="https:&#x2F;&#x2F;d2y8c08sxwbp8v.cloudfront.net&#x2F;2020-backward-in-convnet&#x2F;full-conv-operation.png">
<meta property="og:image" content="https:&#x2F;&#x2F;d2y8c08sxwbp8v.cloudfront.net&#x2F;2020-backward-in-convnet&#x2F;forward-network-for-dag-preview.png">
<meta property="og:image" content="https:&#x2F;&#x2F;d2y8c08sxwbp8v.cloudfront.net&#x2F;2020-backward-in-convnet&#x2F;backward-network-for-dag-preview.png">
<meta property="article:published_time" content="2020-04-18T16:00:00.000Z">
<meta property="article:modified_time" content="2021-05-23T17:28:51.052Z">
<meta property="article:author" content="Tang Huan">
<meta property="article:tag" content="PyTorch">
<meta property="article:tag" content="CNNs">
<meta property="article:tag" content="Backpropagation">
<meta property="article:tag" content="å·ç©ç¶²çµ¡">
<meta property="article:tag" content="åå‘å‚³æ’­">
<meta property="article:tag" content="å·ç§¯ç½‘ç»œ">
<meta property="article:tag" content="åå‘ä¼ æ’­">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https:&#x2F;&#x2F;d2y8c08sxwbp8v.cloudfront.net&#x2F;2020-backward-in-convnet&#x2F;backward-network-automatic-built-by-pytorch.png">
    
    
        
    
    
        <meta property="og:image" content="https://tangh.github.io/assets/images/icon.jpg"/>
    
    
    
    
    <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+JP:wght@400;700&family=Noto+Serif+SC:wght@400;700&display=swap" rel="stylesheet">
    <!--STYLES-->
    
<link rel="stylesheet" href="/assets/css/style-iaetwm81hfopcuajcp7qnh2zsnqn4dhiu3nftuj79wdhe7fie6l4r0thrs6g.min.css">

    <!--STYLES END-->
    
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-137837052-1"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'UA-137837052-1');
    </script><!-- hexo-inject:begin --><!-- hexo-inject:end -->


    

</head>

    <body>
        <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="blog">
            <!-- Define author's picture -->


    
        
            
        
    

<header id="header" data-behavior="4">
    <i id="btn-open-sidebar" class="fa fa-lg fa-bars"></i>
    <div class="header-title">
        <a
            class="header-title-link"
            href="/"
            aria-label=""
        >
            é›¨å¤©ç­‰æ”¾æ™´
        </a>
    </div>
    
        
            <a
                class="header-right-picture "
                href="#about"
                aria-label="Open the link: /#about"
            >
        
        
            <img class="header-picture" src="/assets/images/icon.jpg" alt="Author&#39;s picture"/>
        
        </a>
    
</header>

            <!-- Define author's picture -->



        
    

<nav id="sidebar" data-behavior="4">
    <div class="sidebar-container">
        
            <div class="sidebar-profile">
                <a
                    href="/#about"
                    aria-label="Read more about the author"
                >
                    <img class="sidebar-profile-picture" src="/assets/images/icon.jpg" alt="Author&#39;s picture"/>
                </a>
                <h4 class="sidebar-profile-name">Tang Huan</h4>
                
                    <h5 class="sidebar-profile-bio"></h5>
                
            </div>
        
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/"
                            
                            rel="noopener"
                            title="Home"
                        >
                        <i class="sidebar-button-icon fa fa-home" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Home</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/all-categories"
                            
                            rel="noopener"
                            title="Categories"
                        >
                        <i class="sidebar-button-icon fa fa-bookmark" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Categories</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/all-tags"
                            
                            rel="noopener"
                            title="Tags"
                        >
                        <i class="sidebar-button-icon fa fa-tags" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Tags</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/all-archives"
                            
                            rel="noopener"
                            title="Archives"
                        >
                        <i class="sidebar-button-icon fa fa-archive" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Archives</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/about"
                            
                            rel="noopener"
                            title="About"
                        >
                        <i class="sidebar-button-icon fas fa-cube" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">About</span>
                    </a>
            </li>
            
        </ul>
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="https://twitter.com/tanghrtx/"
                            
                                target="_blank"
                            
                            rel="noopener"
                            title="Twitter"
                        >
                        <i class="sidebar-button-icon fab fa-twitter" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Twitter</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="https://www.flickr.com/photos/135277712@N07/"
                            
                                target="_blank"
                            
                            rel="noopener"
                            title="Flickr"
                        >
                        <i class="sidebar-button-icon fab fa-flickr" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Flickr</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="https://www.instagram.com/tanghrtx/"
                            
                                target="_blank"
                            
                            rel="noopener"
                            title="Instagram"
                        >
                        <i class="sidebar-button-icon fab fa-instagram" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Instagram</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="https://www.youtube.com/channel/UCO-I0MZR6-HYmI_tgbBc0yw/"
                            
                                target="_blank"
                            
                            rel="noopener"
                            title="YouTube"
                        >
                        <i class="sidebar-button-icon fab fa-youtube" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">YouTube</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="https://space.bilibili.com/634428/"
                            
                                target="_blank"
                            
                            rel="noopener"
                            title="BiliBili"
                        >
                        <i class="sidebar-button-icon fab fa-youtube-square" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">BiliBili</span>
                    </a>
            </li>
            
        </ul>
        
    </div>
</nav>

            
            <div id="main" data-behavior="4"
                 class="
                        hasCoverMetaIn
                        ">
                
<article class="post">
    
    
        <div class="post-header main-content-wrap text-center">
    
        <h1 class="post-title">
            å·ç©ç¥ç¶“ç¶²çµ¡ä¸­çš„åå‘å‚³æ’­
        </h1>
    
    
        <div class="post-meta">
    <time datetime="2020-04-19T00:00:00+08:00">
	
		    Apr 19, 2020
    	
    </time>
    
        <span>in </span>
        
    <a class="category-link" href="/categories/Computer-Science/">Computer Science</a>, <a class="category-link" href="/categories/Computer-Science/Deep-Learning/">Deep Learning</a>


    
</div>

    
</div>

    
    
        <div class="post-content markdown">
    
        <div class="main-content-wrap">
            <!-- excerpt -->


<p>å‰å¹¾å¤©æœ‰äººå•æˆ‘ä¸€å€‹å•é¡Œï¼Œä»–æƒ³æŠŠä¸€å€‹è‡ªå·±å‰µå»ºçš„ tensorï¼ˆè€Œä¸æ˜¯ç¶²çµ¡çš„æ¬Šé‡ï¼‰æ”¾é€² optimizerï¼Œä½†æ˜¯ PyTorch å ±éŒ¯ï¼š<code>ValueError: can&#39;t optimize a non-leaf Tensor</code>ã€‚çŸ­è©±é•·èªªï¼Œæˆ‘æ±ºå®šå¯«ä¸€å€‹é—œæ–¼åå‘å‚³æ’­çš„æ–‡ç« ï¼Œè‡³æ–¼å‰é¢é€™å€‹å•é¡Œï¼Œæœƒåœ¨ä¸­é–“ç”¨ä¸€ç¯€å»è§£é‡‹ï¼ˆä¸æ˜¯è§£æ±ºï¼Œç”¨ä¸€å€‹ <code>.detach()</code> å°±èƒ½è§£æ±ºäº†ï¼‰ã€‚</p>
<p>å¦å¤–æˆ‘å…ˆè¦èªªä¸€é»å°±æ˜¯ï¼ˆå¯èƒ½æ˜¯æ¼¢èªç¿’æ…£çš„å•é¡Œï¼‰ï¼Œå°æ–¼ä¸€å€‹ç¶²çµ¡ï¼Œå®ƒæ›´é è¿‘æœ€çµ‚è¼¸å‡ºçš„éƒ¨åˆ†å«ã€Œå‰é¢ã€ï¼Œè‹±æ–‡çš„ forwardã€network head é€™äº›å°±æ˜¯é€™å€‹æ„æ€ï¼Œé è¿‘è¼¸å…¥çš„åœ°æ–¹å«ã€Œå¾Œé¢ã€ã€‚</p>
<h1 id="table-of-contents">Table of Contents</h1><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#æœ€åŸºæœ¬çš„åå‘å‚³æ’­ä¾‹å­"><span class="toc-text">æœ€åŸºæœ¬çš„åå‘å‚³æ’­ä¾‹å­</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#å…¨é€£æ¥å±‚ä¸­çš„åå‘å‚³æ’­"><span class="toc-text">å…¨é€£æ¥å±‚ä¸­çš„åå‘å‚³æ’­</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#å¦‚ä½•ç°¡æ˜åœ°å¯¦ç¾"><span class="toc-text">å¦‚ä½•ç°¡æ˜åœ°å¯¦ç¾</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#å·ç©å±‚ä¸­çš„åå‘å‚³æ’­"><span class="toc-text">å·ç©å±‚ä¸­çš„åå‘å‚³æ’­</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#ç°¡å–®ä¾‹å­å’Œä»£ç¢¼"><span class="toc-text">ç°¡å–®ä¾‹å­å’Œä»£ç¢¼</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#æœ€é–‹å§‹çš„å•é¡Œ"><span class="toc-text">æœ€é–‹å§‹çš„å•é¡Œ</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#æ± åŒ–å±‚ä¸­çš„åå‘å‚³æ’­"><span class="toc-text">æ± åŒ–å±‚ä¸­çš„åå‘å‚³æ’­</span></a></li></ol>



<h1 id="æœ€åŸºæœ¬çš„åå‘å‚³æ’­ä¾‹å­"><a href="#æœ€åŸºæœ¬çš„åå‘å‚³æ’­ä¾‹å­" class="headerlink" title="æœ€åŸºæœ¬çš„åå‘å‚³æ’­ä¾‹å­"></a>æœ€åŸºæœ¬çš„åå‘å‚³æ’­ä¾‹å­</h1><p>æˆ‘å€‘å®šç¾©ä¸€å€‹ tensor <code>x</code>ï¼Œç„¶å¾Œå°å…¶é€²è¡Œä¸€äº›é‹ç®—ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">x = torch.ones(<span class="number">2</span>, <span class="number">2</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line">y = x + <span class="number">2</span></span><br><span class="line">z = y * y * <span class="number">3</span></span><br><span class="line">out = z.mean()</span><br><span class="line"></span><br><span class="line">out.backward()</span><br><span class="line">print(x.grad)</span><br></pre></td></tr></table></figure>

<p>åœ¨é€™è£¡ï¼Œ<code>x</code> æ˜¯ä¸€å€‹ 2Ã—2 çš„æ•°çµ„ï¼Œæœ€çµ‚è¼¸å‡ºçš„çµæœæ˜¯ <code>tensor([[4.5000, 4.5000],[4.5000, 4.5000]])</code>ã€‚æˆ‘å€‘æ‰‹å‹•è¨ˆç®—ä¸€ä¸‹é€™å€‹æ¢¯åº¦ï¼šæœ‰ \( o = \frac{1}{4}\sum_i z_i \)ï¼Œä¸” \( z_i = 3(x_i+2)^2 \)ï¼Œæ‰€ä»¥ \( \frac{\partial o}{\partial x_i} = \frac{3}{2}(x_i+2) \)ï¼Œæ­¤æ™‚ <code>x=1</code>ï¼Œå‰‡æ¢¯åº¦ $$ \frac{\partial o}{\partial x_i}\bigr\rvert_{x_i=1} = \frac{9}{2} = 4.5 $$</p>
<p>é€™å€‹ä¾‹å­ä¹‹æ‰€ä»¥ç°¡å–®æ˜ç­ï¼Œæ˜¯å› ç‚ºå‰ä¸€å±‚ä¸­ä¸€å€‹å…ƒç´ å¯¦éš›ä¸Šåªå’Œå‰å¾Œä¸€å±‚ä¸­çš„åŒä½ç½®çš„ä¸€å€‹å…ƒç´ ç›¸å°æ‡‰ï¼Œå¦‚ä¸‹æ‰€ç¤ºã€‚</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">x1 â”€ y1 â”€ z1 â”</span><br><span class="line">x2 â”€ y2 â”€ z2 â”¤</span><br><span class="line">             â”œâ”€ out</span><br><span class="line">x3 â”€ y3 â”€ z3 â”¤</span><br><span class="line">x4 â”€ y4 â”€ z4 â”˜</span><br></pre></td></tr></table></figure>

<p>åœ¨é€²è¡Œåˆ°ä¸‹ä¸€æ­¥ä¹‹å‰ï¼Œæˆ‘å€‘å…ˆä¾†çœ‹ä¸€å€‹ PyTorch çš„æ“ä½œã€‚</p>
<p>å¦‚æœ <code>print(out)</code>ï¼Œçµæœç‚º <code>tensor(27., grad_fn=&lt;MeanBackward0&gt;)</code>ï¼Œé€™è£¡ä¸åƒ…å¯ä»¥çœ‹åˆ°å®ƒçš„å€¼ï¼Œé‚„å¯ä»¥çœ‹åˆ°å®ƒæ‰€é—œè¯çš„æ¢¯åº¦å‡½æ•°ï¼Œé€™å€‹å‡½æ•°ï¼Œå¯ä»¥é€šé <code>out.grad_fn</code> è¨ªå•ï¼Œå®ƒæœ‰ä¸€å€‹å±æ€§ <code>next_functions</code>ã€‚å°æ–¼ <code>out.grad_fn.next_functions</code>ï¼Œè¼¸å‡ºçš„çµæœç‚º <code>((&lt;MulBackward0 object at 0x7fa140178850&gt;, 0),)</code>ï¼Œå¦‚æœçœ‹çœ‹ <code>z.grad_fn</code> å¯ä»¥å¾—åˆ° <code>&lt;MulBackward0 object at 0x7fa140178850&gt;</code>ã€‚ä¹Ÿå°±æ˜¯èªªï¼Œ<code>next_functions</code> æŒ‡å‘çš„å°±æ˜¯åå‘å‚³æ’­ç¶²çµ¡ä¸­ï¼ŒæŸä¸€å€‹æ¢¯åº¦å‡½æ•°çš„ä¸‹ä¸€ç´šçš„æ¢¯åº¦å‡½æ•°ã€‚</p>
<p><code>next_functions</code> è¿”å›çš„ç¬¬ä¸€å±‚ tuple å…§æ˜¯æŒ‡å‘çš„æ‰€æœ‰çš„ä¸‹ä¸€ç´šï¼Œä¹Ÿå°±æ˜¯èªªï¼Œå®ƒå¯èƒ½æŒ‡å‘å¤šå€‹å‡½æ•°ï¼›ç¬¬äºŒå±‚ tuple å…§çš„ç¬¬äºŒå€‹å…ƒç´ ä¸€èˆ¬æ˜¯ <code>0</code>ï¼Œå®ƒæ˜¯åå‘å‡½æ•°çš„è¼¸å…¥å€¼ï¼Œåªæœ‰è¿”å›å¤šå€‹å¯å¾®åˆ†çš„å€¼çš„å‡½æ•°ï¼ˆä¾‹å¦‚ <code>torch.unbind()</code>ï¼‰æ‰æœƒä½¿å®ƒçš„åå‘å‡½æ•°çš„é€™å€‹è¼¸å…¥å€¼éé›¶ã€‚ç¬¬äºŒå±‚ tuple å…§çš„ç¬¬ä¸€å€‹å…ƒç´ å¦‚æœæ˜¯ <code>None</code>ï¼Œèªªæ˜å®ƒæŒ‡å‘äº†ä¸€å€‹å¸¸æ•°ã€‚</p>
<p>ç¸½ä¹‹ï¼Œæˆ‘å€‘å¯ä»¥ä¸€å±‚ä¸€å±‚å»çœ‹é€™å€‹åå‘å‚³æ’­ç¶²çµ¡ï¼Œçµæœå¦‚ä¸‹åœ–ã€‚æˆ‘å€‘å¯ä»¥çœ‹åˆ°ï¼ŒPyTorch è‡ªå‹•å‰µå»ºçš„é€™å€‹åå‘ç¶²çµ¡æ˜¯ä¸€ç´šä¸€ç´šçš„ï¼Œæ¯æ¬¡åªæœ‰ä¸€æ­¥æ“ä½œï¼Œæˆ‘å€‘å¯«åœ¨ä¸€è¡Œå…§çš„æ“ä½œä¹Ÿæœƒè‡ªå‹•è¢«æ‹†åˆ†é–‹ä¾†ã€‚</p>
<div class="figure center" style="width:;"><a class="fancybox" href="https://d2y8c08sxwbp8v.cloudfront.net/2020-backward-in-convnet/backward-network-automatic-built-by-pytorch.png" target="_blank" rel="noopener" title="backward network automatic built by pytorch" data-caption="backward network automatic built by pytorch" data-fancybox="default"><img class="fig-img" src="https://d2y8c08sxwbp8v.cloudfront.net/2020-backward-in-convnet/backward-network-automatic-built-by-pytorch.png" alt="backward network automatic built by pytorch"></a><span class="caption">backward network automatic built by pytorch</span></div><div style="clear:both;"></div>

<p>æœ€æœ«å°¾çš„ <code>AccumulateGrad object</code> æœ‰ä¸€å€‹ <code>.variable</code> å±æ€§ï¼Œå®ƒæŒ‡å‘çš„å°±æ˜¯ <code>x</code>ï¼Œé€™å€‹å¾Œé¢é‚„æœƒæåˆ°ã€‚</p>
<h1 id="å…¨é€£æ¥å±‚ä¸­çš„åå‘å‚³æ’­"><a href="#å…¨é€£æ¥å±‚ä¸­çš„åå‘å‚³æ’­" class="headerlink" title="å…¨é€£æ¥å±‚ä¸­çš„åå‘å‚³æ’­"></a>å…¨é€£æ¥å±‚ä¸­çš„åå‘å‚³æ’­</h1><p>å°æ–¼å·ç©ç¥ç¶“ç¶²çµ¡ï¼Œè£¡é¢ä¹Ÿä¸æ’é™¤åŒ…å«å…¨é€£æ¥å±‚ã€‚æ­¤å¤–ï¼Œä¸€å€‹å…·é«”è€Œç°¡å–®çš„ç¥ç¶“ç¶²çµ¡ä¾‹å­ï¼Œé€šå¸¸é¸æ“‡å…¨é€£æ¥ç¶²çµ¡ï¼Œæˆ–è€…å« MLP (Mutli-Layer Perceptron)ã€‚ç‚ºäº†ç°¡å–®ä¸€èˆ¬åªä½œä¸‰å±‚ï¼šè¼¸å…¥å±‚ã€éš±è—å±‚ï¼ˆhidden layerï¼‰ã€è¼¸å‡ºå±‚ã€‚å…¶ä¸­æ¯ä¸€å€‹ç¥ç¶“å…ƒï¼Œéƒ½èˆ‡å‰å¾Œå±‚ä¸­æ¯å€‹ç¥ç¶“å…ƒç›¸é€£ï¼ŒåŒæ¨£ç‚ºäº†ç°¡ä¾¿ï¼Œåœ¨æœ¬æ–‡çš„ä¾‹å­ä¸­æˆ‘å€‘æ¯ä¸€å±‚åªæœ‰å…©å€‹ç¥ç¶“å…ƒï¼Œç•«å‡ºçµæ§‹åœ–å¦‚ä¸‹ã€‚</p>
<div class="figure center" style="width:;"><a class="fancybox" href="https://d2y8c08sxwbp8v.cloudfront.net/2020-backward-in-convnet/a-simple-mlp-network.png" target="_blank" rel="noopener" title="a simple MLP network" data-caption="a simple MLP network" data-fancybox="default"><img class="fig-img" src="https://d2y8c08sxwbp8v.cloudfront.net/2020-backward-in-convnet/a-simple-mlp-network.png" alt="a simple MLP network"></a><span class="caption">a simple MLP network</span></div><div style="clear:both;"></div>

<p>é€™è£¡å¯ä»¥çœ‹åˆ°ï¼Œèˆ‡ä¸Šä¸€ç¯€ä¸åŒï¼Œç¥ç¶“å…ƒä¹‹é–“çš„é€£çµæ›´è¤‡é›œäº†ï¼Œä¸å†åªæ˜¯å¹³è¡Œåœ°é€£çµï¼›ä½†æ˜¯é€™è£¡ä¹Ÿåªæœ‰ä¸€æ¬¡ä¹˜æ³•ï¼ˆç·šæ€§é‹ç®—ï¼‰ï¼Œæ²’æœ‰äºŒæ¬¡çš„é …äº†ã€‚æ­¤å¤–ï¼Œå°æ¯ä¸€å€‹ç¥ç¶“å…ƒï¼ˆåœ“åœˆç¯€é»ï¼‰ï¼Œå¦‚ä¸Šåœ–å³å´æ‰€ç¤ºï¼ˆh1 ç‚ºä¾‹ï¼‰ï¼Œé™¤äº†æ¬Šé‡ <code>w</code> ä»¥å¤–ï¼Œé‚„æœ‰åŠ ä¸Šä¸€å€‹åç½® <code>b</code>ï¼Œå¾ <code>neth1</code> åˆ° <code>outh1</code>ï¼Œéœ€è¦ç¶“éä¸€å€‹å¯å¾®åˆ†çš„æ¿€æ´»å‡½æ•°ï¼Œé€™è£¡æˆ‘å€‘ä½¿ç”¨ sigmoid å‡½æ•°ï¼Œå®ƒçš„è¡¨é”å¼å’Œå¾®åˆ†ç‚ºï¼š<br>$$<br>\begin{aligned}<br>y = \text{sigmoid}(x) = \frac{1}{1+e^{-x}} \\<br>\frac{\partial y}{\partial x} = \frac{e^x}{({1+e^{-x})}^2} = y \cdot (1-y)<br>\end{aligned}<br>$$</p>
<p>ç¾åœ¨æˆ‘å€‘çµ¦å®šè¼¸å…¥å€¼å’Œç›®æ¨™ï¼ˆè—è‰²ï¼‰ï¼Œä»¥åŠåˆå§‹åŒ–å€¼çš„æ¬Šé‡ï¼ˆç´…è‰²ï¼‰ï¼Œå’Œåˆå§‹åŒ–çš„åç½®ï¼ˆé»ƒè‰²ï¼Œå‡è¨­æ¯ä¸€å±‚çš„åç½®éƒ½ç›¸åŒï¼Œç‚ºäº†ç°¡ä¾¿ï¼‰ï¼Œé€™æ¨£ä¸€ä¾†ï¼Œç¨æœ‰å¸¸è­˜çš„äººéƒ½å¯ä»¥è¨ˆç®—å‡ºæ¯å€‹ç¥ç¶“å…ƒçš„æ¿€æ´»å€¼ï¼ˆç¶ è‰²ï¼‰ï¼Œå¦‚ä¸‹åœ–æ‰€ç¤ºã€‚æœ¬æ–‡å‡å‡å®šå°å„ç¨®æ­£å‘éç¨‹éƒ½å·²ç¶“éå¸¸äº†è§£ã€‚</p>
<div class="figure center" style="width:;"><a class="fancybox" href="https://d2y8c08sxwbp8v.cloudfront.net/2020-backward-in-convnet/forward-pass-of-mlp.png" target="_blank" rel="noopener" title="forward pass of MLP" data-caption="forward pass of MLP" data-fancybox="default"><img class="fig-img" src="https://d2y8c08sxwbp8v.cloudfront.net/2020-backward-in-convnet/forward-pass-of-mlp.png" alt="forward pass of MLP"></a><span class="caption">forward pass of MLP</span></div><div style="clear:both;"></div>

<p>ç¾åœ¨æˆ‘å€‘éœ€è¦è¨ˆç®—æ¯å€‹æ¬Šé‡å’Œåç½®ç›¸å°æ–¼æœ€çµ‚åå·®çš„æ¢¯åº¦ï¼Œæå¤±å‡½æ•°é€™è£¡ä½¿ç”¨ squared error function: \(E_{total} = \frac{1}{2} (target - output)^2\)ï¼Œé‚£éº¼ \(E_{o1} = \frac{1}{2} (target_{o1} - output_{o1})^2 = \frac{1}{2} (0.01 - 0.751)^2 = 0.2748\)ï¼ŒåŒç† \(E_{o2} = 0.0236\)ã€‚</p>
<p>ä¸€èˆ¬ä¾†èªªï¼Œç¸½çš„æå¤±å°±æ˜¯äºŒè€…ä¹‹å’Œï¼Œå¯ä»¥èªªæ˜¯æ¬Šé‡ç›¸ç­‰ï¼Œéƒ½ç‚º <code>1</code>ã€‚å¦‚æœæˆ‘å€‘çœ‹çœ‹ PyTorchï¼Œæˆ‘å€‘ç¸½æ˜¯éœ€è¦åœ¨ä¸€å€‹æ¨™é‡è€Œä¸æ˜¯å‘é‡ä¸Šä½¿ç”¨ <code>.backward()</code> è¨ˆç®—æ•´å€‹ graph çš„æ¢¯åº¦ï¼Œå¦‚æœåœ¨ä¸€å€‹å‘é‡ä¸Šä½¿ç”¨æœƒå ±éŒ¯ <code>RuntimeError: grad can be implicitly created only for scalar outputs</code>ã€‚å°æ–¼ä¸€å€‹è¼¸å‡ºå‘é‡çš„å‡½æ•° \(\vec{y}=f(\vec{x})\)ï¼Œ\(\vec{y}\) ç›¸å°æ–¼ \(\vec{x}\) çš„æ¢¯åº¦æ˜¯ä¸€å€‹é›…å¯æ¯”çŸ©é™£ï¼ˆJacobian Matrixï¼‰ï¼š<br>$$<br>\begin{split}<br>J =<br> \left( \begin{array}{ccc}<br> \frac{\partial y_{1}}{\partial x_{1}} &amp; \cdots &amp; \frac{\partial y_{1}}{\partial x_{n}} \\<br> \vdots &amp; \ddots &amp; \vdots \\<br> \frac{\partial y_{m}}{\partial x_{1}} &amp; \cdots &amp; \frac{\partial y_{m}}{\partial x_{n}}<br> \end{array} \right)<br>\end{split}<br>$$</p>
<p><code>torch.autograd</code> ç”¨æ–¼è¨ˆç®— Vector-Jacobian Productï¼Œå®ƒä¸èƒ½ç›´æ¥è¨ˆç®—æ•´å€‹ Jacobian çŸ©é™£ã€‚ä¹Ÿå°±æ˜¯èªªï¼Œæˆ‘å€‘éœ€è¦çµ¦å®šä¸€å€‹å‘é‡ <code>v</code>ï¼Œå»è¨ˆç®— \(v^{T} \cdot J\)ã€‚å¦‚æœé€™å€‹ <code>v</code> æ­£å¥½æ˜¯æŸä¸€å€‹çµæœç‚ºæ¨™é‡çš„å‡½æ•° \(l = g\left(\vec{y}\right)\) çš„æ¢¯åº¦ï¼Œä¹Ÿå°±æ˜¯èªª \(v=\left(\begin{array}{ccc}\frac{\partial l}{\partial y_{1}} &amp; \cdots &amp; \frac{\partial l}{\partial y_{m}}\end{array}\right)^{T}\)ï¼Œé‚£éº¼æ ¹æ“šéˆå¼æ³•å‰‡ï¼Œé€™å€‹ä¹˜ç©æ˜¯ \(l\) ç›¸å°æ–¼ \(\vec{x}\) çš„æ¢¯åº¦ï¼š<br>$$<br>\begin{split}<br>J^{T}\cdot v=<br> \left(\begin{array}{ccc}<br> \frac{\partial y_{1}}{\partial x_{1}} &amp; \cdots &amp; \frac{\partial y_{m}}{\partial x_{1}} \\<br> \vdots &amp; \ddots &amp; \vdots \\<br> \frac{\partial y_{1}}{\partial x_{n}} &amp; \cdots &amp; \frac{\partial y_{m}}{\partial x_{n}}<br> \end{array}\right)\left(\begin{array}{c}<br> \frac{\partial l}{\partial y_{1}} \\<br> \vdots \\<br> \frac{\partial l}{\partial y_{m}}<br> \end{array}\right)=\left(\begin{array}{c}<br> \frac{\partial l}{\partial x_{1}} \\<br> \vdots \\<br> \frac{\partial l}{\partial x_{n}}<br> \end{array}\right)<br>\end{split}<br>$$</p>
<p>æ‰€ä»¥å¦‚æœæˆ‘å€‘æƒ³åœ¨ä¸€å€‹å‘é‡ä¸Šä½¿ç”¨ <code>vector.backward(v)</code>ï¼Œæˆ‘å€‘éœ€è¦å‚³å…¥ä¸€å€‹ <code>v = torch.tensor([weight1, weight2, ...])</code>ï¼Œå®ƒè¡¨ç¤ºçš„å°±æ˜¯æ¯ä¸€å€‹æå¤±åœ¨ç¸½æå¤±ä¸­çš„æ¬Šé‡ï¼ˆå®ƒçš„åƒæ•°åç‚º <code>gradient</code>ï¼Œä¹Ÿå¯ä»¥çœ‹ä½œæ˜¯é€™å€‹å‘é‡å°æŸä¸€å€‹å¤–éƒ¨æ¨™é‡çš„æ¢¯åº¦ï¼‰ã€‚å¦‚æœæˆ‘å€‘åœ¨ä¸€å€‹æ¨™é‡ä¸Šä½¿ç”¨ <code>scalar.backward()</code>ï¼Œé‚£éº¼ç„¡éœ€å‚³å…¥ä»»ä½•åƒæ•°ã€‚</p>
<p>å›åˆ°é–‹å§‹çš„è©±é¡Œï¼Œæˆ‘å€‘ç¾åœ¨é–‹å§‹è¨ˆç®—æ¯ä¸€å€‹æ¬Šé‡é—œæ–¼æœ€çµ‚æå¤±çš„æ¢¯åº¦ï¼Œå°æ–¼è¼¸å‡ºå±‚çš„ <code>w5ï½w8</code>ï¼Œä»¥ <code>w5</code> ç‚ºä¾‹ï¼Œé¦–å…ˆæˆ‘å€‘æœ‰ï¼Œç¸½æå¤±å°æ–¼ <code>out o1</code> çš„æ¢¯åº¦ï¼š<br>$$<br>\frac{\partial L_{total}}{\partial out_{o1}} =<br>2 \cdot \frac{1}{2} \cdot (target_{o1} - out_{o1}) * (-1)\ +\ 0<br>= 0.7414<br>$$<br>ç¸½æå¤±çš„ç¬¬äºŒé … \(E_{o2}\) èˆ‡ <code>out o1</code> æ²’æœ‰é—œä¿‚ï¼Œæ‰€ä»¥å°å…¶çš„æ¢¯åº¦ç‚º <code>0</code>ã€‚</p>
<p>è€Œ <code>out o1</code> å°æ–¼ <code>net o1</code>ï¼Œå°±æ˜¯ sigmoid çš„æ¢¯åº¦ï¼Œ\(\frac{\partial out_{o1}}{\partial net_{o1}} = out_{o1} \cdot (1 - out_{o1}) = 0.1868 \)ã€‚å¹¾ä¹æ‰€æœ‰æ¿€æ´»å‡½æ•°æ˜¯å°æ¯ä¸€å€‹å…ƒç´ å–®ç¨åšçš„é‹ç®—ï¼Œä¸æ¶‰åŠç›¸äº’å½±éŸ¿ï¼ˆå³å°æ¯ä¸€å€‹å…ƒç´ ï¼Œæ“ä½œå…¬å¼éƒ½æ˜¯ç›¸åŒçš„ï¼‰ï¼Œæ‰€ä»¥è·Ÿä¸Šä¸€ç¯€çš„æƒ…æ³å®Œå…¨ç›¸åŒã€‚æ¢¯åº¦é€šéæ¿€æ´»å‡½æ•°æ™‚ï¼Œæ•´å€‹æ¢¯åº¦åœ–çš„å¤§å°æ˜¯ä¸æœƒæ”¹å¤‰çš„ã€‚</p>
<p>æœ€çµ‚ï¼Œæˆ‘å€‘çœ‹ <code>net o1</code> å°æ–¼ <code>w5</code>ï¼Œæœ‰ \(net_{o1} = w_5 * out_{h1}\ +\ w_6 * out_{h1}\ +\ b_2\)ï¼Œæ‰€ä»¥ \(\frac{\partial net_{o1}}{\partial w_5} = out_{h1} = 0.5933\)ã€‚æ‰€ä»¥æ ¹æ“šéˆå¼æ³•å‰‡ï¼Œæˆ‘å€‘æŠŠä¸Šè¿°ä¸‰é …ç›¸ä¹˜ï¼Œå°±å¾—åˆ°ç¸½æå¤± <code>L</code> å°æ–¼ <code>w5</code> çš„æ¢¯åº¦ <code>0.7414 Ã— 0.1868 Ã— 0.5933 = 0.082</code>ã€‚</p>
<div class="alert info"><p>å¦‚æœåªæŠŠå‰å…©é …ç›¸ä¹˜ï¼Œæˆ‘å€‘å¾—åˆ° \(\frac{\partial L_{total}}{\partial net_{o1}}\)ã€‚é€šå¸¸ï¼Œæˆ‘å€‘æŠŠç¸½æå¤±å°æŸä¸€å±‚ï¼ˆæˆ–æŸä¸€å€‹ç¥ç¶“å…ƒï¼‰æœªæ¿€æ´»ä¹‹å‰çš„çµæœï¼ˆå³ <code>net</code>ï¼‰çš„å°æ•°è¨˜ä½œ \(\delta_{layer}\)ï¼Œä¾‹å¦‚é€™è£¡å¯è¨˜ä½œ \(\delta_{o1}\)ã€‚</p>
</div>

<p>è¨ˆç®—è¼¸å‡ºå±‚çš„å…¶å®ƒæ¬Šé‡å’Œåç½®ä¹Ÿéƒ½é¡ä¼¼ã€‚å†çœ‹ä¸­é–“çš„éš±è—å±‚ï¼Œå®ƒè·Ÿè¼¸å‡ºå±‚çš„å€åˆ¥å°±æ˜¯ï¼Œå®ƒçš„å³å´èˆ‡å¤šå€‹ç¥ç¶“å…ƒç›¸é€£ï¼Œæ‰€ä»¥æ¢¯åº¦æœƒä¾†è‡ªæ–¼å³å´å¤šæ¢é€šè·¯ï¼Œæ‰€ä»¥<br>$$<br>\begin{aligned}<br>\frac{\partial L_{total}}{\partial w_1} = &amp;<br>\frac{\partial L_{total}}{\partial out_{h1}} \cdot \frac{\partial out_{h1}}{\partial net_{h1}} \cdot \frac{\partial net_{h1}}{\partial w_1} \\<br>= &amp; \left(<br>\frac{\partial L_{total}}{\partial out_{o1}} \cdot \frac{\partial out_{o1}}{\partial net_{o1}} \cdot \frac{\partial net_{o1}}{\partial out_{h1}}\ +\ \frac{\partial L_{total}}{\partial out_{o2}} \cdot \frac{\partial out_{o2}}{\partial net_{o2}} \cdot \frac{\partial net_{o2}}{\partial out_{h1}}<br>\right) \\<br>&amp; \cdot \frac{\partial out_{h1}}{\partial net_{h1}} \cdot \frac{\partial net_{h1}}{\partial w_1} \\<br>= &amp; (sum_o \delta_o \cdot w_{ho}) \times out_{h1} (1 - out_{h1}) \times i_1 \\<br>= &amp; 0.0364 \times 0.2413 \times 0.05 = 0.000439<br>\end{aligned}<br>$$</p>
<p>çœ‹è‘—å¾ˆææ€–ï¼Œå…¶å¯¦ä¸¦ä¸è¤‡é›œã€‚ä»¥ç¬¬äºŒè¡ŒåŠ è™Ÿå·¦é‚Šçš„ä¸‰é …ç‚ºä¾‹ï¼Œå‰å…©é … \(\delta_{o1}\) ä¸Šé¢å·²ç¶“ç®—éäº†ï¼›ç¬¬ä¸‰é …ä»ç„¶æœ‰ \(net_{o1} = w_5 * out_{h1}\ +\ w_6 * out_{h1}\ +\ b_2\)ï¼Œæ‰€ä»¥ \(\frac{\partial net_{o1}}{\partial out_{h1}} = w_5 = 0.40\)ï¼Œç”±æ–¼é€™éƒ½æ˜¯ä¸€æ¬¡ç·šæ€§çš„é‹ç®—ï¼Œæ‰€ä»¥å°æ¬Šé‡æ±‚å°å°±å¾—è¼¸å…¥ï¼Œå°è¼¸å…¥æ±‚å°å°±å¾—æ¬Šé‡ï¼›å°æ–¼ç¬¬ä¸‰è¡Œï¼Œç¬¬ä¸€é …æ˜¯æ¿€æ´»å‡½æ•°ï¼Œå’Œä¸Šé¢ä¹Ÿä¸€æ¨£ï¼Œæœ€å¾Œä¸€é …æ˜¯å°æ¬Šé‡æ±‚å°ï¼Œæ‰€ä»¥å¾—è¼¸å…¥å€¼ <code>i1</code>ã€‚</p>
<p>é€™è£¡ä¹Ÿçœ‹åˆ°ä¸€ä»¶äº‹ï¼Œå°±æ˜¯è¶Šå¾€å¾Œæ¢¯åº¦è¶Šä¾†è¶Šå°äº†ï¼Œå› ç‚ºä¹˜ä¸Šå°æ–¼ä¸€çš„é …è¶Šä¾†è¶Šå¤šï¼Œã€Œæ¢¯åº¦æ¶ˆå¤±ã€èªªçš„å°±æ˜¯é€™éº¼å›äº‹ã€‚</p>
<h2 id="å¦‚ä½•ç°¡æ˜åœ°å¯¦ç¾"><a href="#å¦‚ä½•ç°¡æ˜åœ°å¯¦ç¾" class="headerlink" title="å¦‚ä½•ç°¡æ˜åœ°å¯¦ç¾"></a>å¦‚ä½•ç°¡æ˜åœ°å¯¦ç¾</h2><p>é¡¯ç„¶å°æ–¼æ¯ä¸€å€‹æ¬Šé‡ï¼Œæˆ‘å€‘ä¸æ‡‰ç•¶å¾æå¤±å‡½æ•°é–‹å§‹ä¸€å€‹ä¸€å€‹åœ°è¨ˆç®—åˆ°æœ€å¾Œï¼Œè€Œæ˜¯æ‡‰ç•¶å…ˆè¨ˆç®—ä¸€ç´šï¼ˆè¼¸å‡ºå±‚ï¼‰ï¼Œç„¶å¾ŒæŠŠä¸€äº›è¨ˆç®—çµæœå‚³çµ¦å‰ä¸€ç´šï¼ˆéš±è—å±‚ï¼‰ï¼Œç„¶å¾Œå‰ä¸€ç´šæ‹¿åˆ°é€™å€‹çµæœåªéœ€è¨ˆç®—å’Œä»–ç›´æ¥ç›¸é€£çš„éƒ¨åˆ†ã€‚å¯¦éš›ä½¿ç”¨ä¸Šï¼Œå…¨é€£æ¥å±‚ä¹Ÿæ˜¯ä¸€å€‹æ•´é«”ï¼Œè‚¯å®šä¸æœƒä¸€å€‹ä¸€å€‹ç¥ç¶“å…ƒå–®ç¨è¨ˆç®—ã€‚</p>
<p>æˆ‘å€‘åœ¨å¾—åˆ° [\(\delta_{o1}\), \(\delta_{o2}\)] ä¹‹å¾Œï¼Œå¯ä»¥ä½œç‚ºä¸€å€‹æ•´é«”å‚³çµ¦å¾Œä¸€å±‚ï¼Œç„¶å¾Œåšä¸€å€‹çŸ©é™£ä¹˜æ³• \(\cdot \begin{bmatrix} w_5 &amp; w_6 \\ w_7 &amp; w_8 \end{bmatrix}\)ã€‚</p>
<ul>
<li><p>å°æ–¼ç´”å…¬å¼çš„æ¨å°ï¼Œå¯ä»¥åƒè€ƒ <a href="https://zhuanlan.zhihu.com/p/39195266" target="_blank" rel="noopener">åå‘ä¼ æ’­ç®—æ³•æ¨å¯¼-å…¨è¿æ¥ç¥ç»ç¶²ç»œ</a></p>
</li>
<li><p>å°æ–¼æ˜“æ‡‚çš„ä»£ç¢¼ï¼Œå¯ä»¥åƒè€ƒ <a href="https://machinelearningmastery.com/implement-backpropagation-algorithm-scratch-python/" target="_blank" rel="noopener">How to Code a Neural Network with Backpropagation In Python (from scratch)</a></p>
</li>
</ul>
<h1 id="å·ç©å±‚ä¸­çš„åå‘å‚³æ’­"><a href="#å·ç©å±‚ä¸­çš„åå‘å‚³æ’­" class="headerlink" title="å·ç©å±‚ä¸­çš„åå‘å‚³æ’­"></a>å·ç©å±‚ä¸­çš„åå‘å‚³æ’­</h1><p>å·ç©å±‚è‡ªç„¶æ˜¯å·ç©ç¥ç¶“ç¶²çµ¡çš„é—œéµï¼Œæ‰€ä»¥é€™ä¸€éƒ¨åˆ†å…ˆæœƒèªªå¾—æ¯”è¼ƒæŠ½è±¡å’Œæ³›åŒ–ã€‚å°æ–¼å·ç©å±‚ï¼Œåœ¨é‹ç®—ä¸Šèˆ‡ä¸Šä¸€ç¯€æ²’æœ‰ä»€éº¼ä¸åŒï¼Œæ‰€ä»¥æˆ‘å€‘å¯ä»¥é æ–™å°æ¬Šé‡æ±‚å°å°±å¾—è¼¸å…¥ï¼Œå°è¼¸å…¥æ±‚å°å°±å¾—æ¬Šé‡é‚„æ˜¯ä¸€æ¨£çš„ã€‚å€åˆ¥åœ¨æ–¼å‰å¾Œçš„é€£çµæ–¹å¼ï¼Œå·ç©å±‚æ˜¯ç¨€ç–çš„é€£æ¥ï¼Œä¸€å€‹ç¥ç¶“å…ƒä¸¦ä¸æœƒå’Œå¾Œä¸€ç´šæ‰€æœ‰ç¥ç¶“å…ƒç›¸é€£ï¼Œæ­¤å¤–ï¼Œæ¬Šé‡æœƒæœ‰å¾©ç”¨ï¼Œæ‰€ä»¥ä¸åŒçš„é€£ç·šï¼Œä¸è¡¨ç¤ºé€™å€‹é€£ç·šä¸Šçš„æ¬Šé‡ä¸åŒï¼Œå¦‚ä¸‹åœ–ã€‚ç•¶å·ç©æ ¸å¤§å°ç­‰æ–¼è¼¸å…¥åœ–æ™‚ï¼Œå·ç©å±‚å°±å¤‰ç‚ºä¸€å€‹å…¨é€£æ¥å±‚ï¼Œæ‰€ä»¥é€™è£¡æœƒæ˜¯ä¸Šé¢ä¸€ç¯€é€²ä¸€æ­¥æŠ½è±¡ã€æ³›åŒ–çš„åå‘å‚³æ’­æ–¹å¼ã€‚</p>
<div class="figure center" style="width:;"><a class="fancybox" href="https://d2y8c08sxwbp8v.cloudfront.net/2020-backward-in-convnet/connection-in-forward-pass-of-conv.png" target="_blank" rel="noopener" title="forward pass of conv" data-caption="forward pass of conv" data-fancybox="default"><img class="fig-img" src="https://d2y8c08sxwbp8v.cloudfront.net/2020-backward-in-convnet/connection-in-forward-pass-of-conv.png" alt="forward pass of conv"></a><span class="caption">forward pass of conv</span></div><div style="clear:both;"></div>

<div class="alert info"><p><strong>ç¬¦è™Ÿèªªæ˜ï¼š</strong></p>
<ol>
<li><p>å·ç©æ ¸ \(w\) çš„å°ºå¯¸ç‚º \(k_1 \times k_2\)ï¼Œ\(w_{m,n}^l\) è¡¨ç¤ºé€™å€‹å·ç©æ ¸å…§é€šé“ç‚º \(l\)ï¼Œä½ç½®ç‚º \(m, n\) çš„åƒæ•°å€¼ã€‚</p>
</li>
<li><p>\(x_{i,j}^l\) è¡¨ç¤ºä¸€å€‹å·ç©çš„çµæœï¼Œå®ƒæ˜¯ç”±ä¸Šä¸€å±‚çš„è¼¸å‡ºèˆ‡å·ç©æ ¸æ¬Šé‡ç›¸ä¹˜åŠ ä¸Šåç½®å€¼å¾—åˆ°ã€‚è¼¸å…¥ç‰¹å¾µåœ– \(O\)ï¼ˆå³é€²è¡Œå·ç©ä¹‹å‰çš„ï¼‰çš„å°ºå¯¸ä½¿ç”¨ \(H \times W\) è¡¨ç¤ºï¼Œ \(i, j\) ç‚ºç‰¹å¾µåœ–ä¸Šçš„æŸä¸€å€‹ä½ç½®ã€‚<br>$$<br>x_{i,j}^l = \sum_{m = 0}^{k_1 - 1} \sum_{n = 0}^{k_2 - 1} w_{m,n}^l o_{i + m,j + n}^{l-1} + b^l<br>$$</p>
</li>
<li><p>\(o_{i,j}^l\) ç‚ºæ¿€æ´»å‡½æ•°çš„è¼¸å‡ºå€¼ï¼Œå³ \(o_{i,j}^l = f(x_{i,j}^{l})\)ï¼Œ\(f(\cdot)\) è¡¨ç¤ºæŸç¨®æ¿€æ´»å‡½æ•°ã€‚</p>
</li>
</ol>
</div>


<p>å‡è¨­é€²è¡Œçš„æ˜¯ <code>padding=0, stride=1</code> çš„å·ç©ï¼Œé‚£éº¼æ­£å‘éç¨‹å¦‚ç¬¦è™Ÿèªªæ˜å…§çš„å…¬å¼ï¼Œ\(\delta w_{m^{\prime},n^{\prime}}^l\) ç‚º<br>$$<br>\frac{\partial L}{\partial w_{m^{\prime},n^{\prime}}^l} = \sum_{i=0}^{H-k_1} \sum_{j=0}^{W-k_2} \frac{\partial L}{\partial x_{i,j}^{l}} \frac{\partial x_{i,j}^{l}}{\partial w_{m^{\prime},n^{\prime}}^l} \tag{1}<br>$$</p>
<p>é€™è£¡çš„ \(x_{i,j}^l\) å°±æ˜¯ä¸Šä¸€ç¯€ä¸­çš„ <code>net</code> å±‚ä¸­çš„å…ƒç´ ï¼Œæ¯”å¦‚ <code>net h1</code>ã€<code>net o1</code>ã€‚æ‰€ä»¥é€™å€‹å…¬å¼è¡¨ç¤ºçš„å°±æ˜¯ç›´é”æ¬Šé‡çš„æœ€å¾Œä¸€æ­¥ï¼Œç¬¬äºŒé …é¡ä¼¼æ–¼ä¹‹å‰çš„ \(\frac{\partial net_{h1}}{\partial w_1}\)ï¼Œç¬¬ä¸€é … \(\delta x_{i,j}^{l}\) å¦‚å‰æ‰€è¿°æ˜¯å¾å‰æ–¹å±‚å‚³ééä¾†çš„ï¼Œåœ¨é€™è£¡æ˜¯å€‹å·²çŸ¥å€¼ã€‚ç©åˆ†çš„å€åŸŸç‚ºå·ç©æ ¸ä¸Šçš„é€™å€‹åƒæ•°è§¸åŠçš„å€åŸŸã€‚</p>
<p>åˆæœ‰<br>$$<br>x_{i,j}^l = \sum_{m = 0}^{k_1 - 1} \sum_{n = 0}^{k_2 - 1} w_{m,n}^l o_{i + m,j + n}^{l-1} + b^l<br>$$</p>
<p>æ‰€ä»¥ç¬¬äºŒé …æœ‰<br>$$<br>\frac{\partial x_{i,j}^{l}}{\partial w_{m^{\prime},n^{\prime}}^l} = \frac{\partial}{\partial w_{m^{\prime},n^{\prime}}^l}\left( \sum_{m} \sum_{n} w_{m,n}^{l}o_{i+m, j+n}^{l-1} + b^l \right)<br>$$</p>
<p>ç¹¼çºŒé€²ä¸€æ­¥å±•é–‹ï¼Œå·ç©æ ¸å…§çš„æ¯ä¸€å€‹æ¬Šé‡é¡¯ç„¶æ˜¯ç¨ç«‹çš„ï¼Œå‰ä¸€å±‚çš„è¼¸å‡º <code>o</code> é¡¯ç„¶ä¹Ÿä¸å—é€™å€‹å·ç©æ ¸çš„å½±éŸ¿ï¼Œæ‰€ä»¥å±•é–‹å¾Œï¼Œåªæœ‰ä¸€é …æ±‚åå°ä¸ç‚ºé›¶<br>$$<br>\begin{align}<br>\frac{\partial x_{i,j}^{l}}{\partial w_{m^{\prime},n^{\prime}}^l} &amp;= \frac{\partial}{\partial w_{mâ€™,nâ€™}^l}\left( w_{0,0}^{l} o_{ i + 0, j + 0}^{l-1} + \dots + w_{mâ€™,nâ€™}^{l} o_{ i + m^{\prime}, j + n^{\prime}}^{l-1} + \dots + b^l\right) \\<br>&amp; = \frac{\partial}{\partial w_{m^{\prime},n^{\prime}}^l}\left( w_{m^{\prime},n^{\prime}}^{l} o_{ i + m^{\prime}, j + n^{\prime}}^{l-1}\right) \\<br>&amp; = o_{i+m^{\prime},j+n^{\prime}}^{l-1}<br>\end{align}<br>$$</p>
<p>æŠŠé€™å€‹çµè«–ä»£å…¥æœ€é–‹å§‹çš„å…¬å¼ï¼ˆ1ï¼‰ï¼š<br>$$<br>\frac{\partial L}{\partial w_{mâ€™,nâ€™}^l} = \sum_{i=0}^{H-k_1} \sum_{j=0}^{W-k_2} \delta x_{i,j}^{l} \cdot o_{ i + m^{\prime}, j + n^{\prime}}^{l-1} \tag{2}<br>$$</p>
<p>é€™å€‹å¼å­è£¡é¢é›™é‡æ±‚å’Œå°±æ˜¯æ¬Šé‡å…±äº«çš„çµæœï¼Œéš¨è‘— <code>k1</code>ï¼Œ<code>k2</code> çš„å¢å¤§ï¼Œå·ç©æ ¸çš„å¤§å°é€æ¼¸æ¥è¿‘æ–¼è¼¸å…¥ç‰¹å¾µåœ–ï¼Œé€™å€‹æ±‚å’Œå€åŸŸä¹Ÿé€æ¼¸æ¸›å°ã€‚ç•¶æ ¸çš„å¤§å°ç­‰æ–¼ç‰¹å¾µåœ–å¤§å°æ™‚ï¼Œé€™å€‹å¼å­èˆ‡ä¸Šä¸€ç¯€ä¸­çš„å…¨é€£æ¥çš„å½¢å¼ç›¸åŒã€‚åŒæ™‚æˆ‘å€‘å°æ¯”ä¸€ä¸‹æœ€é–‹å§‹çš„å·ç©å…¬å¼ï¼š<br>$$<br>x_{i,j}^l = \sum_{m = 0}^{k_1 - 1} \sum_{n = 0}^{k_2 - 1} w_{m,n}^l o_{i + m,j + n}^{l-1} + b^l<br>$$</p>
<p>å°±ç™¼ç¾é€™å€‹ï¼ˆgradients of L w.r.t to the weightï¼‰æ±‚å°çš„å…¬å¼å…¶å¯¦å°±æ˜¯å€‹å·ç©æ“ä½œï¼Œè¼¸å…¥æ˜¯ \(O^{l-1}\)ï¼Œå·ç©æ ¸æ˜¯å‰æ–¹å±‚å‚³ä¾†çš„æ¢¯åº¦åœ–ï¼ˆgradients of L w.r.t to the feature mapsï¼‰ï¼Œè¡¨ç¤ºç‰¹å¾µåœ–ä¸Šä¸€å€‹å€¼çš„å¤‰å‹•ï¼Œæœƒå°æå¤±å€¼é€ æˆå¤šå¤§å½±éŸ¿ã€‚é€™å€‹æ¢¯åº¦åœ–é¡¯ç„¶ä¹Ÿä¸æ˜¯æ†‘ç©ºç”¢ç”Ÿçš„ï¼Œæˆ‘å€‘ç¾åœ¨å°±é‚„è¦è¨ˆç®—å®ƒã€‚</p>
<p>å°æ–¼ä¸€å€‹ \(x_{i,j}^l\)ï¼Œå®ƒåœ¨ <code>l+1</code> å±‚ä¸­çš„å½±éŸ¿å€åŸŸæ˜¯å·¦ä¸Šè§’ \(\left(i^{\prime}-k_1+1,j^{\prime}-k_2+1 \right)\) åˆ°å³ä¸‹è§’ \(\left(i^{\prime},j^{\prime} \right)\) ä¸­é–“çš„çŸ©å½¢å€åŸŸã€‚é‚£éº¼</p>
<p>$$<br>\begin{align}<br>\frac{\partial L}{\partial x_{iâ€™,jâ€™}^{l}} &amp;= \sum_{m = 0}^{k_1 -1} \sum_{n = 0}^{k_2 -1} \frac{\partial E}{\partial x_{iâ€™-m, jâ€™-n}^{l+1}}\frac{\partial x_{iâ€™-m, jâ€™-n}^{l+1}}{\partial x_{iâ€™,jâ€™}^l} \\<br>&amp;= \sum_{m = 0}^{k_1 -1} \sum_{n = 0}^{k_2 -1} \delta_{iâ€™-m, jâ€™-n}^{l+1} \frac{\partial x_{iâ€™-m, jâ€™-n}^{l+1}}{\partial x_{iâ€™,jâ€™}^l} \tag{3} \\<br>\end{align}<br>$$</p>
<p>é‚„æ˜¯ä¸€æ¨£åœ°çœ‹ç¬¬äºŒé …ï¼Œå±•é–‹è£¡é¢çš„ <code>x</code>ï¼š<br>$$<br>\begin{align}<br>\frac{\partial x_{iâ€™-m,jâ€™-n}^{l+1}}{\partial x_{iâ€™,jâ€™}^l} &amp;= \frac{\partial}{\partial x_{iâ€™,jâ€™}^l} \left( \sum_{mâ€™=0}^{k_1^{l+1} -1} \sum_{nâ€™=0}^{k_2^{l+1} -1} w_{mâ€™, nâ€™}^{l+1} o_{iâ€™ - m + mâ€™,jâ€™ - n + nâ€™}^{l} + b^{l+1} \right) \\<br>&amp;= \frac{\partial}{\partial x_{iâ€™,jâ€™}^l}\left( \sum_{mâ€™=0}^{k_1^{l+1} -1} \sum_{nâ€™=0}^{k_2^{l+1} -1} w_{mâ€™,nâ€™}^{l+1}f\left(x_{iâ€™ - m + mâ€™,jâ€™ - n + nâ€™}^{l}\right) + b^{l+1} \right)<br>\end{align}<br>$$</p>
<p>ç¹¼çºŒå±•é–‹å…©å€‹æ±‚å’Œï¼Œåœ¨é€™è£¡åŒæ¨£ï¼Œä¸‹ä¸€å±‚çš„æ¬Šé‡ä¸æœƒå—é€™ä¸€å±‚çš„ç‰¹å¾µåœ–çš„å½±éŸ¿ï¼Œä¸€å€‹ç‰¹å¾µåœ–ä¹‹å…§çš„å„å€‹å€¼ä¹Ÿæ˜¯ç¨ç«‹çš„ï¼Œæ‰€ä»¥å®ƒå€‘çš„åå°éƒ½ç‚ºé›¶ï¼š<br>$$<br>\begin{align}<br>\frac{\partial x_{i^{\prime} - m,j^{\prime} - n}^{l+1}}{\partial x_{iâ€™,jâ€™}^l}<br>&amp;= \frac{\partial}{\partial x_{iâ€™,jâ€™}^l}\left( w_{mâ€™,nâ€™}^{l+1} f(x_{ 0 - m + mâ€™, 0 - n + nâ€™}^{l}) + \dots + w_{m,n}^{l+1} f(x_{iâ€™,jâ€™}^{l}) + \dots + b^{l+1}\right) \\<br>&amp;= \frac{\partial}{\partial x_{iâ€™,jâ€™}^l}\left( w_{m,n}^{l+1} f(x_{iâ€™,jâ€™}^{l}) \right) \\<br>&amp;= w_{m,n}^{l+1} \frac{\partial}{\partial x_{iâ€™,jâ€™}^l} \left( f(x_{iâ€™,jâ€™}^{l}) \right) \\<br>&amp;= w_{m,n}^{l+1} fâ€™(x_{iâ€™,jâ€™}^{l})<br>\end{align}<br>$$</p>
<p>æŠŠé€™å€‹çµè«–ä»£å›é–‹å§‹çš„å…¬å¼ï¼ˆ3ï¼‰ï¼š<br>$$<br>\frac{\partial E}{\partial x_{iâ€™,jâ€™}^{l}} =<br>fâ€™(x_{iâ€™,jâ€™}^{l}) \cdot \sum_{m = 0}^{k_1^{l+1} - 1} \sum_{n = 0}^{k_2^{l+1} - 1} \delta_{iâ€™-m, jâ€™-m}^{l+1} w_{m,n}^{l+1} \tag{4}<br>$$</p>
<p>é€™åŒæ¨£æ˜¯ä¸€å€‹å·ç©ï¼Œåªæ˜¯ <code>i-m, j-n</code> è¡¨ç¤ºæˆ‘å€‘éœ€è¦æŠŠå·ç©æ ¸åè½‰ 180 åº¦ã€‚é€™å€‹å·ç©çš„è¼¸å…¥æ˜¯æ›´å‰é¢å±‚å‚³å›çš„ \(\delta_{iâ€™-m, jâ€™-m}^{l+1}\)ï¼Œå·ç©æ ¸æ˜¯ <code>l+1</code> å±‚çš„æ¬Šé‡ï¼Œè€Œ \(fâ€™(x_{iâ€™,jâ€™}^{l})\) é€™å€‹æ¿€æ´»å‡½æ•°çš„å°æ•°æ˜¯å€‹å¸¸æ•°ï¼Œå‰é¢ä¹Ÿæåˆ°äº†ï¼Œå®ƒæ˜¯å°æ¯å€‹å…ƒç´ å–®ç¨åšçš„ã€‚</p>
<p>å…¬å¼ï¼ˆ2ï¼‰å’Œï¼ˆ4ï¼‰å°±æ˜¯åå‘å‚³æ’­çš„æ ¸å¿ƒï¼Œå‰è€…ç”¨æ–¼æ›´æ–°åƒæ•°ï¼Œå¾Œè€…ç”¨æ–¼å°‡å°ç¸½æå¤±çš„æ¢¯åº¦å‘å¾Œå‚³æ’­ï¼Œç”¨æ–¼å¾Œä¸€å±‚çš„è¨ˆç®—ã€‚åŒæ™‚ï¼Œé€™è£¡æˆ‘å€‘çœ‹åˆ°ï¼Œå·ç©æ±‚æ¢¯åº¦ä¹Ÿæ˜¯ç”±å·ç©å®Œæˆï¼Œæ‰€ä»¥æœ‰äº›åœ°æ–¹æœƒèªªåå·ç©å°±æ˜¯ç”¨å·ç©çš„æ¢¯åº¦ã€‚</p>
<h2 id="ç°¡å–®ä¾‹å­å’Œä»£ç¢¼"><a href="#ç°¡å–®ä¾‹å­å’Œä»£ç¢¼" class="headerlink" title="ç°¡å–®ä¾‹å­å’Œä»£ç¢¼"></a>ç°¡å–®ä¾‹å­å’Œä»£ç¢¼</h2><p>ä¸Šè¿°åˆ†æå¯ä»¥çœ‹å‡ºï¼Œå½¢å¼éƒ½æ˜¯é¡ä¼¼çš„ï¼Œä½†æ˜¯æœ‰é»æŠ½è±¡ï¼Œé€™è£¡æˆ‘å€‘çœ‹ä¸€å€‹å…·é«”çš„ä¾‹å­å¹«åŠ©ç†è§£ã€‚ä¸‹é¢çš„åœ–æ˜¯ä¸€å€‹å·ç©çš„æ­£å‘éç¨‹ï¼Œé€™è£¡æˆ‘å€‘ç•¥å» biasã€‚</p>
<div class="figure center" style="width:;"><a class="fancybox" href="https://d2y8c08sxwbp8v.cloudfront.net/2020-backward-in-convnet/forward-pass-of-conv.png" target="_blank" rel="noopener" title="foward pass of a simple conv example" data-caption="foward pass of a simple conv example" data-fancybox="default"><img class="fig-img" src="https://d2y8c08sxwbp8v.cloudfront.net/2020-backward-in-convnet/forward-pass-of-conv.png" alt="foward pass of a simple conv example"></a><span class="caption">foward pass of a simple conv example</span></div><div style="clear:both;"></div>

<p>$$<br>\begin{align}<br>X_{11} = W_{11} O_{11} + W_{12} O_{12} + W_{21} O_{21} + W_{22} O_{22} \\<br>X_{12} = W_{11} O_{12} + W_{12} O_{13} + W_{21} O_{22} + W_{22} O_{23} \\<br>X_{21} = W_{11} O_{21} + W_{12} O_{22} + W_{21} O_{31} + W_{22} O_{32} \\<br>X_{22} = W_{11} O_{22} + W_{12} O_{23} + W_{21} O_{32} + W_{22} O_{33} \\<br>\end{align}<br>$$</p>
<p>æŠŠä¸Šé¢å››å€‹å¼å­åŠ åœ¨ä¸€èµ·ï¼Œç„¶å¾Œåˆ†åˆ¥å°å››å€‹åƒæ•°æ±‚åå°ï¼Œå¯å¾—</p>
<p>$$<br>\begin{align}<br>\frac{\partial L}{\partial W_{11}} = \frac{\partial L}{\partial X_{11}} \frac{\partial X_{11}}{\partial W_{11}} + \frac{\partial L}{\partial X_{12}} \frac{\partial X_{12}}{\partial W_{11}} + \frac{\partial L}{\partial X_{21}} \frac{\partial X_{21}}{\partial W_{11}} + \frac{\partial L}{\partial X_{22}} \frac{\partial X_{22}}{\partial W_{11}} \\<br>\frac{\partial L}{\partial W_{12}} = \frac{\partial L}{\partial X_{11}} \frac{\partial X_{11}}{\partial W_{12}} + \frac{\partial L}{\partial X_{12}} \frac{\partial X_{12}}{\partial W_{12}} + \frac{\partial L}{\partial X_{21}} \frac{\partial X_{21}}{\partial W_{12}} + \frac{\partial L}{\partial X_{22}} \frac{\partial X_{22}}{\partial W_{12}} \\<br>\frac{\partial L}{\partial W_{21}} = \frac{\partial L}{\partial X_{11}} \frac{\partial X_{11}}{\partial W_{21}} + \frac{\partial L}{\partial X_{12}} \frac{\partial X_{12}}{\partial W_{21}} + \frac{\partial L}{\partial X_{21}} \frac{\partial X_{21}}{\partial W_{12}} + \frac{\partial L}{\partial X_{22}} \frac{\partial X_{22}}{\partial W_{21}} \\<br>\frac{\partial L}{\partial W_{22}} = \frac{\partial L}{\partial X_{11}} \frac{\partial X_{11}}{\partial W_{22}} + \frac{\partial L}{\partial X_{12}} \frac{\partial X_{12}}{\partial W_{22}} + \frac{\partial L}{\partial X_{21}} \frac{\partial X_{21}}{\partial W_{22}} + \frac{\partial L}{\partial X_{22}} \frac{\partial X_{22}}{\partial W_{22}} \\<br>\end{align}<br>$$</p>
<p>æˆ‘å€‘åœ¨ä¹‹å‰å·²ç¶“çŸ¥é“ï¼Œ\(\frac{\partial X}{\partial W} = O\)ï¼Œæ‰€ä»¥ä¸Šé¢çš„å¼å­å¯ä»¥å¯«æˆ<br>$$<br>\begin{align}<br>\frac{\partial L}{\partial W_{11}} = \frac{\partial L}{\partial X_{11}} O_{11} + \frac{\partial L}{\partial X_{12}} O_{12} + \frac{\partial L}{\partial X_{21}} O_{21} + \frac{\partial L}{\partial X_{22}} O_{22} \\<br>\frac{\partial L}{\partial W_{12}} = \frac{\partial L}{\partial X_{11}} O_{12} + \frac{\partial L}{\partial X_{12}} O_{13} + \frac{\partial L}{\partial X_{21}} O_{22} + \frac{\partial L}{\partial X_{22}} O_{23} \\<br>\frac{\partial L}{\partial W_{21}} = \frac{\partial L}{\partial X_{11}} O_{21} + \frac{\partial L}{\partial X_{12}} O_{22} + \frac{\partial L}{\partial X_{21}} O_{31} + \frac{\partial L}{\partial X_{22}} O_{32} \\<br>\frac{\partial L}{\partial W_{22}} = \frac{\partial L}{\partial X_{11}} O_{22} + \frac{\partial L}{\partial X_{12}} O_{23} + \frac{\partial L}{\partial X_{21}} O_{32} + \frac{\partial L}{\partial X_{22}} O_{33} \\<br>\end{align}<br>$$</p>
<p>å¦‚æœä»”ç´°çœ‹çœ‹ï¼Œé€™å€‹å½¢å¼ï¼Œå…¶å¯¦å°±æ˜¯å·ç©ï¼Œå·ç©çš„è¼¸å…¥æ˜¯æ­£å‘éç¨‹ç›¸åŒçš„è¼¸å…¥ï¼Œå·ç©æ ¸æ˜¯å¾å¾Œä¸€å±‚å‚³éä¾†çš„æ¢¯åº¦åœ–ï¼Œå¦‚ä¸‹åœ–æ‰€ç¤ºã€‚</p>
<div class="figure center" style="width:;"><a class="fancybox" href="https://d2y8c08sxwbp8v.cloudfront.net/2020-backward-in-convnet/weight-gradient-calc.png" target="_blank" rel="noopener" title="weight gradient calculation as conv" data-caption="weight gradient calculation as conv" data-fancybox="default"><img class="fig-img" src="https://d2y8c08sxwbp8v.cloudfront.net/2020-backward-in-convnet/weight-gradient-calc.png" alt="weight gradient calculation as conv"></a><span class="caption">weight gradient calculation as conv</span></div><div style="clear:both;"></div>

<p>ç¾åœ¨æˆ‘å€‘å¾—åˆ°äº†å·ç©æ ¸ <code>W</code> çš„æ¯å€‹å…ƒç´ å°æ–¼æœ€çµ‚æå¤±çš„æ¢¯åº¦ï¼Œæˆ‘å€‘å¯ä»¥æ›´æ–°é€™å€‹å·ç©æ ¸çš„åƒæ•°äº†ã€‚åŒæ¨£ï¼Œä¸‹ä¸€ä»¶äº‹æ˜¯ï¼Œå¾—åˆ°è¼¸å…¥ç‰¹å¾µåœ– <code>O</code> ä¸Šæ¯å€‹å…ƒç´ é—œæ–¼æœ€çµ‚æå¤±çš„æ¢¯åº¦ï¼Œé€™æ¨£æˆ‘å€‘æ‰å¯ä»¥æŠŠé€™å€‹æ¢¯åº¦ç¹¼çºŒå‘å¾Œå‚³æ’­ã€‚</p>
<p>åŒæ¨£æŠŠå››å€‹å¼å­ç›¸åŠ ï¼Œç„¶å¾Œæ±‚åå°ï¼Œçµæœå¦‚ä¸‹ï¼š<br>$$<br>\begin{align}<br>\frac{\partial L}{\partial O_{11}} = \frac{\partial L}{\partial X_{11}} W_{11} + \frac{\partial L}{\partial X_{12}} \cdot 0 + \frac{\partial L}{\partial X_{21}} \cdot 0 + \frac{\partial L}{\partial X_{22}} \cdot 0 \\<br>\frac{\partial L}{\partial O_{12}} = \frac{\partial L}{\partial X_{11}} W_{12} + \frac{\partial L}{\partial X_{12}} W_{11} + \frac{\partial L}{\partial X_{21}} \cdot 0 + \frac{\partial L}{\partial X_{22}} \cdot 0 \\<br>\frac{\partial L}{\partial O_{13}} = \frac{\partial L}{\partial X_{11}} \cdot 0 + \frac{\partial L}{\partial X_{12}} W_{12} + \frac{\partial L}{\partial X_{21}} \cdot 0 + \frac{\partial L}{\partial X_{22}} \cdot 0 \\<br>\frac{\partial L}{\partial O_{21}} = \frac{\partial L}{\partial X_{11}} W_{21} + \frac{\partial L}{\partial X_{12}} \cdot 0 + \frac{\partial L}{\partial X_{21}} W_{11} + \frac{\partial L}{\partial X_{22}} \cdot 0 \\<br>\frac{\partial L}{\partial O_{22}} = \frac{\partial L}{\partial X_{11}} W_{22} + \frac{\partial L}{\partial X_{12}} W_{21} + \frac{\partial L}{\partial X_{21}} W_{12} + \frac{\partial L}{\partial X_{22}} W_{11} \\<br>\frac{\partial L}{\partial O_{23}} = \frac{\partial L}{\partial X_{11}} \cdot 0 + \frac{\partial L}{\partial X_{12}} W_{22} + \frac{\partial L}{\partial X_{21}} \cdot 0 + \frac{\partial L}{\partial X_{22}} W_{11} \\<br>\frac{\partial L}{\partial O_{31}} = \frac{\partial L}{\partial X_{11}} \cdot 0 + \frac{\partial L}{\partial X_{12}} \cdot 0 + \frac{\partial L}{\partial X_{21}} W_{21} + \frac{\partial L}{\partial X_{22}} W_{11} \\<br>\frac{\partial L}{\partial O_{32}} = \frac{\partial L}{\partial X_{11}} \cdot 0 + \frac{\partial L}{\partial X_{12}} \cdot 0 + \frac{\partial L}{\partial X_{21}} W_{22} + \frac{\partial L}{\partial X_{22}} W_{21} \\<br>\frac{\partial L}{\partial O_{33}} = \frac{\partial L}{\partial X_{11}} \cdot 0 + \frac{\partial L}{\partial X_{12}} \cdot 0 + \frac{\partial L}{\partial X_{21}} \cdot 0 + \frac{\partial L}{\partial X_{22}} W_{22} \\<br>\end{align}<br>$$</p>
<p>é€™çœ‹èµ·ä¾†é¡¯ç„¶ä¹Ÿæ˜¯ä¸€ç¨®å·ç©æ“ä½œï¼Œæœ‰äººæŠŠå®ƒå«åšå…¨å·ç©ï¼ˆå®Œå…¨çš„ã€Œå…¨ã€ï¼Œä¸æ˜¯å…¨éƒ¨çš„ã€Œå…¨ã€ï¼‰ï¼Œç¤ºæ„åœ–åœ¨ä¸‹é¢ï¼Œç°¡å–®èªªå°±æ˜¯ <code>padding = 1</code>ã€‚é€™è£¡æˆ‘å€‘éœ€è¦ç”¨åˆ°æ­£å‘éç¨‹ä¸­çš„å·ç©æ ¸ï¼Œå°‡å®ƒæ—‹è½‰ 180 åº¦å¾Œä½¿ç”¨ã€‚</p>
<div class="figure center" style="width:;"><a class="fancybox" href="https://d2y8c08sxwbp8v.cloudfront.net/2020-backward-in-convnet/input-gradient-calc.png" target="_blank" rel="noopener" title="input gradient calculation as full conv" data-caption="input gradient calculation as full conv" data-fancybox="default"><img class="fig-img" src="https://d2y8c08sxwbp8v.cloudfront.net/2020-backward-in-convnet/input-gradient-calc.png" alt="input gradient calculation as full conv"></a><span class="caption">input gradient calculation as full conv</span></div><div style="clear:both;"></div>

<div class="figure center" style="width:;"><a class="fancybox" href="https://d2y8c08sxwbp8v.cloudfront.net/2020-backward-in-convnet/full-conv-operation.png" target="_blank" rel="noopener" title="full conv operation schematic diagram" data-caption="full conv operation schematic diagram" data-fancybox="default"><img class="fig-img" src="https://d2y8c08sxwbp8v.cloudfront.net/2020-backward-in-convnet/full-conv-operation.png" alt="full conv operation schematic diagram"></a><span class="caption">full conv operation schematic diagram</span></div><div style="clear:both;"></div>

<p>é€™è£¡æœ‰ä¸€å€‹ç°¡å–®çš„ä»£ç¢¼æè¿°ä¸Šé¢çš„éç¨‹</p>
<script src="//gist.github.com/f65a80582f45981ca30edbbf1b6dbd35.js"></script>



<h1 id="æœ€é–‹å§‹çš„å•é¡Œ"><a href="#æœ€é–‹å§‹çš„å•é¡Œ" class="headerlink" title="æœ€é–‹å§‹çš„å•é¡Œ"></a>æœ€é–‹å§‹çš„å•é¡Œ</h1><p>å¾ä¸Šé¢æˆ‘å€‘å¯ä»¥çœ‹å‡ºï¼Œåœ¨åå‘å‚³æ’­çš„éç¨‹ä¸­ï¼Œé™¤äº†æå¤±å°åƒæ•°çš„æ¢¯åº¦æ˜¯å¿…é ˆè¦è¨ˆç®—ä»¥åŠå„²å­˜ä¹‹å¤–ï¼Œæˆ‘å€‘é‚„å¿…é ˆè¨ˆç®—ä¸€å€‹æå¤±å°ç‰¹å¾µåœ–çš„æ¢¯åº¦ï¼Œä¸¦ä¸”è¦æŠŠå®ƒå‚³çµ¦å¾Œä¸€å±‚ã€‚</p>
<p>ä»€éº¼æ˜¯è‘‰å­ç¯€é»ï¼Œç›´è§€å°±æ˜¯å°±æ˜¯ä¸åœ¨ã€Œè–ã€ä¸Šçš„ï¼Œå¾ŒçºŒæ²’æœ‰å…¶å®ƒç¯€é»çš„ç¯€é»ï¼Œå…¶å¯¦æ˜¯å€‹å¾ˆå¸¸è¦‹çš„æ¦‚å¿µã€‚åœ¨é€™è£¡èªªäººè©±å°±æ˜¯ç›´æ¥ç”±ç”¨æˆ¶å‰µå»ºï¼Œè€Œä¸æ˜¯å¾å¦ä¸€å€‹ç¯€é»è¨ˆç®—å¾—åˆ°çš„ç¯€é»ï¼ˆA leaf Variable is a variable that is at the beginning of the graphï¼‰ã€‚ç¥ç¶“ç¶²çµ¡ä¸­çš„åƒæ•°éƒ½æ˜¯ <code>leaf tensor</code>ï¼Œè€Œä¸­é–“çš„æ‰€æœ‰ç‰¹å¾µåœ–å’Œè¼¸å‡ºéƒ½ä¸æ˜¯ <code>leaf tensor</code>ï¼Œè¼¸å…¥åœ–å¯ä»¥æ˜¯ï¼Œä½†æ˜¯ä¸€èˆ¬æ²’äººè¨ˆç®—å®ƒçš„æ¢¯åº¦ã€‚å·§çš„æ˜¯å•æˆ‘é‚£å€‹å•é¡Œå°±æ˜¯å› ç‚ºä»–çš„å„ªåŒ–å°è±¡æ˜¯è¼¸å…¥åœ–åƒï¼ˆå¯è¦–åŒ–ã€é¢¨æ ¼é·ç§»é€™äº›ä»»å‹™ä¸Šæœ‰æ™‚éœ€é€™æ¨£åšï¼‰ã€‚åœ¨ PyTorch ä¸Šï¼Œå¦‚æœä¸€å€‹ CPU Tensor æ˜¯ <code>requires_grad=True</code> çš„ï¼Œé‚£éº¼ç”¨ <code>.to(device)</code> å°‡å®ƒç™¼é€åˆ° GPU çš„æ™‚å€™æœƒç”¢ç”Ÿä¸€å€‹é—œè¯æ“ä½œ <code>grad_fn=&lt;CopyBackwards&gt;</code>ï¼Œè¦è§£æ±ºçš„è©±å¯ä»¥ <code>.to(device).detach().requires_grad_(True)</code>ã€‚</p>
<p>ç‚ºä½• optimizer åªèƒ½å°è‘‰å­ç¯€é»é€²è¡Œæ¢¯åº¦ä¸‹é™ï¼Ÿå› ç‚ºå¹¾ä¹æ‰€æœ‰çš„æ·±åº¦å­¸ç¿’æ¡†æ¶ï¼Œéƒ½ä¸æœƒå„²å­˜éè‘‰å­ç¯€é»çš„æ¢¯åº¦ï¼Œå®ƒçš„æ¢¯åº¦åœ¨å‚³éçµ¦æ‰€æœ‰ç›¸é€£çš„å¾Œæ–¹å±‚ä¹‹å¾Œå°±è¢«åˆªé™¤äº†ï¼Œæ²’æœ‰ç´€éŒ„ä¸‹æ¢¯åº¦è‡ªç„¶æ²’æ³•é€²è¡Œæ¢¯åº¦ä¸‹é™ã€‚é‚£ç‚ºä½•ä¸å„²å­˜å‘¢ï¼Œå›åˆ°æœ€é–‹å§‹çš„é›…å¯æ¯”çŸ©é™£ï¼Œå°æ–¼ä¸€å€‹ tensor functionï¼Œå‡è¨­ <code>H = Hâ€² = W = Wâ€² = 32 and C = Câ€² = 128</code>ï¼Œé‚£éº¼é€™å€‹é›…å¯æ¯”çŸ©é™£å…§çš„å…ƒç´ æ•°æ˜¯ <code>Hâ€²Wâ€²Câ€²HWC â‰ˆ 17 Ã— 10e9</code> å€‹ï¼Œéœ€è¦ç´„ 68GB é€²è¡Œå–®ç²¾åº¦å„²å­˜ï¼Œæ‰€ä»¥ <code>.backward()</code> ä¸€å®šæ˜¯åœ¨ä¸€å€‹æ¨™é‡ä¸Šé€²è¡Œï¼ˆæˆ–è€…èªªè¨ˆç®—çš„æ˜¯ Vector-Jacobian Productï¼‰ã€‚å°æ–¼ä¸€å€‹æ¨™é‡çš„æ¢¯åº¦ï¼ŒçŸ©é™£å¤§å°å°±åªæœ‰ <code>HWC</code> å¤§å°ï¼Œå¤§ç´„æ˜¯ç™¾ MB çš„ç´šåˆ¥ï¼Œä½†æ˜¯é‚„è€ƒæ…®åˆ° batch sizeï¼Œå’Œå„ç¨® skip-connectionï¼Œé€™å€‹ç¸½å¤§å°é‚„æ˜¯å¾ˆå¯è§€çš„ã€‚è€Œä¸”ç¾ä»£ç¶²çµ¡éƒ½æ˜¯å¹¾ç™¾å±‚éš¨éš¨ä¾¿ä¾¿ï¼Œçµ•å°æ²’å¯èƒ½å…¨éƒ¨å„²å­˜ä¸‹ä¾†ã€‚</p>
<div class="figure fig-50" style="width:;"><a class="fancybox" href="https://d2y8c08sxwbp8v.cloudfront.net/2020-backward-in-convnet/forward-network-for-dag.png" target="_blank" rel="noopener" title="forward network for a DAG" data-caption="forward network for a DAG" data-fancybox="default"><img class="fig-img" src="https://d2y8c08sxwbp8v.cloudfront.net/2020-backward-in-convnet/forward-network-for-dag-preview.png" alt="forward network for a DAG"></a><span class="caption">forward network for a DAG</span></div>
<div class="figure fig-50" style="width:;"><a class="fancybox" href="https://d2y8c08sxwbp8v.cloudfront.net/2020-backward-in-convnet/backward-network-for-dag.png" target="_blank" rel="noopener" title="backward network for a DAG" data-caption="backward network for a DAG" data-fancybox="default"><img class="fig-img" src="https://d2y8c08sxwbp8v.cloudfront.net/2020-backward-in-convnet/backward-network-for-dag-preview.png" alt="backward network for a DAG"></a><span class="caption">backward network for a DAG</span></div>
<div style="clear:both;"></div>

<p>å¦‚æœè¦åˆ¤æ–·ä¸€å€‹ tensor æ˜¯ä¸æ˜¯è‘‰å­ç¯€é»ï¼Œå¯ä»¥ä½¿ç”¨ <code>tensor.is_leaf</code>ï¼Œå°æ–¼è‘‰å­ç¯€é»ï¼Œå®ƒæœƒåœ¨åå‘åœ–ä¸­å‰µå»ºä¸€å€‹ <code>AccumulateGrad object</code>ï¼Œä¹Ÿå°±æ˜¯æˆ‘å€‘ç¬¬ä¸€ç¯€ä¸­æåˆ°çš„ï¼Œè¡¨ç¤ºåœ¨é€™è£¡ç´¯ç©æ¢¯åº¦ã€‚</p>
<p>å¦‚æœéœ€è¦ç²å¾—ä¸€å€‹ä¸­é–“å€¼çš„æ¢¯åº¦ï¼Œå¯ä»¥ä½¿ç”¨ <a href="https://pytorch.org/docs/master/autograd.html#torch.Tensor.retain_grad" target="_blank" rel="noopener">retain_grad</a>ï¼Œæˆ–è€…æ›´è¤‡é›œçš„å¯ä»¥ç”¨ <a href="https://pytorch.org/docs/master/autograd.html#torch.Tensor.register_hook" target="_blank" rel="noopener">register_hook</a>ã€‚</p>
<p>é€™è£¡å†èªªä¸€å€‹é—œæ–¼ optimizerã€grad å’Œ weight decay çš„äº‹ã€‚ä¸€èˆ¬ä¾†èªªï¼Œweight decayï¼ˆæ¬Šå€¼è¡°æ¸›ï¼‰æ˜¯èªªè¦åœ¨ loss ä¸ŠåŠ ä¸Šä¸€é …ï¼Œä½¿å¾—ç¶²çµ¡çš„åƒæ•°å°ä¸€é»ï¼Œé˜²æ­¢éæ“¬åˆã€‚å¦‚æœä½¿ç”¨ L2 regularizationï¼Œé‚£éº¼ç¸½çš„ loss ç‚ºï¼š<br>$$<br>\text{Regularized Loss} = \text{Loss} + \lambda \sum_i {\omega}_i^2<br>$$</p>
<p>åœ¨ PyTorch ä¸­ï¼Œweight decay çš„åƒæ•°æ˜¯å‚³çµ¦ optimizer çš„ï¼Œå®ƒæ˜¯åœ¨æ›´æ–°åƒæ•°æ™‚æ‰ç”¨é€™ä¸€é …ï¼ŒæœƒæŠŠæŸä¸€å€‹åƒæ•°çš„æ¢¯åº¦ <a href="https://github.com/pytorch/pytorch/blob/master/torch/optim/sgd.py#L98" target="_blank" rel="noopener">ä¹˜ä»¥ <code>(1 + weight_decay)</code></a>ã€‚é€™éº¼åšä¹Ÿæ˜¯å› ç‚ºåƒæ•°å’Œåƒæ•°ä¹‹é–“æ˜¯ç¨ç«‹çš„ï¼Œæ±‚å°ä¹‹å¾Œå¦‚ä¸‹å¼ï¼ˆä¿‚æ•° <code>2</code> å¯ä»¥å¿½ç•¥ï¼‰ã€‚<br>$$<br>\text{updated weight}_i = \text{weight}_i - lr \times \alpha (grad_i + 2 \lambda {\omega}_i)<br>$$</p>
<h1 id="æ± åŒ–å±‚ä¸­çš„åå‘å‚³æ’­"><a href="#æ± åŒ–å±‚ä¸­çš„åå‘å‚³æ’­" class="headerlink" title="æ± åŒ–å±‚ä¸­çš„åå‘å‚³æ’­"></a>æ± åŒ–å±‚ä¸­çš„åå‘å‚³æ’­</h1><p>çœ¾æ‰€å‘¨çŸ¥æ± åŒ–å±‚ä¸­æ˜¯æ²’æœ‰å¯å­¸ç¿’çš„åƒæ•°çš„ï¼Œæ‰€ä»¥é€™è£¡åªçœ‹å°æ–¼ç‰¹å¾µåœ–ä¸Šçš„å€¼çš„æ¢¯åº¦æ€éº¼é€šéã€‚å¾å‰é¢å‚³ä¾†ä¸€å€‹ <code>C Ã— H Ã— W</code> å¤§å°çš„æ¢¯åº¦åœ–ï¼Œè¦å¾€å¾Œå‚³ä¸€å€‹ <code>C Ã— nH Ã— nW</code> çš„æ¢¯åº¦åœ–ã€‚</p>
<ul>
<li><p>æœ€å¤§å€¼æ± åŒ–ï¼Œå‰å‘éç¨‹ä¸­æœƒç´€éŒ„æ¯ä¸€å€‹ bin ä¸­æœ€å¤§å€¼çš„ä½ç½®ï¼Œåœ¨åå‘éç¨‹ä¸­ï¼Œæ¢¯åº¦æœƒè³¦çµ¦ä¹‹å‰ç´€éŒ„çš„ä½ç½®ï¼Œbin ä¸­çš„å…¶å®ƒä½ç½®å¡« <code>0</code>ã€‚</p>
</li>
<li><p>å¹³å‡å€¼æ± åŒ–ï¼Œæ¢¯åº¦æœƒç¸®å° <code>n Ã— n</code> å€ç„¶å¾Œè³¦çµ¦ä¸€å€‹ bin å…§æ‰€æœ‰ä½ç½®ï¼Œå³æ¯å€‹ bin å…§æ¢¯åº¦ç›¸åŒã€‚</p>
</li>
</ul>
<br/>

<p>å¾Œè©±ï¼šè‡ªå®šç¾©ä¸€å€‹ç¶²çµ¡å±‚ï¼Œä¾‹å¦‚ RoIPooling é€™äº›ï¼Œä¸»è¦æ˜¯è¦å°‡æå¤±å°ç‰¹å¾µåœ–çš„æ¢¯åº¦è¨ˆç®—å‡ºä¾†ç„¶å¾Œå‘å¾Œå‚³å‡ºï¼Œå°æ–¼ä¸€äº›æœ‰åƒæ•°çš„å±‚ï¼Œé‚„éœ€è¦è¨ˆç®—å‡ºå°åƒæ•°çš„æ¢¯åº¦ï¼Œå„²å­˜åœ¨ tensor çš„ <code>.grad</code> å±æ€§ä¸­å‚³çµ¦ optimizerã€‚</p>
<p>æˆ‘æ²’æƒ³åˆ°å¯«é€™å€‹ç•«åœ–æ’ç‰ˆä¹‹é¡çš„å±…ç„¶èŠ±äº†å…©å¤©æ™‚é–“ï¼Œæ—©çŸ¥å¦‚æ­¤å°±ä¸å¯«äº†ã€‚ã€‚ï¼ˆé€™å¥½åƒæ˜¯çµ•å¤§å¤šèªªè¦å¯«çš„æ±è¥¿çš„ä¸‹å ´ï¼Œæˆ‘å»å¹´å±…ç„¶é‚„èªªè¦å¯«ä¸€äº›é—œæ–¼è‰²å½©ç§‘å­¸è¨ˆç®—æ”å½±ä¹‹é¡çš„ï¼Ÿï¼Ÿå°äº†ï¼Œæˆ‘æœ€è¿‘å¥½ä¸€é™£åœ¨ç ”ç©¶ ğŸï¸ï¼Œä¸¦é­”æ”¹ä¸€å€‹æ‹ç«‹å¾—çµ¦ä¸­ç‰‡å¹…è† ç‰‡æ©Ÿåšå¾ŒèƒŒï¼ŒçœŸçš„å¾ˆå¥½ç©ï¼‰</p>
<p><strong>åƒè€ƒè³‡æ–™ï¼š</strong></p>
<ol>
<li><p><a href="https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html" target="_blank" rel="noopener">Deep Learning with PyTorch: A 60 Minute Blitz &gt; Autograd: Automatic Differentiation</a></p>
</li>
<li><p><a href="https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/" target="_blank" rel="noopener">A Step by Step Backpropagation Example</a></p>
</li>
<li><p><a href="https://www.jefkine.com/general/2016/09/05/backpropagation-in-convolutional-neural-networks/" target="_blank" rel="noopener">Backpropagation In Convolutional Neural Networks</a></p>
</li>
<li><p><a href="https://medium.com/@2017csm1006/forward-and-backpropagation-in-convolutional-neural-network-4dfa96d7b37e" target="_blank" rel="noopener">Forward And Backpropagation in Convolutional Neural Network</a></p>
</li>
<li><p><a href="https://becominghuman.ai/back-propagation-in-convolutional-neural-networks-intuition-and-code-714ef1c38199" target="_blank" rel="noopener">Back Propagation in Convolutional Neural Networks â€” Intuition and Code</a></p>
</li>
<li><p><a href="https://www.vlfeat.org/matconvnet/matconvnet-manual.pdf" target="_blank" rel="noopener">Manual of MatConvNet: CNNs for MATLAB</a></p>
</li>
<li><p><a href="https://www.cnblogs.com/pinard/p/6494810.html" target="_blank" rel="noopener">å·ç§¯ç¥ç»ç¶²ç»œ(CNN)åå‘ä¼ æ’­ç®—æ³•</a></p>
</li>
</ol>
<br/>
            


        </div>
    </div>
    <div id="post-footer" class="post-footer main-content-wrap">
        
            <div class="post-footer-tags">
                <span class="text-color-light text-small">TAGGED IN</span><br/>
                
    <a class="tag tag--primary tag--small t-link" href="/tags/Backpropagation/" rel="tag">Backpropagation</a> <a class="tag tag--primary tag--small t-link" href="/tags/Computer-Vision/" rel="tag">Computer Vision</a> <a class="tag tag--primary tag--small t-link" href="/tags/Deep-Learning/" rel="tag">Deep Learning</a> <a class="tag tag--primary tag--small t-link" href="/tags/PyTorch/" rel="tag">PyTorch</a>

            </div>
        
        
            <div class="post-actions-wrap">
    <nav>
        <ul class="post-actions post-action-nav">
            <li class="post-action">
                
                    
                <a
                    class="post-action-btn btn btn--default tooltip--top"
                    href="/articles/yolo-from-v1-to-v4/"
                    data-tooltip="å®æ—¶ç›®æ ‡æ£€æµ‹æ–¹æ³• YOLO â€” ä» V1 åˆ° V4"
                    aria-label="PREVIOUS: å®æ—¶ç›®æ ‡æ£€æµ‹æ–¹æ³• YOLO â€” ä» V1 åˆ° V4"
                >
                    
                        <i class="fa fa-angle-left" aria-hidden="true"></i>
                        <span class="hide-xs hide-sm text-small icon-ml">PREVIOUS</span>
                    </a>
            </li>
            <li class="post-action">
                
                    
                <a
                    class="post-action-btn btn btn--default tooltip--top"
                    href="/posts/simple-thoughts-on-chinese-characters/"
                    data-tooltip="æ¼¢å­—é›œè«‡"
                    aria-label="NEXT: æ¼¢å­—é›œè«‡"
                >
                    
                        <span class="hide-xs hide-sm text-small icon-mr">NEXT</span>
                        <i class="fa fa-angle-right" aria-hidden="true"></i>
                    </a>
            </li>
        </ul>
    </nav>
    <ul class="post-actions post-action-share">
        <li class="post-action hide-lg hide-md hide-sm">
            <a
                class="post-action-btn btn btn--default btn-open-shareoptions"
                href="#btn-open-shareoptions"
                aria-label="Share this post"
            >
                <i class="fa fa-share-alt" aria-hidden="true"></i>
            </a>
        </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://www.facebook.com/sharer/sharer.php?u=https://tangh.github.io/articles/backward-in-convolutional-neural-networks/"
                    title="Share on Facebook"
                    aria-label="Share on Facebook"
                >
                    <i class="fab fa-facebook" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://twitter.com/intent/tweet?text=https://tangh.github.io/articles/backward-in-convolutional-neural-networks/"
                    title="Share on Twitter"
                    aria-label="Share on Twitter"
                >
                    <i class="fab fa-twitter" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="http://service.weibo.com/share/share.php?&amp;title=https://tangh.github.io/articles/backward-in-convolutional-neural-networks/"
                    title="Share on Weibo"
                    aria-label="Share on Weibo"
                >
                    <i class="fab fa-weibo" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="http://connect.qq.com/widget/shareqq/index.html?url=https://tangh.github.io/articles/backward-in-convolutional-neural-networks/&amp;title=å·ç©ç¥ç¶“ç¶²çµ¡ä¸­çš„åå‘å‚³æ’­"
                    title="Share on QQ"
                    aria-label="Share on QQ"
                >
                    <i class="fab fa-qq" aria-hidden="true"></i>
                </a>
            </li>
        
        
            
                <li class="post-action">
                    <a
                        class="post-action-btn btn btn--default"
                        href="#gitalk"
                        aria-label="Leave a comment"
                    >
                        <i class="fa fa-comment"></i>
                    </a>
                </li>
            
        
        <li class="post-action">
            
                <a class="post-action-btn btn btn--default" href="#table-of-contents" aria-label="Table of Contents">
            
                <i class="fa fa-list" aria-hidden="true"></i>
            </a>
        </li>
    </ul>
</div>


        
        
            
                <div id="gitalk"></div>

            
        
    </div>
</article>



                <footer id="footer" class="main-content-wrap">
    <span class="copyrights">
        Copyrights &copy; 2021 Tang Huan. All Rights Reserved.
    </span>
</footer>

            </div>
            
                <div id="bottom-bar" class="post-bottom-bar" data-behavior="4">
                    <div class="post-bar-actions-wrap">
    <div class="post-actions post-action-share">
        <div class="post-action">
            
                <a class="post-bar-action-btn btn btn--default" href="#table-of-contents" aria-label="Table of Contents">
            
                <i class="fas fa-angle-up" aria-hidden="true"></i>
            </a>
        </div>
        
            
                <div class="post-action">
                    <a 
                        class="post-bar-action-btn btn btn--default"
                        href="#gitalk"
                        aria-label="Leave a comment"
                    >
                         <i class="fas fa-angle-down"></i>
                    </a>
                </div>
            
        
    </div>
</div>
                </div>
                
    <div id="share-options-bar" class="share-options-bar" data-behavior="4">
        <i id="btn-close-shareoptions" class="fa fa-times"></i>
        <ul class="share-options">
            
                
                
                <li class="share-option">
                    <a
                        class="share-option-btn"
                        target="new"
                        href="https://www.facebook.com/sharer/sharer.php?u=https://tangh.github.io/articles/backward-in-convolutional-neural-networks/"
                        aria-label="Share on Facebook"
                    >
                        <i class="fab fa-facebook" aria-hidden="true"></i><span>Share on Facebook</span>
                    </a>
                </li>
            
                
                
                <li class="share-option">
                    <a
                        class="share-option-btn"
                        target="new"
                        href="https://twitter.com/intent/tweet?text=https://tangh.github.io/articles/backward-in-convolutional-neural-networks/"
                        aria-label="Share on Twitter"
                    >
                        <i class="fab fa-twitter" aria-hidden="true"></i><span>Share on Twitter</span>
                    </a>
                </li>
            
                
                
                <li class="share-option">
                    <a
                        class="share-option-btn"
                        target="new"
                        href="http://service.weibo.com/share/share.php?&amp;title=https://tangh.github.io/articles/backward-in-convolutional-neural-networks/"
                        aria-label="Share on Weibo"
                    >
                        <i class="fab fa-weibo" aria-hidden="true"></i><span>Share on Weibo</span>
                    </a>
                </li>
            
                
                
                <li class="share-option">
                    <a
                        class="share-option-btn"
                        target="new"
                        href="http://connect.qq.com/widget/shareqq/index.html?url=https://tangh.github.io/articles/backward-in-convolutional-neural-networks/&amp;title=å·ç©ç¥ç¶“ç¶²çµ¡ä¸­çš„åå‘å‚³æ’­"
                        aria-label="Share on QQ"
                    >
                        <i class="fab fa-qq" aria-hidden="true"></i><span>Share on QQ</span>
                    </a>
                </li>
            
        </ul>
    </div>


            
        </div>
        


    
        
    

<div id="about">
    <div id="about-card">
        <div id="about-btn-close">
            <i class="fa fa-times"></i>
        </div>
        
            <img id="about-card-picture" src="/assets/images/icon.jpg" alt="Author&#39;s picture"/>
        
            <h4 id="about-card-name">Tang Huan</h4>
        
            <div id="about-card-bio"></div>
        
        
            <div id="about-card-job">
                <i class="fa fa-briefcase"></i>
                <br/>
                
            </div>
        
        
            <div id="about-card-location">
                <i class="fa fa-map-marker-alt"></i>
                <br/>
                Shanghai
            </div>
        
    </div>
</div>

        
        
<div id="cover" style="background-image:url('/assets/images/cover.jpg');"></div>
        

<!--SCRIPTS-->

<script src="/assets/js/script-21vlobaq8sfmdbypn0z91hl6jyot6shixuux8ijser2jcbktmikbwlb6yvjx.min.js"></script>

<!--SCRIPTS END-->


    
      <script type="text/javascript">
        (function() {
          function render() {
            new Gitalk({
              clientID: 'b7b365f41dbbfaaf9b88',
              clientSecret: '25de272b8030e3c498dd56b883e4386d881b6d62',
              repo: 'tangh.github.io',
              owner: 'tangh',
              admin: ['tangh'],
              id: 'articles/backward-in-convolutional-neural-networks',
              title: document.title.replace(' - é›¨å¤©ç­‰æ”¾æ™´', ''),
              ...{"language":"en","perPage":10,"distractionFreeMode":false,"enableHotKey":true,"pagerDirection":"first","createIssueManually":true}
            }).render('gitalk');
          }
          var gc = document.createElement('script');
          gc.type = 'text/javascript';
          gc.src = '//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js';
          gc.charset = 'UTF-8';
          gc.onload = render;
          gc.async = true;
          document.querySelector('body').appendChild(gc);
          var gcs = document.createElement('link');
          gcs.href = '//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css';
          gcs.type = 'text/css';
          gcs.rel = 'stylesheet';
          gcs.media = 'screen,print';
          document.querySelector('head').appendChild(gcs);
        })();
      </script>
    




    <script>!function(e){var c=Array.prototype.slice.call(document.querySelectorAll("img[data-original]"));function i(){for(var r=0;r<c.length;r++)t=c[r],(n=t.getBoundingClientRect()).top>=-n.height&&0<=n.left&&n.top<=1.5*(e.innerHeight||document.documentElement.clientHeight)&&function(){var t,n,e,i,o=c[r];t=o,n=function(){c=c.filter(function(t){return o!==t})},e=new Image,i=t.getAttribute("data-original"),e.onload=function(){t.src=i,n&&n()},e.src=i}();var t,n}i(),e.addEventListener("scroll",function(){var t,n;t=i,n=e,clearTimeout(t.tId),t.tId=setTimeout(function(){t.call(n)},500)})}(this);</script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config("");
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end --></body>
</html>
